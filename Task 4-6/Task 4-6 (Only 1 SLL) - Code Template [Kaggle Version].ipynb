{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13416578,"sourceType":"datasetVersion","datasetId":8515242},{"sourceId":13941635,"sourceType":"datasetVersion","datasetId":8885301},{"sourceId":14004161,"sourceType":"datasetVersion","datasetId":8922763},{"sourceId":14004184,"sourceType":"datasetVersion","datasetId":8922778},{"sourceId":14004253,"sourceType":"datasetVersion","datasetId":8922829}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task 4","metadata":{}},{"cell_type":"markdown","source":"## CELL 1 - Header / Config (Edit Page)","metadata":{}},{"cell_type":"code","source":"# =========================\n# SimSiam (Task 4,5,6) - Config\n# =========================\n\nimport os, random, json, time\nimport numpy as np\nimport torch\n\n# ---------- Required user edits (change if needed) ----------\nDATA_DIR = \"/kaggle/input/betel-leaf/Betel Leaf Dataset A Primary Dataset From Field And Controlled Environment/Betel Leaf Dataset\"\n\n# Input resolution (default 224). Allowed: 224 (default) or 160 (optional) or any int >= 64.\nRESOLUTION = 224  # change to 160 if want 160x160\n\n# Pretraining epochs for SimSiam (ENFORCED minimum 100)\nPRETRAIN_EPOCHS = 100\n\n# Downstream training epochs (linear probe / fine-tune)\nLINEAR_EPOCHS = 50\nFINETUNE_EPOCHS = 50\n\n# Other experiment settings\nBATCH_SIZE = 64\nBACKBONE = \"resnet18\"   # 'resnet18' or 'resnet50'\nSEED = 42\nNUM_WORKERS = 2         # DataLoader workers; increase if instance allows\nOUT_DIR = \"/kaggle/working/simsiam_task4\"\n\n# Safety / assertions\nassert os.path.exists(DATA_DIR), f\"DATA_DIR not found: {DATA_DIR}\"\nassert PRETRAIN_EPOCHS >= 100, \"PRETRAIN_EPOCHS must be >= 100\"\nassert isinstance(RESOLUTION, int) and RESOLUTION >= 64, \"RESOLUTION must be integer >=64\"\n\n# reproducibility\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n\n# create output dir\nos.makedirs(OUT_DIR, exist_ok=True)\n\nprint(\"CONFIG\")\nprint(\"DATA_DIR:\", DATA_DIR)\nprint(\"RESOLUTION:\", RESOLUTION)\nprint(\"PRETRAIN_EPOCHS:\", PRETRAIN_EPOCHS)\nprint(\"BATCH_SIZE:\", BATCH_SIZE)\nprint(\"BACKBONE:\", BACKBONE)\nprint(\"OUT_DIR:\", OUT_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:09:27.733399Z","iopub.execute_input":"2025-12-05T08:09:27.733561Z","iopub.status.idle":"2025-12-05T08:09:34.145639Z","shell.execute_reply.started":"2025-12-05T08:09:27.733544Z","shell.execute_reply":"2025-12-05T08:09:34.144962Z"}},"outputs":[{"name":"stdout","text":"CONFIG\nDATA_DIR: /kaggle/input/betel-leaf/Betel Leaf Dataset A Primary Dataset From Field And Controlled Environment/Betel Leaf Dataset\nRESOLUTION: 224\nPRETRAIN_EPOCHS: 100\nBATCH_SIZE: 64\nBACKBONE: resnet18\nOUT_DIR: /kaggle/working/simsiam_task4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## CELL 2 — Imports & Basic Utilities","metadata":{}},{"cell_type":"code","source":"# =========================\n# Safe Imports & Utilities\n# =========================\n\n# Put environment variables first to reduce noisy native logs if TensorFlow\n# or other C++ extensions are imported later in the same process.\nimport os\nos.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"3\")   # silence many TF logs if TF loaded later\nos.environ.setdefault(\"XLA_FLAGS\", \"--xla_gpu_cuda_data_dir=/usr/local/cuda  --xla_force_host_platform_device_count=1\")\n# Note: XLA_FLAGS and its values may be environment / system dependent;\n# setting TF_CPP_MIN_LOG_LEVEL is the most portable suppressor.\n\n# core stdlib\nimport sys\nimport math\nimport shutil\nfrom pathlib import Path\nfrom glob import glob\nfrom typing import Optional\n\n# helpful progress / imaging\nfrom tqdm import tqdm\nfrom PIL import Image\n\n# plotting (matplotlib first, then seaborn)\nimport matplotlib.pyplot as plt\ntry:\n    import seaborn as sns\nexcept Exception as e:\n    sns = None\n    print(\"Warning: seaborn import failed — continuing without it:\", e)\n\n# PyTorch (import only if available)\ntry:\n    import torch\n    from torch import nn, optim\n    from torch.utils.data import DataLoader, Dataset\n    import torchvision\n    from torchvision import transforms, models\nexcept Exception as e:\n    torch = None\n    nn = None\n    optim = None\n    DataLoader = None\n    Dataset = None\n    torchvision = None\n    transforms = None\n    models = None\n    print(\"Warning: PyTorch imports failed or CUDA unavailable:\", e)\n\n# Scikit-learn (classifiers & metrics)\ntry:\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.svm import SVC\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n    from sklearn.model_selection import train_test_split\nexcept Exception as e:\n    print(\"Warning: scikit-learn import failed:\", e)\n\n# UMAP / t-SNE / silhouette\ntry:\n    import umap\nexcept Exception as e:\n    umap = None\n    print(\"Info: umap not available:\", e)\n\ntry:\n    from sklearn.manifold import TSNE\n    from sklearn.metrics import silhouette_score\nexcept Exception as e:\n    print(\"Warning importing TSNE / silhouette_score:\", e)\n\n# Save utility\ntry:\n    import joblib\n    import pickle\nexcept Exception as e:\n    print(\"Warning: joblib/pickle import issue:\", e)\n\n# Utility to print versions and environment diagnostics\ndef env_diagnostics(show_packages: Optional[list] = None):\n    \"\"\"Print device + common package versions to help debug environment mismatches.\"\"\"\n    print(\"Python:\", sys.version.splitlines()[0])\n    # PyTorch & CUDA\n    if torch is not None:\n        try:\n            print(\"PyTorch:\", torch.__version__)\n            print(\"CUDA available:\", torch.cuda.is_available())\n            if torch.cuda.is_available():\n                print(\"CUDA device count:\", torch.cuda.device_count())\n                print(\"CUDA current device:\", torch.cuda.current_device())\n                print(\"CUDA device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n        except Exception as e:\n            print(\"PyTorch diagnostic error:\", e)\n    else:\n        print(\"PyTorch: not available\")\n\n    # seaborn / matplotlib\n    try:\n        import matplotlib\n        print(\"matplotlib:\", matplotlib.__version__)\n    except Exception:\n        print(\"matplotlib: not available\")\n\n    if sns is not None:\n        try:\n            print(\"seaborn:\", sns.__version__)\n        except Exception:\n            pass\n\n    # scikit-learn\n    try:\n        import sklearn\n        print(\"scikit-learn:\", sklearn.__version__)\n    except Exception:\n        print(\"scikit-learn: not available\")\n\n    # umap\n    if umap is not None:\n        try:\n            print(\"umap-learn:\", umap.__version__)\n        except Exception:\n            pass\n\n    # If TensorFlow is installed (we don't import it by default), just print version info safely:\n    try:\n        import importlib\n        if importlib.util.find_spec(\"tensorflow\") is not None:\n            import tensorflow as tf\n            print(\"TensorFlow:\", tf.__version__)\n            # don't call anything that triggers plugin registration here\n        else:\n            print(\"TensorFlow: not installed (or not found in this env)\")\n    except Exception as e:\n        # Avoid failing diagnostics if TF import triggers C++ plugin registrations\n        print(\"TensorFlow import safe-check raised an exception (not fatal):\", e)\n\n# Device selection (PyTorch-first)\nif torch is not None:\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nelse:\n    DEVICE = \"cpu\"\nprint(\"Device:\", DEVICE)\n\n# Example: run environment diagnostics immediately (optional)\nenv_diagnostics()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:11:45.981669Z","iopub.execute_input":"2025-12-05T08:11:45.982000Z","iopub.status.idle":"2025-12-05T08:11:45.995877Z","shell.execute_reply.started":"2025-12-05T08:11:45.981976Z","shell.execute_reply":"2025-12-05T08:11:45.995303Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nPython: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPyTorch: 2.6.0+cu124\nCUDA available: True\nCUDA device count: 2\nCUDA current device: 0\nCUDA device name: Tesla T4\nmatplotlib: 3.7.2\nseaborn: 0.12.2\nscikit-learn: 1.2.2\numap-learn: 0.5.9.post2\nTensorFlow: 2.18.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"CELL 3 — Build file manifest (reads dataset structure & prints counts)","metadata":{}},{"cell_type":"code","source":"# ===== Final robust manifest builder (corrects Leaf / non-Leaf folders) =====\n\nfrom pathlib import Path\nimport json, os\nroot = Path(\"/kaggle/input/betel-leaf/Betel Leaf Dataset A Primary Dataset From Field And Controlled Environment/Betel Leaf Dataset\")\nassert root.exists(), f\"Dataset root missing: {root}\"\n\nexpected_classes = [\"Diseased\", \"Dried\", \"Healthy\"]\nsources = [p.name for p in root.iterdir() if p.is_dir()]\nprint(\"Detected top-level source folders:\", sources)\n\nfilepaths = []\nlabels = []\nfound_map = {}\n\ndef normalize(name: str):\n    \"\"\"Utility to normalize folder names for matching.\"\"\"\n    return name.lower().replace(\" \", \"\").replace(\"_\", \"\").replace(\"-\", \"\")\n\nfor src in sources:\n    src_dir = root / src\n    subdirs = [d.name for d in src_dir.iterdir() if d.is_dir()]\n    print(f\"\\nSource '{src}' subfolders:\", subdirs)\n\n    for cls in expected_classes:\n        cls_norm = normalize(cls)\n        matched = None\n\n        # Scan each subfolder to find those containing this class\n        for s in subdirs:\n            if cls_norm in normalize(s):  # <-- KEY FIX: match Diseased ↔ DiseasedLeaf\n                matched = s\n                break\n\n        if matched is None:\n            print(f\"WARNING: class '{cls}' not found under '{src}'\")\n            continue\n\n        found_map.setdefault(src, {})[cls] = matched\n        cls_dir = src_dir / matched\n\n        for p in cls_dir.glob(\"*\"):\n            if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n                filepaths.append(str(p))\n                labels.append(expected_classes.index(cls))\n\nprint(\"\\nTotal images found:\", len(filepaths))\nfrom collections import Counter\nctr = Counter([Path(p).parent.name for p in filepaths])\nprint(\"Per-subfolder counts:\")\nfor k, v in ctr.items():\n    print(f\"  {k}: {v}\")\n\nmanifest = {\n    \"classes\": expected_classes,\n    \"sources_detected\": sources,\n    \"found_map\": found_map,\n    \"files\": filepaths,\n    \"labels\": labels\n}\n\nos.makedirs(\"/kaggle/working/simsiam_task4\", exist_ok=True)\nwith open(\"/kaggle/working/simsiam_task4/manifest.json\", \"w\") as f:\n    json.dump(manifest, f)\nprint(\"\\nManifest saved to /kaggle/working/simsiam_task4/manifest.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:11:50.291094Z","iopub.execute_input":"2025-12-05T08:11:50.291756Z","iopub.status.idle":"2025-12-05T08:11:50.334294Z","shell.execute_reply.started":"2025-12-05T08:11:50.291722Z","shell.execute_reply":"2025-12-05T08:11:50.333551Z"}},"outputs":[{"name":"stdout","text":"Detected top-level source folders: ['On Field', 'Controlled Environment']\n\nSource 'On Field' subfolders: ['Diseased Leaf', 'Healthy Leaf', 'Dried Leaf']\n\nSource 'Controlled Environment' subfolders: ['Diseased', 'Dried', 'Healthy']\n\nTotal images found: 1800\nPer-subfolder counts:\n  Diseased Leaf: 289\n  Dried Leaf: 282\n  Healthy Leaf: 336\n  Diseased: 220\n  Dried: 340\n  Healthy: 333\n\nManifest saved to /kaggle/working/simsiam_task4/manifest.json\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"CELL 4 — Transforms (SimSiam two-view + eval transforms)","metadata":{}},{"cell_type":"code","source":"# =========================\n# Transforms: SimSiam augmentation (two-view) and evaluation transforms\n# - Uses global RESOLUTION variable set in cell 1\n# =========================\n\n# Augmentation recipe tailored for leaf images; includes safe cropping and color jitter.\n# We keep it relatively strong but include an augmentation probe later in the notebook.\nsimsiam_transform = transforms.Compose([\n    transforms.RandomResizedCrop(RESOLUTION, scale=(0.2, 1.0), ratio=(0.75, 1.33)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.2),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.02),\n    transforms.RandomGrayscale(p=0.2),\n    transforms.GaussianBlur(kernel_size=(3,3), sigma=(0.1, 2.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\n\n# Evaluation transforms (deterministic)\neval_transform = transforms.Compose([\n    transforms.Resize(int(RESOLUTION * 1.1)),\n    transforms.CenterCrop(RESOLUTION),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\n\n# quick visual check function for augmentation probe (returns a list of PIL images)\ndef aug_probe_image(path, n=6):\n    img = Image.open(path).convert(\"RGB\")\n    outs = []\n    for _ in range(n):\n        timg = simsiam_transform(img)\n        # de-normalize for visualization\n        t = timg.numpy().transpose(1,2,0)\n        t = t * np.array([0.229,0.224,0.225]) + np.array([0.485,0.456,0.406])\n        t = np.clip(t, 0, 1)\n        outs.append((t*255).astype(np.uint8))\n    return outs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:11:56.237089Z","iopub.execute_input":"2025-12-05T08:11:56.237754Z","iopub.status.idle":"2025-12-05T08:11:56.245377Z","shell.execute_reply.started":"2025-12-05T08:11:56.237728Z","shell.execute_reply":"2025-12-05T08:11:56.244786Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"CELL 5 — Dataset wrappers: TwoViewDataset + ManifestDataset","metadata":{}},{"cell_type":"code","source":"# =========================\n# Dataset classes\n# TwoViewDataset: returns two augmented views per image for SimSiam training\n# ManifestDataset: deterministic dataset for evaluation/feature extraction\n# =========================\n\nclass TwoViewDataset(Dataset):\n    \"\"\"Returns two different augmented views of the same image (for SimSiam).\"\"\"\n    def __init__(self, paths, labels, transform):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        lbl = self.labels[idx]\n        img = Image.open(p).convert(\"RGB\")\n        x1 = self.transform(img)\n        x2 = self.transform(img)\n        return x1, x2, lbl, p\n\nclass ManifestDataset(Dataset):\n    \"\"\"Deterministic dataset for feature extraction and downstream training.\"\"\"\n    def __init__(self, paths, labels, transform):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        lbl = self.labels[idx]\n        img = Image.open(p).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, lbl, p\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:12:01.255128Z","iopub.execute_input":"2025-12-05T08:12:01.255707Z","iopub.status.idle":"2025-12-05T08:12:01.261788Z","shell.execute_reply.started":"2025-12-05T08:12:01.255684Z","shell.execute_reply":"2025-12-05T08:12:01.261019Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"CELL 6 — Create train/val/test splits and DataLoaders (deterministic split saved)","metadata":{}},{"cell_type":"code","source":"# =========================\n# Create fixed stratified train/val/test splits and DataLoaders\n# Save split manifest for reproducibility\n# =========================\n\npaths = manifest[\"files\"]\nlabels = manifest[\"labels\"]\nclasses = manifest[\"classes\"]\n\n# First split: fixed test set 20%\ntrain_paths, test_paths, train_labels, test_labels = train_test_split(\n    paths, labels, test_size=0.20, stratify=labels, random_state=SEED)\n\n# From train, carve out validation 10% of train\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    train_paths, train_labels, test_size=0.10, stratify=train_labels, random_state=SEED)\n\nprint(\"Train:\", len(train_paths), \"Val:\", len(val_paths), \"Test:\", len(test_paths))\n\nsplit_manifest = {\n    \"classes\": classes,\n    \"train\": train_paths, \"train_labels\": train_labels,\n    \"val\": val_paths, \"val_labels\": val_labels,\n    \"test\": test_paths, \"test_labels\": test_labels\n}\nwith open(os.path.join(OUT_DIR, \"split_manifest.json\"), \"w\") as f:\n    json.dump(split_manifest, f)\nprint(\"Split manifest saved to\", os.path.join(OUT_DIR, \"split_manifest.json\"))\n\n# DataLoaders for pretraining (two-view)\ntrain_dataset = TwoViewDataset(train_paths, train_labels, simsiam_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n                          num_workers=NUM_WORKERS, drop_last=True)\n\n# DataLoaders for evaluation (use ManifestDataset)\nval_dataset = ManifestDataset(val_paths, val_labels, eval_transform)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\ntest_dataset = ManifestDataset(test_paths, test_labels, eval_transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:12:10.373575Z","iopub.execute_input":"2025-12-05T08:12:10.373858Z","iopub.status.idle":"2025-12-05T08:12:10.402244Z","shell.execute_reply.started":"2025-12-05T08:12:10.373837Z","shell.execute_reply":"2025-12-05T08:12:10.401364Z"}},"outputs":[{"name":"stdout","text":"Train: 1296 Val: 144 Test: 360\nSplit manifest saved to /kaggle/working/simsiam_task4/split_manifest.json\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"CELL 7 — SimSiam model definition (encoder, projector, predictor)","metadata":{}},{"cell_type":"code","source":"# =========================\n# SimSiam model (backbone + projector + predictor)\n# Implementation note: this is a compact, readable SimSiam for our project.\n# =========================\n\nclass SimSiam(nn.Module):\n    def __init__(self, backbone=\"resnet18\", pretrained=False, proj_hidden=2048, pred_hidden=512, out_dim=512):\n        super().__init__()\n        # backbone\n        if backbone == \"resnet18\":\n            base = models.resnet18(pretrained=pretrained)\n            feat_dim = 512\n        elif backbone == \"resnet50\":\n            base = models.resnet50(pretrained=pretrained)\n            feat_dim = 2048\n        else:\n            raise ValueError(\"backbone must be resnet18 or resnet50\")\n        # remove fc\n        modules = list(base.children())[:-1]  # remove avgpool? we keep avgpool and flatten path\n        self.encoder = nn.Sequential(*modules)  # encoder returns [B, feat_dim, 1, 1]\n        self.feat_dim = feat_dim\n\n        # projector: 3-layer MLP\n        self.projector = nn.Sequential(\n            nn.Linear(feat_dim, proj_hidden),\n            nn.BatchNorm1d(proj_hidden),\n            nn.ReLU(inplace=True),\n            nn.Linear(proj_hidden, proj_hidden),\n            nn.BatchNorm1d(proj_hidden),\n            nn.ReLU(inplace=True),\n            nn.Linear(proj_hidden, out_dim)\n        )\n\n        # predictor: 2-layer MLP\n        self.predictor = nn.Sequential(\n            nn.Linear(out_dim, pred_hidden),\n            nn.BatchNorm1d(pred_hidden),\n            nn.ReLU(inplace=True),\n            nn.Linear(pred_hidden, out_dim)\n        )\n\n    def forward_backbone(self, x):\n        # encoder gives shape [B, feat_dim, 1, 1] normally; flatten to [B, feat_dim]\n        h = self.encoder(x)\n        h = h.view(h.size(0), -1)\n        return h\n\n    def forward(self, x1, x2):\n        # returns predictor outputs and targets (projector outputs detached)\n        h1 = self.forward_backbone(x1)\n        h2 = self.forward_backbone(x2)\n        z1 = self.projector(h1)\n        z2 = self.projector(h2)\n        p1 = self.predictor(z1)\n        p2 = self.predictor(z2)\n        # For loss: compare p1 with z2.detach() and p2 with z1.detach()\n        return p1, p2, z1.detach(), z2.detach()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:12:18.646118Z","iopub.execute_input":"2025-12-05T08:12:18.646785Z","iopub.status.idle":"2025-12-05T08:12:18.654772Z","shell.execute_reply.started":"2025-12-05T08:12:18.646762Z","shell.execute_reply":"2025-12-05T08:12:18.653928Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"CELL 8 — Loss function (negative cosine similarity) & utilities","metadata":{}},{"cell_type":"code","source":"# =========================\n# Loss: negative cosine similarity as used by SimSiam\n# =========================\n\ndef negative_cosine_similarity(p, z):\n    # p: [B, D] predictor outputs (not detached)\n    # z: [B, D] target projector outputs (detached)\n    p = nn.functional.normalize(p, dim=1)\n    z = nn.functional.normalize(z, dim=1)\n    return - (p * z).sum(dim=1).mean()\n\n# checkpoint saving helper\ndef save_checkpoint(state, filename):\n    torch.save(state, filename)\n    print(\"Saved checkpoint:\", filename)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:12:24.656281Z","iopub.execute_input":"2025-12-05T08:12:24.657042Z","iopub.status.idle":"2025-12-05T08:12:24.661277Z","shell.execute_reply.started":"2025-12-05T08:12:24.657017Z","shell.execute_reply":"2025-12-05T08:12:24.660545Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"CELL 9 — Pretraining loop (resumeable) — run this cell to pretrain SimSiam","metadata":{}},{"cell_type":"code","source":"# =========================\n# Pretraining: SimSiam training loop with resumeable checkpointing\n# Save encoder at the end as simsiam_encoder.pth\n# =========================\n\n# Hyperparams for pretraining loop (can edit if needed)\nlearning_rate = 0.03 * (BATCH_SIZE / 256)  # linear scaling rule; small batches => smaller lr\nmomentum = 0.9\nweight_decay = 1e-4\n\n# instantiate model, optimizer, scheduler\nmodel = SimSiam(backbone=BACKBONE).to(DEVICE)\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=PRETRAIN_EPOCHS)\n\n# checkpoint paths\nlatest_ckpt = os.path.join(OUT_DIR, \"simsiam_latest.pth\")\nbest_ckpt = os.path.join(OUT_DIR, \"simsiam_best_linearprobe.pth\")  # kept for future extension\nencoder_outpath = os.path.join(OUT_DIR, \"simsiam_encoder.pth\")\n\n# optionally resume\nstart_epoch = 0\nif os.path.exists(latest_ckpt):\n    ck = torch.load(latest_ckpt, map_location=DEVICE)\n    model.load_state_dict(ck[\"model_state\"])\n    optimizer.load_state_dict(ck[\"optimizer_state\"])\n    scheduler.load_state_dict(ck[\"scheduler_state\"])\n    start_epoch = ck[\"epoch\"] + 1\n    print(\"Resumed from checkpoint. Starting at epoch\", start_epoch)\n\n# quick function to evaluate linear probe on val using frozen encoder (used as proxy occasionally)\ndef extract_features_from_encoder(encoder, paths_list, transform, batch_size=64):\n    encoder.eval()\n    ds = ManifestDataset(paths_list, [0]*len(paths_list), transform=transform)\n    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)\n    feats = []\n    with torch.no_grad():\n        for imgs, _, _ in loader:\n            imgs = imgs.to(DEVICE)\n            h = encoder(imgs).view(imgs.size(0), -1).cpu().numpy()\n            feats.append(h)\n    feats = np.vstack(feats)\n    return feats\n\n# For occasional quick probing: a small linear-probe train on a subset (fast)\ndef quick_linear_probe(encoder, train_paths, train_labels, val_paths, val_labels, transform, max_samples=500):\n    # build features (may subsample for speed)\n    tpaths = train_paths[:max_samples]; tlabels = train_labels[:max_samples]\n    train_feats = extract_features_from_encoder(encoder, tpaths, transform)\n    val_feats = extract_features_from_encoder(encoder, val_paths, transform)\n    clf = LogisticRegression(max_iter=1000)\n    clf.fit(train_feats, tlabels)\n    preds = clf.predict(val_feats)\n    acc = accuracy_score(val_labels, preds)\n    return acc\n\n# Main training loop\nprint(\"Starting pretraining for\", PRETRAIN_EPOCHS, \"epochs (from epoch\", start_epoch, \")\")\nfor epoch in range(start_epoch, PRETRAIN_EPOCHS):\n    model.train()\n    epoch_losses = []\n    loop = tqdm(train_loader, desc=f\"Pretrain Epoch {epoch+1}/{PRETRAIN_EPOCHS}\")\n    for x1, x2, lbl, _ in loop:\n        x1 = x1.to(DEVICE); x2 = x2.to(DEVICE)\n        p1, p2, z1, z2 = model(x1, x2)\n        loss = 0.5 * negative_cosine_similarity(p1, z2) + 0.5 * negative_cosine_similarity(p2, z1)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        epoch_losses.append(loss.item())\n        loop.set_postfix(loss=f\"{np.mean(epoch_losses):.4f}\")\n\n    scheduler.step()\n    avg_loss = float(np.mean(epoch_losses))\n    print(f\"Epoch {epoch+1} finished. Avg loss: {avg_loss:.4f}\")\n\n    # checkpoint: save latest (includes RNG/manifest information for reproducibility)\n    ck = {\n        \"epoch\": epoch,\n        \"model_state\": model.state_dict(),\n        \"optimizer_state\": optimizer.state_dict(),\n        \"scheduler_state\": scheduler.state_dict(),\n        \"avg_loss\": avg_loss,\n        \"manifest\": split_manifest\n    }\n    save_checkpoint(ck, latest_ckpt)\n\n# After training save encoder state dict (only encoder weights; projector/predictor not needed downstream)\ntorch.save({\"encoder_state_dict\": model.encoder.state_dict(), \"feat_dim\": model.feat_dim},\n           encoder_outpath)\nprint(\"Pretraining complete. Encoder saved to\", encoder_outpath)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:20:26.188907Z","iopub.execute_input":"2025-11-23T19:20:26.189444Z","iopub.status.idle":"2025-11-24T05:49:19.686304Z","shell.execute_reply.started":"2025-11-23T19:20:26.189421Z","shell.execute_reply":"2025-11-24T05:49:19.685492Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Starting pretraining for 100 epochs (from epoch 0 )\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 1/100: 100%|██████████| 20/20 [06:57<00:00, 20.89s/it, loss=-0.1287]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 finished. Avg loss: -0.1287\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 2/100: 100%|██████████| 20/20 [06:21<00:00, 19.07s/it, loss=-0.4303]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 finished. Avg loss: -0.4303\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 3/100: 100%|██████████| 20/20 [06:14<00:00, 18.73s/it, loss=-0.5787]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 finished. Avg loss: -0.5787\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 4/100: 100%|██████████| 20/20 [06:10<00:00, 18.51s/it, loss=-0.6860]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 finished. Avg loss: -0.6860\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 5/100: 100%|██████████| 20/20 [06:19<00:00, 18.96s/it, loss=-0.7681]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 finished. Avg loss: -0.7681\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 6/100: 100%|██████████| 20/20 [06:10<00:00, 18.54s/it, loss=-0.8111]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 finished. Avg loss: -0.8111\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 7/100: 100%|██████████| 20/20 [06:13<00:00, 18.67s/it, loss=-0.8327]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 finished. Avg loss: -0.8327\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 8/100: 100%|██████████| 20/20 [06:14<00:00, 18.72s/it, loss=-0.8515]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 finished. Avg loss: -0.8515\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 9/100: 100%|██████████| 20/20 [06:17<00:00, 18.88s/it, loss=-0.8444]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 finished. Avg loss: -0.8444\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 10/100: 100%|██████████| 20/20 [06:17<00:00, 18.89s/it, loss=-0.8696]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 finished. Avg loss: -0.8696\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 11/100: 100%|██████████| 20/20 [06:19<00:00, 18.98s/it, loss=-0.8581]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 finished. Avg loss: -0.8581\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 12/100: 100%|██████████| 20/20 [06:14<00:00, 18.72s/it, loss=-0.8753]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 finished. Avg loss: -0.8753\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 13/100: 100%|██████████| 20/20 [06:06<00:00, 18.35s/it, loss=-0.8759]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 finished. Avg loss: -0.8759\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 14/100: 100%|██████████| 20/20 [06:13<00:00, 18.68s/it, loss=-0.8736]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 finished. Avg loss: -0.8736\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 15/100: 100%|██████████| 20/20 [06:13<00:00, 18.65s/it, loss=-0.8942]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 finished. Avg loss: -0.8942\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 16/100: 100%|██████████| 20/20 [06:19<00:00, 18.98s/it, loss=-0.8858]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 finished. Avg loss: -0.8858\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 17/100: 100%|██████████| 20/20 [06:13<00:00, 18.67s/it, loss=-0.8934]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 finished. Avg loss: -0.8934\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 18/100: 100%|██████████| 20/20 [05:59<00:00, 18.00s/it, loss=-0.8937]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 finished. Avg loss: -0.8937\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 19/100: 100%|██████████| 20/20 [06:17<00:00, 18.90s/it, loss=-0.8942]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 finished. Avg loss: -0.8942\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 20/100: 100%|██████████| 20/20 [06:19<00:00, 18.97s/it, loss=-0.9003]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 finished. Avg loss: -0.9003\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 21/100: 100%|██████████| 20/20 [06:11<00:00, 18.59s/it, loss=-0.8986]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 finished. Avg loss: -0.8986\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 22/100: 100%|██████████| 20/20 [06:11<00:00, 18.58s/it, loss=-0.8984]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 finished. Avg loss: -0.8984\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 23/100: 100%|██████████| 20/20 [06:20<00:00, 19.04s/it, loss=-0.8972]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 finished. Avg loss: -0.8972\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 24/100: 100%|██████████| 20/20 [06:18<00:00, 18.91s/it, loss=-0.8948]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 finished. Avg loss: -0.8948\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 25/100: 100%|██████████| 20/20 [06:03<00:00, 18.16s/it, loss=-0.8922]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 finished. Avg loss: -0.8922\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 26/100: 100%|██████████| 20/20 [06:19<00:00, 18.97s/it, loss=-0.8974]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 finished. Avg loss: -0.8974\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 27/100: 100%|██████████| 20/20 [06:16<00:00, 18.80s/it, loss=-0.8999]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 finished. Avg loss: -0.8999\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 28/100: 100%|██████████| 20/20 [06:10<00:00, 18.54s/it, loss=-0.9013]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 finished. Avg loss: -0.9013\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 29/100: 100%|██████████| 20/20 [06:20<00:00, 19.02s/it, loss=-0.9023]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 finished. Avg loss: -0.9023\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 30/100: 100%|██████████| 20/20 [06:21<00:00, 19.08s/it, loss=-0.9070]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 finished. Avg loss: -0.9070\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 31/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9009]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31 finished. Avg loss: -0.9009\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 32/100: 100%|██████████| 20/20 [06:28<00:00, 19.40s/it, loss=-0.9014]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32 finished. Avg loss: -0.9014\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 33/100: 100%|██████████| 20/20 [06:12<00:00, 18.64s/it, loss=-0.8989]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33 finished. Avg loss: -0.8989\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 34/100: 100%|██████████| 20/20 [06:18<00:00, 18.91s/it, loss=-0.9083]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34 finished. Avg loss: -0.9083\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 35/100: 100%|██████████| 20/20 [06:20<00:00, 19.03s/it, loss=-0.9056]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35 finished. Avg loss: -0.9056\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 36/100: 100%|██████████| 20/20 [06:13<00:00, 18.67s/it, loss=-0.9021]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36 finished. Avg loss: -0.9021\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 37/100: 100%|██████████| 20/20 [06:19<00:00, 18.96s/it, loss=-0.9027]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37 finished. Avg loss: -0.9027\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 38/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9024]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38 finished. Avg loss: -0.9024\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 39/100: 100%|██████████| 20/20 [06:17<00:00, 18.87s/it, loss=-0.9041]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39 finished. Avg loss: -0.9041\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 40/100: 100%|██████████| 20/20 [06:15<00:00, 18.77s/it, loss=-0.9015]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40 finished. Avg loss: -0.9015\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 41/100: 100%|██████████| 20/20 [06:12<00:00, 18.61s/it, loss=-0.8954]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41 finished. Avg loss: -0.8954\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 42/100: 100%|██████████| 20/20 [06:16<00:00, 18.84s/it, loss=-0.9000]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42 finished. Avg loss: -0.9000\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 43/100: 100%|██████████| 20/20 [06:20<00:00, 19.05s/it, loss=-0.9058]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43 finished. Avg loss: -0.9058\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 44/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9043]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44 finished. Avg loss: -0.9043\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 45/100: 100%|██████████| 20/20 [06:25<00:00, 19.29s/it, loss=-0.9010]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45 finished. Avg loss: -0.9010\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 46/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9076]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46 finished. Avg loss: -0.9076\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 47/100: 100%|██████████| 20/20 [06:16<00:00, 18.82s/it, loss=-0.9098]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47 finished. Avg loss: -0.9098\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 48/100: 100%|██████████| 20/20 [06:14<00:00, 18.73s/it, loss=-0.9045]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48 finished. Avg loss: -0.9045\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 49/100: 100%|██████████| 20/20 [06:23<00:00, 19.17s/it, loss=-0.9105]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49 finished. Avg loss: -0.9105\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 50/100: 100%|██████████| 20/20 [06:11<00:00, 18.60s/it, loss=-0.9072]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50 finished. Avg loss: -0.9072\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 51/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9112]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51 finished. Avg loss: -0.9112\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 52/100: 100%|██████████| 20/20 [06:18<00:00, 18.93s/it, loss=-0.9114]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52 finished. Avg loss: -0.9114\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 53/100: 100%|██████████| 20/20 [06:14<00:00, 18.74s/it, loss=-0.9047]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53 finished. Avg loss: -0.9047\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 54/100: 100%|██████████| 20/20 [06:29<00:00, 19.47s/it, loss=-0.8987]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54 finished. Avg loss: -0.8987\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 55/100: 100%|██████████| 20/20 [06:21<00:00, 19.05s/it, loss=-0.9183]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55 finished. Avg loss: -0.9183\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 56/100: 100%|██████████| 20/20 [06:15<00:00, 18.76s/it, loss=-0.9190]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56 finished. Avg loss: -0.9190\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 57/100: 100%|██████████| 20/20 [06:17<00:00, 18.88s/it, loss=-0.9139]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57 finished. Avg loss: -0.9139\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 58/100: 100%|██████████| 20/20 [06:24<00:00, 19.23s/it, loss=-0.9146]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58 finished. Avg loss: -0.9146\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 59/100: 100%|██████████| 20/20 [06:18<00:00, 18.92s/it, loss=-0.9131]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59 finished. Avg loss: -0.9131\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 60/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9122]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 60 finished. Avg loss: -0.9122\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 61/100: 100%|██████████| 20/20 [06:19<00:00, 18.98s/it, loss=-0.9176]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 61 finished. Avg loss: -0.9176\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 62/100: 100%|██████████| 20/20 [06:19<00:00, 18.97s/it, loss=-0.9130]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 62 finished. Avg loss: -0.9130\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 63/100: 100%|██████████| 20/20 [06:18<00:00, 18.93s/it, loss=-0.9147]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 63 finished. Avg loss: -0.9147\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 64/100: 100%|██████████| 20/20 [06:21<00:00, 19.07s/it, loss=-0.9130]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 64 finished. Avg loss: -0.9130\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 65/100: 100%|██████████| 20/20 [06:19<00:00, 18.99s/it, loss=-0.9130]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 65 finished. Avg loss: -0.9130\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 66/100: 100%|██████████| 20/20 [06:20<00:00, 19.02s/it, loss=-0.9187]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 66 finished. Avg loss: -0.9187\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 67/100: 100%|██████████| 20/20 [06:19<00:00, 18.97s/it, loss=-0.9150]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 67 finished. Avg loss: -0.9150\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 68/100: 100%|██████████| 20/20 [06:05<00:00, 18.28s/it, loss=-0.9201]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 68 finished. Avg loss: -0.9201\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 69/100: 100%|██████████| 20/20 [06:22<00:00, 19.14s/it, loss=-0.9135]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 69 finished. Avg loss: -0.9135\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 70/100: 100%|██████████| 20/20 [06:23<00:00, 19.18s/it, loss=-0.9123]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 70 finished. Avg loss: -0.9123\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 71/100: 100%|██████████| 20/20 [06:22<00:00, 19.10s/it, loss=-0.9177]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 71 finished. Avg loss: -0.9177\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 72/100: 100%|██████████| 20/20 [06:20<00:00, 19.03s/it, loss=-0.9154]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 72 finished. Avg loss: -0.9154\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 73/100: 100%|██████████| 20/20 [06:24<00:00, 19.22s/it, loss=-0.9192]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 73 finished. Avg loss: -0.9192\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 74/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9154]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 74 finished. Avg loss: -0.9154\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 75/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9158]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 75 finished. Avg loss: -0.9158\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 76/100: 100%|██████████| 20/20 [06:22<00:00, 19.13s/it, loss=-0.9128]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 76 finished. Avg loss: -0.9128\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 77/100: 100%|██████████| 20/20 [06:13<00:00, 18.69s/it, loss=-0.9191]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 77 finished. Avg loss: -0.9191\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 78/100: 100%|██████████| 20/20 [06:13<00:00, 18.65s/it, loss=-0.9230]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 78 finished. Avg loss: -0.9230\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 79/100: 100%|██████████| 20/20 [06:17<00:00, 18.88s/it, loss=-0.9172]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 79 finished. Avg loss: -0.9172\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 80/100: 100%|██████████| 20/20 [06:15<00:00, 18.77s/it, loss=-0.9178]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 80 finished. Avg loss: -0.9178\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 81/100: 100%|██████████| 20/20 [06:12<00:00, 18.60s/it, loss=-0.9160]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 81 finished. Avg loss: -0.9160\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 82/100: 100%|██████████| 20/20 [06:21<00:00, 19.06s/it, loss=-0.9195]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 82 finished. Avg loss: -0.9195\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 83/100: 100%|██████████| 20/20 [06:15<00:00, 18.76s/it, loss=-0.9179]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 83 finished. Avg loss: -0.9179\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 84/100: 100%|██████████| 20/20 [06:18<00:00, 18.92s/it, loss=-0.9208]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 84 finished. Avg loss: -0.9208\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 85/100: 100%|██████████| 20/20 [05:50<00:00, 17.52s/it, loss=-0.9239]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 85 finished. Avg loss: -0.9239\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 86/100: 100%|██████████| 20/20 [06:19<00:00, 18.96s/it, loss=-0.9157]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 86 finished. Avg loss: -0.9157\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 87/100: 100%|██████████| 20/20 [06:20<00:00, 19.01s/it, loss=-0.9111]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 87 finished. Avg loss: -0.9111\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 88/100: 100%|██████████| 20/20 [06:11<00:00, 18.60s/it, loss=-0.9194]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 88 finished. Avg loss: -0.9194\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 89/100: 100%|██████████| 20/20 [06:14<00:00, 18.72s/it, loss=-0.9169]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 89 finished. Avg loss: -0.9169\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 90/100: 100%|██████████| 20/20 [06:14<00:00, 18.71s/it, loss=-0.9176]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 90 finished. Avg loss: -0.9176\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 91/100: 100%|██████████| 20/20 [06:17<00:00, 18.87s/it, loss=-0.9189]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 91 finished. Avg loss: -0.9189\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 92/100: 100%|██████████| 20/20 [05:32<00:00, 16.64s/it, loss=-0.9194]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 92 finished. Avg loss: -0.9194\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 93/100: 100%|██████████| 20/20 [06:16<00:00, 18.81s/it, loss=-0.9203]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 93 finished. Avg loss: -0.9203\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 94/100: 100%|██████████| 20/20 [06:14<00:00, 18.73s/it, loss=-0.9212]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 94 finished. Avg loss: -0.9212\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 95/100: 100%|██████████| 20/20 [06:16<00:00, 18.82s/it, loss=-0.9223]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 95 finished. Avg loss: -0.9223\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 96/100: 100%|██████████| 20/20 [06:11<00:00, 18.57s/it, loss=-0.9198]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 96 finished. Avg loss: -0.9198\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 97/100: 100%|██████████| 20/20 [06:14<00:00, 18.74s/it, loss=-0.9226]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 97 finished. Avg loss: -0.9226\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 98/100: 100%|██████████| 20/20 [06:11<00:00, 18.56s/it, loss=-0.9148]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 98 finished. Avg loss: -0.9148\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 99/100: 100%|██████████| 20/20 [06:18<00:00, 18.95s/it, loss=-0.9190]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 99 finished. Avg loss: -0.9190\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 100/100: 100%|██████████| 20/20 [06:15<00:00, 18.76s/it, loss=-0.9217]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 100 finished. Avg loss: -0.9217\nSaved checkpoint: /kaggle/working/simsiam_task4/simsiam_latest.pth\nPretraining complete. Encoder saved to /kaggle/working/simsiam_task4/simsiam_encoder.pth\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Save Stage","metadata":{}},{"cell_type":"code","source":"# =========================\n# Cell: Save & Export (run after Cell 9 finishes)\n# Saves checkpoints, RNG states, manifests, encoder and zips OUT_DIR for download.\n# =========================\n\nimport os, json, time, pickle, sys, shutil\nimport torch\n\nOUT_DIR = \"/kaggle/working/simsiam_task4\"   # same as notebook config\narchive_path = \"/kaggle/working/simsiam_task4_archive.zip\"\n\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# 1) Save a reproducible checkpoint if model exists in memory\ntry:\n    ck = {\n        \"timestamp\": time.time(),\n        \"python_version\": sys.version,\n        \"manifest\": globals().get(\"manifest\", None),\n        \"split_manifest\": globals().get(\"split_manifest\", None),\n        \"seed\": globals().get(\"SEED\", None),\n    }\n    # model/optimizer/scheduler/epoch if available\n    if \"model\" in globals():\n        ck[\"model_state\"] = model.state_dict()\n    if \"optimizer\" in globals():\n        ck[\"optimizer_state\"] = optimizer.state_dict()\n    if \"scheduler\" in globals():\n        try:\n            ck[\"scheduler_state\"] = scheduler.state_dict()\n        except Exception:\n            pass\n    # epoch if defined\n    ck[\"last_epoch\"] = globals().get(\"epoch\", globals().get(\"start_epoch\", None))\n    # RNG states\n    import random, numpy as np\n    ck[\"py_random_state\"] = random.getstate()\n    ck[\"np_random_state\"] = np.random.get_state()\n    ck[\"torch_cpu_rng\"] = torch.get_rng_state()\n    if torch.cuda.is_available():\n        try:\n            ck[\"torch_cuda_rng_all\"] = torch.cuda.get_rng_state_all()\n        except Exception:\n            pass\n    # save\n    ck_path = os.path.join(OUT_DIR, \"manual_checkpoint_after_pretrain.pth\")\n    torch.save(ck, ck_path)\n    print(\"Saved manual checkpoint to:\", ck_path)\nexcept Exception as e:\n    print(\"Warning: could not save model/optimizer states:\", str(e))\n\n# 2) Save encoder separately if present\ntry:\n    if \"model\" in globals() and hasattr(model, \"encoder\"):\n        enc_path = os.path.join(OUT_DIR, \"simsiam_encoder_memory.pth\")\n        torch.save({\"encoder_state_dict\": model.encoder.state_dict(), \"feat_dim\": model.feat_dim}, enc_path)\n        print(\"Saved in-memory encoder to:\", enc_path)\n    elif os.path.exists(os.path.join(OUT_DIR, \"simsiam_encoder.pth\")):\n        print(\"Encoder checkpoint already on disk:\", os.path.join(OUT_DIR, \"simsiam_encoder.pth\"))\nexcept Exception as e:\n    print(\"Warning saving encoder:\", str(e))\n\n# 3) Ensure manifests are saved to OUT_DIR (copy if present in /kaggle/working)\nfor fname in [\"manifest.json\", \"split_manifest.json\"]:\n    src_candidates = [\n        os.path.join(OUT_DIR, fname),\n        os.path.join(\"/kaggle/working/simsiam_task4\", fname),\n        fname\n    ]\n    for s in src_candidates:\n        if os.path.exists(s) and not os.path.exists(os.path.join(OUT_DIR, fname)):\n            try:\n                shutil.copy(s, os.path.join(OUT_DIR, fname))\n                print(\"Copied manifest to OUT_DIR:\", fname)\n            except Exception:\n                pass\n\n# 4) Save a requirements snapshot\ntry:\n    req_path = os.path.join(OUT_DIR, \"requirements.txt\")\n    # pip freeze may be available on Kaggle\n    import subprocess\n    with open(req_path, \"w\") as f:\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"freeze\"], stdout=f)\n    print(\"Saved package list to:\", req_path)\nexcept Exception as e:\n    print(\"Warning saving requirements:\", str(e))\n\n# 5) Zip the OUT_DIR for download (overwrites existing)\ntry:\n    if os.path.exists(archive_path):\n        os.remove(archive_path)\n    shutil.make_archive(base_name=archive_path.replace(\".zip\",\"\"), format=\"zip\", root_dir=OUT_DIR)\n    print(\"Created archive:\", archive_path)\n    # list archive\n    print(\"Archive size (bytes):\", os.path.getsize(archive_path))\nexcept Exception as e:\n    print(\"Error creating archive:\", str(e))\n\n# 6) Quick listing of artifacts to confirm\nprint(\"\\nSample files in OUT_DIR:\")\nfor root, dirs, files in os.walk(OUT_DIR):\n    sample = files[:10]\n    print(root, \"->\", sample)\n    break\n\nprint(\"\\nDONE: Download the file 'simsiam_task4_archive.zip' from the Kaggle notebook output files (right panel).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:16:23.118194Z","iopub.execute_input":"2025-11-24T06:16:23.118570Z","iopub.status.idle":"2025-11-24T06:16:44.170967Z","shell.execute_reply.started":"2025-11-24T06:16:23.118539Z","shell.execute_reply":"2025-11-24T06:16:44.170310Z"}},"outputs":[{"name":"stdout","text":"Saved manual checkpoint to: /kaggle/working/simsiam_task4/manual_checkpoint_after_pretrain.pth\nSaved in-memory encoder to: /kaggle/working/simsiam_task4/simsiam_encoder_memory.pth\nSaved package list to: /kaggle/working/simsiam_task4/requirements.txt\nCreated archive: /kaggle/working/simsiam_task4_archive.zip\nArchive size (bytes): 350052858\n\nSample files in OUT_DIR:\n/kaggle/working/simsiam_task4 -> ['split_manifest.json', 'requirements.txt', 'simsiam_latest.pth', 'simsiam_encoder_memory.pth', 'manual_checkpoint_after_pretrain.pth', 'manifest.json', 'simsiam_encoder.pth']\n\nDONE: Download the file 'simsiam_task4_archive.zip' from the Kaggle notebook output files (right panel).\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Load Stage","metadata":{}},{"cell_type":"code","source":"# ====== Load & Restore (fixed for torch.load unpickling) ======\nimport os, json, shutil, torch, random, numpy as np\n\nARCHIVE_DIR = \"/kaggle/input/simsiam-task4-archive\"   # your extracted archive path\nOUT_DIR = \"/kaggle/working/simsiam_task4\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# Copy files from archive to OUT_DIR\nfor fname in os.listdir(ARCHIVE_DIR):\n    src = os.path.join(ARCHIVE_DIR, fname)\n    dst = os.path.join(OUT_DIR, fname)\n    if not os.path.exists(dst):\n        try:\n            shutil.copy(src, dst)\n        except:\n            pass\n\nprint(\"Copied archive files to:\", OUT_DIR)\n\n# Load manifests\nmanifest = None\nsplit_manifest = None\nif os.path.exists(os.path.join(OUT_DIR,\"manifest.json\")):\n    with open(os.path.join(OUT_DIR,\"manifest.json\"),\"r\") as f:\n        manifest = json.load(f)\nif os.path.exists(os.path.join(OUT_DIR,\"split_manifest.json\")):\n    with open(os.path.join(OUT_DIR,\"split_manifest.json\"),\"r\") as f:\n        split_manifest = json.load(f)\n\nprint(\"manifest loaded:\", bool(manifest), \"split_manifest loaded:\", bool(split_manifest))\n\n# Load manual checkpoint (FIXED)\nckpt_path = os.path.join(OUT_DIR, \"manual_checkpoint_after_pretrain.pth\")\nck = None\nif os.path.exists(ckpt_path):\n    print(\"Loading checkpoint with weights_only=False ...\")\n    ck = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n    print(\"Loaded checkpoint:\", ckpt_path)\n\n    # restore RNG states if present\n    try:\n        if \"py_random_state\" in ck: random.setstate(ck[\"py_random_state\"])\n        if \"np_random_state\" in ck: np.random.set_state(ck[\"np_random_state\"])\n        if \"torch_cpu_rng\" in ck: torch.set_rng_state(ck[\"torch_cpu_rng\"])\n        if torch.cuda.is_available() and \"torch_cuda_rng_all\" in ck:\n            try: torch.cuda.set_rng_state_all(ck[\"torch_cuda_rng_all\"])\n            except: pass\n    except Exception as e:\n        print(\"Warning restoring RNG:\", e)\nelse:\n    print(\"WARNING: Checkpoint not found:\", ckpt_path)\n\n# Load encoder checkpoint\nenc_ck = None\nfor p in [\n    os.path.join(OUT_DIR,\"simsiam_encoder_memory.pth\"),\n    os.path.join(OUT_DIR,\"simsiam_encoder.pth\")\n]:\n    if os.path.exists(p):\n        enc_ck = torch.load(p, map_location=\"cpu\", weights_only=False)\n        print(\"Loaded encoder:\", p)\n        break\n\nencoder = None\nif enc_ck is not None and \"SimSiam\" in globals():\n    try:\n        BACKBONE = globals().get(\"BACKBONE\", \"resnet18\")\n        model = SimSiam(backbone=BACKBONE)\n        model.encoder.load_state_dict(enc_ck[\"encoder_state_dict\"])\n        encoder = model.encoder\n        print(\"Encoder restored in memory.\")\n    except Exception as e:\n        print(\"Could not attach encoder to SimSiam model:\", e)\nelse:\n    print(\"Encoder available in enc_ck but SimSiam class not defined yet.\")\n\nglobals().update({\n    \"manifest\": manifest,\n    \"split_manifest\": split_manifest,\n    \"checkpoint_dict\": ck,\n    \"encoder_ck\": enc_ck,\n    \"encoder\": encoder\n})\n\nprint(\"\\nRestore summary:\")\nprint(\" manifest:\", bool(manifest))\nprint(\" split_manifest:\", bool(split_manifest))\nprint(\" checkpoint loaded:\", bool(ck))\nprint(\" encoder loaded:\", encoder is not None)\nprint(\"You can now continue from Cell 10.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:12:52.100232Z","iopub.execute_input":"2025-12-05T08:12:52.100760Z","iopub.status.idle":"2025-12-05T08:12:52.507945Z","shell.execute_reply.started":"2025-12-05T08:12:52.100739Z","shell.execute_reply":"2025-12-05T08:12:52.507233Z"}},"outputs":[{"name":"stdout","text":"Copied archive files to: /kaggle/working/simsiam_task4\nmanifest loaded: True split_manifest loaded: True\nLoading checkpoint with weights_only=False ...\nLoaded checkpoint: /kaggle/working/simsiam_task4/manual_checkpoint_after_pretrain.pth\nLoaded encoder: /kaggle/working/simsiam_task4/simsiam_encoder_memory.pth\nEncoder restored in memory.\n\nRestore summary:\n manifest: True\n split_manifest: True\n checkpoint loaded: True\n encoder loaded: True\nYou can now continue from Cell 10.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## 2nd Loader","metadata":{}},{"cell_type":"code","source":"# ====== Restore train/val/test splits from split_manifest.json ======\n\nimport json, os\n\nsplit_path = \"/kaggle/working/simsiam_task4/split_manifest.json\"\n\nwith open(split_path, \"r\") as f:\n    split = json.load(f)\n\ntrain_paths = split[\"train\"]\ntrain_labels = split[\"train_labels\"]\nval_paths   = split[\"val\"]\nval_labels  = split[\"val_labels\"]\ntest_paths  = split[\"test\"]\ntest_labels = split[\"test_labels\"]\n\nclasses = split[\"classes\"] if \"classes\" in split else [\"Diseased\", \"Dried\", \"Healthy\"]\n\nprint(\"Loaded splits:\")\nprint(\"Train:\", len(train_paths))\nprint(\"Val:\", len(val_paths))\nprint(\"Test:\", len(test_paths))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:13:03.094040Z","iopub.execute_input":"2025-12-05T08:13:03.094656Z","iopub.status.idle":"2025-12-05T08:13:03.102000Z","shell.execute_reply.started":"2025-12-05T08:13:03.094633Z","shell.execute_reply":"2025-12-05T08:13:03.101281Z"}},"outputs":[{"name":"stdout","text":"Loaded splits:\nTrain: 1296\nVal: 144\nTest: 360\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"CELL 10 — Feature extraction (frozen encoder) for downstream tasks","metadata":{}},{"cell_type":"code","source":"# =========================\n# Feature extraction using frozen encoder saved above.\n# Produces numpy files: train_feats.npy, val_feats.npy, test_feats.npy and corresponding label npys.\n# =========================\n\n# load encoder\nenc_ckpt = os.path.join(OUT_DIR, \"simsiam_encoder.pth\")\nif not os.path.exists(enc_ckpt):\n    # if we just trained in memory, use model.encoder; else load from file\n    if 'model' in globals() and hasattr(model, \"encoder\"):\n        encoder = model.encoder\n    else:\n        raise FileNotFoundError(\"Encoder checkpoint not found and model not in memory.\")\nelse:\n    d = torch.load(enc_ckpt, map_location=DEVICE)\n    encoder = SimSiam(backbone=BACKBONE).encoder  # dummy to get structure\n    encoder.load_state_dict(d[\"encoder_state_dict\"])\nencoder = encoder.to(DEVICE)\nencoder.eval()\n\n# helper to extract and save\ndef extract_and_save(paths_list, labels_list, split_name):\n    ds = ManifestDataset(paths_list, labels_list, eval_transform)\n    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n    feats = []\n    files = []\n    with torch.no_grad():\n        for imgs, lbls, ps in loader:\n            imgs = imgs.to(DEVICE)\n            h = encoder(imgs).view(imgs.size(0), -1).cpu().numpy()\n            feats.append(h)\n            files.extend(ps)\n    feats = np.vstack(feats)\n    np.save(os.path.join(OUT_DIR, f\"{split_name}_feats.npy\"), feats)\n    np.save(os.path.join(OUT_DIR, f\"{split_name}_labels.npy\"), np.array(labels_list))\n    print(f\"Saved {split_name} features: {feats.shape} to {OUT_DIR}/{split_name}_feats.npy\")\n    return feats\n\ntrain_feats = extract_and_save(train_paths, train_labels, \"train\")\nval_feats = extract_and_save(val_paths, val_labels, \"val\")\ntest_feats = extract_and_save(test_paths, test_labels, \"test\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:13:10.331716Z","iopub.execute_input":"2025-12-05T08:13:10.332070Z","iopub.status.idle":"2025-12-05T08:21:22.431694Z","shell.execute_reply.started":"2025-12-05T08:13:10.332037Z","shell.execute_reply":"2025-12-05T08:21:22.430877Z"}},"outputs":[{"name":"stdout","text":"Saved train features: (1296, 512) to /kaggle/working/simsiam_task4/train_feats.npy\nSaved val features: (144, 512) to /kaggle/working/simsiam_task4/val_feats.npy\nSaved test features: (360, 512) to /kaggle/working/simsiam_task4/test_feats.npy\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"CELL 11 — Linear probe + shallow heads evaluations (train classifiers on frozen features)","metadata":{}},{"cell_type":"code","source":"# =========================\n# Train linear probe and several shallow heads on frozen features.\n# Outputs models to OUT_DIR and prints metrics.\n# =========================\n\n# load feats if needed\ntrain_feats = np.load(os.path.join(OUT_DIR, \"train_feats.npy\"))\ntrain_lbls = np.load(os.path.join(OUT_DIR, \"train_labels.npy\"))\nval_feats = np.load(os.path.join(OUT_DIR, \"val_feats.npy\"))\nval_lbls = np.load(os.path.join(OUT_DIR, \"val_labels.npy\"))\ntest_feats = np.load(os.path.join(OUT_DIR, \"test_feats.npy\"))\ntest_lbls = np.load(os.path.join(OUT_DIR, \"test_labels.npy\"))\n\n# list of models to train\nclassifiers = {\n    \"LogisticRegression\": LogisticRegression(max_iter=2000),\n    \"SVM_RBF\": SVC(kernel=\"rbf\", probability=True),\n    \"RandomForest\": RandomForestClassifier(n_estimators=100),\n    \"DecisionTree\": DecisionTreeClassifier(),\n    \"MLP\": MLPClassifier(hidden_layer_sizes=(512,), max_iter=500)\n}\n\nresults = {}\nfor name, clf in classifiers.items():\n    print(\"Training:\", name)\n    clf.fit(train_feats, train_lbls)\n    val_pred = clf.predict(val_feats)\n    val_acc = accuracy_score(val_lbls, val_pred)\n    test_pred = clf.predict(test_feats)\n    test_acc = accuracy_score(test_lbls, test_pred)\n    print(f\" {name} val_acc: {val_acc:.4f} test_acc: {test_acc:.4f}\")\n    results[name] = {\"val_acc\": float(val_acc), \"test_acc\": float(test_acc)}\n    joblib.dump(clf, os.path.join(OUT_DIR, f\"{name}.joblib\"))\n\n# Save results summary\nwith open(os.path.join(OUT_DIR, \"probe_results.json\"), \"w\") as f:\n    json.dump(results, f, indent=2)\nprint(\"Probe results saved to\", os.path.join(OUT_DIR, \"probe_results.json\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:32:32.580678Z","iopub.execute_input":"2025-12-05T08:32:32.581415Z","iopub.status.idle":"2025-12-05T08:32:45.764310Z","shell.execute_reply.started":"2025-12-05T08:32:32.581384Z","shell.execute_reply":"2025-12-05T08:32:45.763236Z"}},"outputs":[{"name":"stdout","text":"Training: LogisticRegression\n LogisticRegression val_acc: 0.8333 test_acc: 0.8167\nTraining: SVM_RBF\n SVM_RBF val_acc: 0.7917 test_acc: 0.7806\nTraining: RandomForest\n RandomForest val_acc: 0.8403 test_acc: 0.7972\nTraining: DecisionTree\n DecisionTree val_acc: 0.7431 test_acc: 0.6778\nTraining: MLP\n MLP val_acc: 0.8750 test_acc: 0.8528\nProbe results saved to /kaggle/working/simsiam_task4/probe_results.json\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# =========================\n# Full fine-tune: build a classifier that uses the encoder and a linear head; unfreeze encoder\n# Trains for FINETUNE_EPOCHS and saves best checkpoint by val accuracy.\n# =========================\n\n# =========================\n# Cell 12 (REPLACED) — Full fine-tune with safe DataLoader, resume support, and interrupt handling\n# Replace the original Cell 12 with this cell. It:\n# - uses num_workers=0 to avoid worker hang after restoring\n# - uses pin_memory when CUDA available\n# - supports resuming from finetune_resume.pth or finetune_best.pth\n# - periodically saves a resume checkpoint and best checkpoint\n# - saves when KeyboardInterrupt is caught so you can continue later\n# =========================\n\nimport os\nimport torch\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n\n# --- Configurable small settings for stability ---\nft_num_workers = 0                      # Recommended 0 for Kaggle / resume stability\npin_memory = True if torch.cuda.is_available() else False\nresume_ckpt_path = os.path.join(OUT_DIR, \"finetune_resume.pth\")\nbest_ckpt_path = os.path.join(OUT_DIR, \"finetune_best.pth\")\nsave_every_epoch = True                 # set False to save only best\n\n# --- Recreate / ensure encoder is loaded ---\n# If encoder variable not present but encoder checkpoint file exists, load it.\nif 'encoder' not in globals() or encoder is None:\n    enc_candidates = [\n        os.path.join(OUT_DIR, \"simsiam_encoder_memory.pth\"),\n        os.path.join(OUT_DIR, \"simsiam_encoder.pth\")\n    ]\n    found = None\n    for p in enc_candidates:\n        if os.path.exists(p):\n            found = p\n            break\n    if found is None:\n        raise FileNotFoundError(\"Encoder checkpoint not found in OUT_DIR. Run pretraining or restore archive.\")\n    enc_ck = torch.load(found, map_location=\"cpu\", weights_only=False)\n    # build a SimSiam model to host the encoder (SimSiam class must be defined in the notebook)\n    BACKBONE = globals().get(\"BACKBONE\", \"resnet18\")\n    tmp_model = SimSiam(backbone=BACKBONE)\n    tmp_model.encoder.load_state_dict(enc_ck[\"encoder_state_dict\"])\n    encoder = tmp_model.encoder\n    del tmp_model\n\n# Put encoder on device\nencoder = encoder.to(DEVICE)\n\n# --- Build fine-tune model wrapper ---\nclass FineTuneClassifier(nn.Module):\n    def __init__(self, encoder, feat_dim, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(feat_dim, num_classes)\n\n    def forward(self, x):\n        h = self.encoder(x).view(x.size(0), -1)\n        return self.head(h)\n\n# Determine feature dim from encoder output\n# Forward a dummy tensor to compute feat_dim robustly (safe)\nencoder.eval()\nwith torch.no_grad():\n    dummy = torch.zeros(1, 3, RESOLUTION, RESOLUTION).to(DEVICE)\n    try:\n        out = encoder(dummy).view(1, -1)\n        feat_dim = out.shape[1]\n    except Exception:\n        # fallback to known dims\n        feat_dim = 512 if BACKBONE == \"resnet18\" else 2048\n\nnum_classes = len(classes)\nft_model = FineTuneClassifier(encoder, feat_dim, num_classes).to(DEVICE)\n\n# --- Fine-tune dataset & loaders (use mild augment on train) ---\nft_train_transform = transforms.Compose([\n    transforms.Resize(int(RESOLUTION*1.1)),\n    transforms.CenterCrop(RESOLUTION),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\nft_train_ds = ManifestDataset(train_paths, train_labels, ft_train_transform)\nft_val_ds = ManifestDataset(val_paths, val_labels, eval_transform)\n\nft_train_loader = DataLoader(ft_train_ds, batch_size=BATCH_SIZE, shuffle=True,\n                             num_workers=ft_num_workers, pin_memory=pin_memory)\nft_val_loader   = DataLoader(ft_val_ds,  batch_size=BATCH_SIZE, shuffle=False,\n                             num_workers=ft_num_workers, pin_memory=pin_memory)\n\n# --- Optimizer / scheduler / loss ---\nft_optimizer = optim.SGD(ft_model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\nft_scheduler = optim.lr_scheduler.StepLR(ft_optimizer, step_size=15, gamma=0.1)\ncriterion = nn.CrossEntropyLoss()\n\n# --- Resume if possible ---\nstart_epoch = 0\nbest_val_acc = 0.0\nif os.path.exists(resume_ckpt_path):\n    try:\n        ck = torch.load(resume_ckpt_path, map_location=DEVICE, weights_only=False)\n        ft_model.load_state_dict(ck[\"model_state\"])\n        ft_optimizer.load_state_dict(ck[\"optimizer_state\"])\n        if \"scheduler_state\" in ck:\n            try:\n                ft_scheduler.load_state_dict(ck[\"scheduler_state\"])\n            except Exception:\n                pass\n        start_epoch = ck.get(\"epoch\", 0) + 1\n        best_val_acc = ck.get(\"val_acc\", 0.0)\n        print(f\"Resumed fine-tune from resume checkpoint at epoch {start_epoch} (best val {best_val_acc:.4f})\")\n    except Exception as e:\n        print(\"Could not resume from resume checkpoint:\", e)\n\n# If no resume but best exists, you may optionally load best as init\nelif os.path.exists(best_ckpt_path):\n    try:\n        ck = torch.load(best_ckpt_path, map_location=DEVICE, weights_only=False)\n        ft_model.load_state_dict(ck[\"model_state\"])\n        best_val_acc = ck.get(\"val_acc\", 0.0)\n        print(\"Initialized fine-tune from best checkpoint (val_acc={:.4f})\".format(best_val_acc))\n    except Exception as e:\n        print(\"Could not load best checkpoint as init:\", e)\n\n# --- Main fine-tune loop with safe saving & interrupt handling ---\ntry:\n    for epoch in range(start_epoch, FINETUNE_EPOCHS):\n        ft_model.train()\n        losses = []\n        loop = tqdm(ft_train_loader, desc=f\"Fine-tune Epoch {epoch+1}/{FINETUNE_EPOCHS}\")\n        for imgs, labels_batch, _ in loop:\n            imgs = imgs.to(DEVICE, non_blocking=pin_memory)\n            labels_batch = labels_batch.to(DEVICE, non_blocking=pin_memory)\n            logits = ft_model(imgs)\n            loss = criterion(logits, labels_batch)\n            ft_optimizer.zero_grad()\n            loss.backward()\n            ft_optimizer.step()\n            losses.append(loss.item())\n            loop.set_postfix(train_loss=f\"{np.mean(losses):.4f}\")\n\n        ft_scheduler.step()\n\n        # Validation\n        ft_model.eval()\n        all_preds = []\n        all_labels = []\n        with torch.no_grad():\n            for imgs, labels_batch, _ in ft_val_loader:\n                imgs = imgs.to(DEVICE, non_blocking=pin_memory)\n                logits = ft_model(imgs)\n                preds = logits.argmax(dim=1).cpu().numpy()\n                all_preds.extend(preds)\n                all_labels.extend(labels_batch.numpy())\n        val_acc = accuracy_score(all_labels, all_preds)\n        print(f\"Fine-tune Epoch {epoch+1}/{FINETUNE_EPOCHS} - train_loss: {np.mean(losses):.4f} val_acc: {val_acc:.4f}\")\n\n        # Save best\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save({\n                \"epoch\": epoch,\n                \"model_state\": ft_model.state_dict(),\n                \"optimizer_state\": ft_optimizer.state_dict(),\n                \"val_acc\": val_acc\n            }, best_ckpt_path)\n            print(\"Saved best fine-tune checkpoint:\", best_ckpt_path)\n\n        # Periodic resume checkpoint\n        if save_every_epoch:\n            torch.save({\n                \"epoch\": epoch,\n                \"model_state\": ft_model.state_dict(),\n                \"optimizer_state\": ft_optimizer.state_dict(),\n                \"scheduler_state\": ft_scheduler.state_dict(),\n                \"val_acc\": val_acc\n            }, resume_ckpt_path)\n\nexcept KeyboardInterrupt:\n    # Save resume checkpoint on interrupt so you can continue later\n    print(\"KeyboardInterrupt caught — saving resume checkpoint...\")\n    torch.save({\n        \"epoch\": epoch,\n        \"model_state\": ft_model.state_dict(),\n        \"optimizer_state\": ft_optimizer.state_dict(),\n        \"scheduler_state\": ft_scheduler.state_dict(),\n        \"val_acc\": best_val_acc\n    }, resume_ckpt_path)\n    print(\"Saved resume checkpoint to\", resume_ckpt_path)\n    raise\n\nprint(\"Fine-tune complete. Best val acc:\", best_val_acc)\n# End of replaced Cell 12\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:32:52.754629Z","iopub.execute_input":"2025-12-05T08:32:52.754937Z","iopub.status.idle":"2025-12-05T18:20:22.864082Z","shell.execute_reply.started":"2025-12-05T08:32:52.754915Z","shell.execute_reply":"2025-12-05T18:20:22.863222Z"}},"outputs":[{"name":"stderr","text":"Fine-tune Epoch 1/50: 100%|██████████| 21/21 [10:33<00:00, 30.17s/it, train_loss=0.8706]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 1/50 - train_loss: 0.8706 val_acc: 0.3889\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 2/50: 100%|██████████| 21/21 [10:34<00:00, 30.23s/it, train_loss=0.6193]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 2/50 - train_loss: 0.6193 val_acc: 0.5694\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 3/50: 100%|██████████| 21/21 [10:30<00:00, 30.02s/it, train_loss=0.7477]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 3/50 - train_loss: 0.7477 val_acc: 0.7431\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 4/50: 100%|██████████| 21/21 [10:27<00:00, 29.87s/it, train_loss=0.4576]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 4/50 - train_loss: 0.4576 val_acc: 0.7778\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 5/50: 100%|██████████| 21/21 [10:29<00:00, 29.98s/it, train_loss=0.4598]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 5/50 - train_loss: 0.4598 val_acc: 0.8681\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 6/50: 100%|██████████| 21/21 [10:29<00:00, 29.97s/it, train_loss=0.3948]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 6/50 - train_loss: 0.3948 val_acc: 0.8611\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 7/50: 100%|██████████| 21/21 [10:37<00:00, 30.33s/it, train_loss=0.3207]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 7/50 - train_loss: 0.3207 val_acc: 0.6250\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 8/50: 100%|██████████| 21/21 [10:31<00:00, 30.07s/it, train_loss=0.3516]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 8/50 - train_loss: 0.3516 val_acc: 0.8958\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 9/50: 100%|██████████| 21/21 [10:33<00:00, 30.19s/it, train_loss=0.3168]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 9/50 - train_loss: 0.3168 val_acc: 0.8681\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 10/50: 100%|██████████| 21/21 [10:34<00:00, 30.19s/it, train_loss=0.2560]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 10/50 - train_loss: 0.2560 val_acc: 0.8611\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 11/50: 100%|██████████| 21/21 [10:39<00:00, 30.45s/it, train_loss=0.2551]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 11/50 - train_loss: 0.2551 val_acc: 0.8889\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 12/50: 100%|██████████| 21/21 [10:44<00:00, 30.70s/it, train_loss=0.2649]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 12/50 - train_loss: 0.2649 val_acc: 0.8611\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 13/50: 100%|██████████| 21/21 [10:29<00:00, 29.99s/it, train_loss=0.2212]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 13/50 - train_loss: 0.2212 val_acc: 0.8819\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 14/50: 100%|██████████| 21/21 [10:25<00:00, 29.77s/it, train_loss=0.2540]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 14/50 - train_loss: 0.2540 val_acc: 0.8194\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 15/50: 100%|██████████| 21/21 [10:26<00:00, 29.85s/it, train_loss=0.2133]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 15/50 - train_loss: 0.2133 val_acc: 0.8889\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 16/50: 100%|██████████| 21/21 [10:37<00:00, 30.38s/it, train_loss=0.1158]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 16/50 - train_loss: 0.1158 val_acc: 0.9236\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 17/50: 100%|██████████| 21/21 [10:22<00:00, 29.66s/it, train_loss=0.0835]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 17/50 - train_loss: 0.0835 val_acc: 0.9306\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 18/50: 100%|██████████| 21/21 [10:35<00:00, 30.26s/it, train_loss=0.0748]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 18/50 - train_loss: 0.0748 val_acc: 0.9375\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 19/50: 100%|██████████| 21/21 [10:25<00:00, 29.78s/it, train_loss=0.0656]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 19/50 - train_loss: 0.0656 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 20/50: 100%|██████████| 21/21 [10:23<00:00, 29.68s/it, train_loss=0.0606]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 20/50 - train_loss: 0.0606 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 21/50: 100%|██████████| 21/21 [10:29<00:00, 29.99s/it, train_loss=0.0553]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 21/50 - train_loss: 0.0553 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 22/50: 100%|██████████| 21/21 [10:24<00:00, 29.73s/it, train_loss=0.0635]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 22/50 - train_loss: 0.0635 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 23/50: 100%|██████████| 21/21 [10:28<00:00, 29.93s/it, train_loss=0.0465]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 23/50 - train_loss: 0.0465 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 24/50: 100%|██████████| 21/21 [10:34<00:00, 30.22s/it, train_loss=0.0815]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 24/50 - train_loss: 0.0815 val_acc: 0.9236\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 25/50: 100%|██████████| 21/21 [10:33<00:00, 30.15s/it, train_loss=0.0767]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 25/50 - train_loss: 0.0767 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 26/50: 100%|██████████| 21/21 [10:25<00:00, 29.81s/it, train_loss=0.0469]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 26/50 - train_loss: 0.0469 val_acc: 0.9444\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 27/50: 100%|██████████| 21/21 [10:33<00:00, 30.17s/it, train_loss=0.0623]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 27/50 - train_loss: 0.0623 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 28/50: 100%|██████████| 21/21 [10:34<00:00, 30.24s/it, train_loss=0.0466]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 28/50 - train_loss: 0.0466 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 29/50: 100%|██████████| 21/21 [10:31<00:00, 30.08s/it, train_loss=0.0395]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 29/50 - train_loss: 0.0395 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 30/50: 100%|██████████| 21/21 [10:35<00:00, 30.24s/it, train_loss=0.0448]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 30/50 - train_loss: 0.0448 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 31/50: 100%|██████████| 21/21 [10:38<00:00, 30.40s/it, train_loss=0.0296]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 31/50 - train_loss: 0.0296 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 32/50: 100%|██████████| 21/21 [10:43<00:00, 30.64s/it, train_loss=0.0322]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 32/50 - train_loss: 0.0322 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 33/50: 100%|██████████| 21/21 [10:29<00:00, 29.96s/it, train_loss=0.0306]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 33/50 - train_loss: 0.0306 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 34/50: 100%|██████████| 21/21 [10:34<00:00, 30.20s/it, train_loss=0.0329]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 34/50 - train_loss: 0.0329 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 35/50: 100%|██████████| 21/21 [10:33<00:00, 30.17s/it, train_loss=0.0472]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 35/50 - train_loss: 0.0472 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 36/50: 100%|██████████| 21/21 [10:37<00:00, 30.38s/it, train_loss=0.0243]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 36/50 - train_loss: 0.0243 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 37/50: 100%|██████████| 21/21 [10:33<00:00, 30.15s/it, train_loss=0.0286]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 37/50 - train_loss: 0.0286 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 38/50: 100%|██████████| 21/21 [10:38<00:00, 30.40s/it, train_loss=0.0308]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 38/50 - train_loss: 0.0308 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 39/50: 100%|██████████| 21/21 [10:33<00:00, 30.15s/it, train_loss=0.0283]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 39/50 - train_loss: 0.0283 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 40/50: 100%|██████████| 21/21 [10:43<00:00, 30.66s/it, train_loss=0.0349]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 40/50 - train_loss: 0.0349 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 41/50: 100%|██████████| 21/21 [10:31<00:00, 30.06s/it, train_loss=0.0262]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 41/50 - train_loss: 0.0262 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 42/50: 100%|██████████| 21/21 [10:40<00:00, 30.52s/it, train_loss=0.0232]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 42/50 - train_loss: 0.0232 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 43/50: 100%|██████████| 21/21 [10:38<00:00, 30.38s/it, train_loss=0.0282]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 43/50 - train_loss: 0.0282 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 44/50: 100%|██████████| 21/21 [10:30<00:00, 30.01s/it, train_loss=0.0302]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 44/50 - train_loss: 0.0302 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 45/50: 100%|██████████| 21/21 [10:23<00:00, 29.69s/it, train_loss=0.0270]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 45/50 - train_loss: 0.0270 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 46/50: 100%|██████████| 21/21 [10:35<00:00, 30.27s/it, train_loss=0.0399]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 46/50 - train_loss: 0.0399 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 47/50: 100%|██████████| 21/21 [10:31<00:00, 30.05s/it, train_loss=0.0271]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 47/50 - train_loss: 0.0271 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 48/50: 100%|██████████| 21/21 [10:33<00:00, 30.19s/it, train_loss=0.0240]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 48/50 - train_loss: 0.0240 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 49/50: 100%|██████████| 21/21 [10:40<00:00, 30.49s/it, train_loss=0.0271]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 49/50 - train_loss: 0.0271 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 50/50: 100%|██████████| 21/21 [10:31<00:00, 30.09s/it, train_loss=0.0240]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 50/50 - train_loss: 0.0240 val_acc: 0.9375\nFine-tune complete. Best val acc: 0.9444444444444444\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"CELL 12 — Full fine-tune: attach classification head and fine-tune entire encoder","metadata":{}},{"cell_type":"code","source":"# =========================\n# Full fine-tune: build a classifier that uses the encoder and a linear head; unfreeze encoder\n# Trains for FINETUNE_EPOCHS and saves best checkpoint by val accuracy.\n# =========================\n\n# =========================\n# Cell 12 (REPLACED) — Full fine-tune with safe DataLoader, resume support, and interrupt handling\n# Replace the original Cell 12 with this cell. It:\n# - uses num_workers=0 to avoid worker hang after restoring\n# - uses pin_memory when CUDA available\n# - supports resuming from finetune_resume.pth or finetune_best.pth\n# - periodically saves a resume checkpoint and best checkpoint\n# - saves when KeyboardInterrupt is caught so you can continue later\n# =========================\n\nimport os\nimport torch\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n\n# --- Configurable small settings for stability ---\nft_num_workers = 0                      # Recommended 0 for Kaggle / resume stability\npin_memory = True if torch.cuda.is_available() else False\nresume_ckpt_path = os.path.join(OUT_DIR, \"finetune_resume.pth\")\nbest_ckpt_path = os.path.join(OUT_DIR, \"finetune_best.pth\")\nsave_every_epoch = True                 # set False to save only best\n\n# --- Recreate / ensure encoder is loaded ---\n# If encoder variable not present but encoder checkpoint file exists, load it.\nif 'encoder' not in globals() or encoder is None:\n    enc_candidates = [\n        os.path.join(OUT_DIR, \"simsiam_encoder_memory.pth\"),\n        os.path.join(OUT_DIR, \"simsiam_encoder.pth\")\n    ]\n    found = None\n    for p in enc_candidates:\n        if os.path.exists(p):\n            found = p\n            break\n    if found is None:\n        raise FileNotFoundError(\"Encoder checkpoint not found in OUT_DIR. Run pretraining or restore archive.\")\n    enc_ck = torch.load(found, map_location=\"cpu\", weights_only=False)\n    # build a SimSiam model to host the encoder (SimSiam class must be defined in the notebook)\n    BACKBONE = globals().get(\"BACKBONE\", \"resnet18\")\n    tmp_model = SimSiam(backbone=BACKBONE)\n    tmp_model.encoder.load_state_dict(enc_ck[\"encoder_state_dict\"])\n    encoder = tmp_model.encoder\n    del tmp_model\n\n# Put encoder on device\nencoder = encoder.to(DEVICE)\n\n# --- Build fine-tune model wrapper ---\nclass FineTuneClassifier(nn.Module):\n    def __init__(self, encoder, feat_dim, num_classes):\n        super().__init__()\n        self.encoder = encoder\n        self.head = nn.Linear(feat_dim, num_classes)\n\n    def forward(self, x):\n        h = self.encoder(x).view(x.size(0), -1)\n        return self.head(h)\n\n# Determine feature dim from encoder output\n# Forward a dummy tensor to compute feat_dim robustly (safe)\nencoder.eval()\nwith torch.no_grad():\n    dummy = torch.zeros(1, 3, RESOLUTION, RESOLUTION).to(DEVICE)\n    try:\n        out = encoder(dummy).view(1, -1)\n        feat_dim = out.shape[1]\n    except Exception:\n        # fallback to known dims\n        feat_dim = 512 if BACKBONE == \"resnet18\" else 2048\n\nnum_classes = len(classes)\nft_model = FineTuneClassifier(encoder, feat_dim, num_classes).to(DEVICE)\n\n# --- Fine-tune dataset & loaders (use mild augment on train) ---\nft_train_transform = transforms.Compose([\n    transforms.Resize(int(RESOLUTION*1.1)),\n    transforms.CenterCrop(RESOLUTION),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\nft_train_ds = ManifestDataset(train_paths, train_labels, ft_train_transform)\nft_val_ds = ManifestDataset(val_paths, val_labels, eval_transform)\n\nft_train_loader = DataLoader(ft_train_ds, batch_size=BATCH_SIZE, shuffle=True,\n                             num_workers=ft_num_workers, pin_memory=pin_memory)\nft_val_loader   = DataLoader(ft_val_ds,  batch_size=BATCH_SIZE, shuffle=False,\n                             num_workers=ft_num_workers, pin_memory=pin_memory)\n\n# --- Optimizer / scheduler / loss ---\nft_optimizer = optim.SGD(ft_model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\nft_scheduler = optim.lr_scheduler.StepLR(ft_optimizer, step_size=15, gamma=0.1)\ncriterion = nn.CrossEntropyLoss()\n\n# --- Resume if possible ---\nstart_epoch = 0\nbest_val_acc = 0.0\nif os.path.exists(resume_ckpt_path):\n    try:\n        ck = torch.load(resume_ckpt_path, map_location=DEVICE, weights_only=False)\n        ft_model.load_state_dict(ck[\"model_state\"])\n        ft_optimizer.load_state_dict(ck[\"optimizer_state\"])\n        if \"scheduler_state\" in ck:\n            try:\n                ft_scheduler.load_state_dict(ck[\"scheduler_state\"])\n            except Exception:\n                pass\n        start_epoch = ck.get(\"epoch\", 0) + 1\n        best_val_acc = ck.get(\"val_acc\", 0.0)\n        print(f\"Resumed fine-tune from resume checkpoint at epoch {start_epoch} (best val {best_val_acc:.4f})\")\n    except Exception as e:\n        print(\"Could not resume from resume checkpoint:\", e)\n\n# If no resume but best exists, you may optionally load best as init\nelif os.path.exists(best_ckpt_path):\n    try:\n        ck = torch.load(best_ckpt_path, map_location=DEVICE, weights_only=False)\n        ft_model.load_state_dict(ck[\"model_state\"])\n        best_val_acc = ck.get(\"val_acc\", 0.0)\n        print(\"Initialized fine-tune from best checkpoint (val_acc={:.4f})\".format(best_val_acc))\n    except Exception as e:\n        print(\"Could not load best checkpoint as init:\", e)\n\n# --- Main fine-tune loop with safe saving & interrupt handling ---\ntry:\n    for epoch in range(start_epoch, FINETUNE_EPOCHS):\n        ft_model.train()\n        losses = []\n        loop = tqdm(ft_train_loader, desc=f\"Fine-tune Epoch {epoch+1}/{FINETUNE_EPOCHS}\")\n        for imgs, labels_batch, _ in loop:\n            imgs = imgs.to(DEVICE, non_blocking=pin_memory)\n            labels_batch = labels_batch.to(DEVICE, non_blocking=pin_memory)\n            logits = ft_model(imgs)\n            loss = criterion(logits, labels_batch)\n            ft_optimizer.zero_grad()\n            loss.backward()\n            ft_optimizer.step()\n            losses.append(loss.item())\n            loop.set_postfix(train_loss=f\"{np.mean(losses):.4f}\")\n\n        ft_scheduler.step()\n\n        # Validation\n        ft_model.eval()\n        all_preds = []\n        all_labels = []\n        with torch.no_grad():\n            for imgs, labels_batch, _ in ft_val_loader:\n                imgs = imgs.to(DEVICE, non_blocking=pin_memory)\n                logits = ft_model(imgs)\n                preds = logits.argmax(dim=1).cpu().numpy()\n                all_preds.extend(preds)\n                all_labels.extend(labels_batch.numpy())\n        val_acc = accuracy_score(all_labels, all_preds)\n        print(f\"Fine-tune Epoch {epoch+1}/{FINETUNE_EPOCHS} - train_loss: {np.mean(losses):.4f} val_acc: {val_acc:.4f}\")\n\n        # Save best\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save({\n                \"epoch\": epoch,\n                \"model_state\": ft_model.state_dict(),\n                \"optimizer_state\": ft_optimizer.state_dict(),\n                \"val_acc\": val_acc\n            }, best_ckpt_path)\n            print(\"Saved best fine-tune checkpoint:\", best_ckpt_path)\n\n        # Periodic resume checkpoint\n        if save_every_epoch:\n            torch.save({\n                \"epoch\": epoch,\n                \"model_state\": ft_model.state_dict(),\n                \"optimizer_state\": ft_optimizer.state_dict(),\n                \"scheduler_state\": ft_scheduler.state_dict(),\n                \"val_acc\": val_acc\n            }, resume_ckpt_path)\n\nexcept KeyboardInterrupt:\n    # Save resume checkpoint on interrupt so you can continue later\n    print(\"KeyboardInterrupt caught — saving resume checkpoint...\")\n    torch.save({\n        \"epoch\": epoch,\n        \"model_state\": ft_model.state_dict(),\n        \"optimizer_state\": ft_optimizer.state_dict(),\n        \"scheduler_state\": ft_scheduler.state_dict(),\n        \"val_acc\": best_val_acc\n    }, resume_ckpt_path)\n    print(\"Saved resume checkpoint to\", resume_ckpt_path)\n    raise\n\nprint(\"Fine-tune complete. Best val acc:\", best_val_acc)\n# End of replaced Cell 12\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T02:17:17.601020Z","iopub.execute_input":"2025-11-27T02:17:17.601351Z","iopub.status.idle":"2025-11-27T12:09:11.346078Z","shell.execute_reply.started":"2025-11-27T02:17:17.601329Z","shell.execute_reply":"2025-11-27T12:09:11.345255Z"}},"outputs":[{"name":"stderr","text":"Fine-tune Epoch 1/50: 100%|██████████| 21/21 [10:45<00:00, 30.75s/it, train_loss=0.8789]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 1/50 - train_loss: 0.8789 val_acc: 0.6875\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 2/50: 100%|██████████| 21/21 [10:31<00:00, 30.05s/it, train_loss=0.5919]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 2/50 - train_loss: 0.5919 val_acc: 0.7222\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 3/50: 100%|██████████| 21/21 [10:14<00:00, 29.26s/it, train_loss=0.7003]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 3/50 - train_loss: 0.7003 val_acc: 0.6181\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 4/50: 100%|██████████| 21/21 [10:24<00:00, 29.72s/it, train_loss=0.5374]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 4/50 - train_loss: 0.5374 val_acc: 0.7222\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 5/50: 100%|██████████| 21/21 [10:24<00:00, 29.72s/it, train_loss=0.5268]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 5/50 - train_loss: 0.5268 val_acc: 0.5972\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 6/50: 100%|██████████| 21/21 [10:42<00:00, 30.62s/it, train_loss=0.4216]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 6/50 - train_loss: 0.4216 val_acc: 0.8542\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 7/50: 100%|██████████| 21/21 [10:35<00:00, 30.27s/it, train_loss=0.3410]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 7/50 - train_loss: 0.3410 val_acc: 0.7153\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 8/50: 100%|██████████| 21/21 [10:36<00:00, 30.31s/it, train_loss=0.3464]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 8/50 - train_loss: 0.3464 val_acc: 0.8750\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 9/50: 100%|██████████| 21/21 [10:36<00:00, 30.33s/it, train_loss=0.3185]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 9/50 - train_loss: 0.3185 val_acc: 0.8889\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 10/50: 100%|██████████| 21/21 [10:39<00:00, 30.45s/it, train_loss=0.2622]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 10/50 - train_loss: 0.2622 val_acc: 0.7569\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 11/50: 100%|██████████| 21/21 [10:55<00:00, 31.20s/it, train_loss=0.2276]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 11/50 - train_loss: 0.2276 val_acc: 0.8403\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 12/50: 100%|██████████| 21/21 [10:50<00:00, 30.98s/it, train_loss=0.2587]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 12/50 - train_loss: 0.2587 val_acc: 0.8958\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 13/50: 100%|██████████| 21/21 [10:53<00:00, 31.12s/it, train_loss=0.2122]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 13/50 - train_loss: 0.2122 val_acc: 0.9444\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 14/50: 100%|██████████| 21/21 [10:56<00:00, 31.27s/it, train_loss=0.2195]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 14/50 - train_loss: 0.2195 val_acc: 0.8958\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 15/50: 100%|██████████| 21/21 [10:37<00:00, 30.35s/it, train_loss=0.2529]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 15/50 - train_loss: 0.2529 val_acc: 0.8958\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 16/50: 100%|██████████| 21/21 [10:32<00:00, 30.14s/it, train_loss=0.1418]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 16/50 - train_loss: 0.1418 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 17/50: 100%|██████████| 21/21 [10:21<00:00, 29.59s/it, train_loss=0.1043]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 17/50 - train_loss: 0.1043 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 18/50: 100%|██████████| 21/21 [10:42<00:00, 30.59s/it, train_loss=0.0951]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 18/50 - train_loss: 0.0951 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 19/50: 100%|██████████| 21/21 [10:38<00:00, 30.40s/it, train_loss=0.0772]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 19/50 - train_loss: 0.0772 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 20/50: 100%|██████████| 21/21 [10:37<00:00, 30.38s/it, train_loss=0.0750]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 20/50 - train_loss: 0.0750 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 21/50: 100%|██████████| 21/21 [10:37<00:00, 30.36s/it, train_loss=0.0699]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 21/50 - train_loss: 0.0699 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 22/50: 100%|██████████| 21/21 [10:29<00:00, 29.96s/it, train_loss=0.0748]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 22/50 - train_loss: 0.0748 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 23/50: 100%|██████████| 21/21 [10:29<00:00, 29.96s/it, train_loss=0.0591]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 23/50 - train_loss: 0.0591 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 24/50: 100%|██████████| 21/21 [10:49<00:00, 30.93s/it, train_loss=0.0852]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 24/50 - train_loss: 0.0852 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 25/50: 100%|██████████| 21/21 [10:32<00:00, 30.10s/it, train_loss=0.0999]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 25/50 - train_loss: 0.0999 val_acc: 0.9306\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 26/50: 100%|██████████| 21/21 [10:40<00:00, 30.49s/it, train_loss=0.0599]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 26/50 - train_loss: 0.0599 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 27/50: 100%|██████████| 21/21 [10:29<00:00, 29.97s/it, train_loss=0.0674]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 27/50 - train_loss: 0.0674 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 28/50: 100%|██████████| 21/21 [10:29<00:00, 29.98s/it, train_loss=0.0546]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 28/50 - train_loss: 0.0546 val_acc: 0.9514\nSaved best fine-tune checkpoint: /kaggle/working/simsiam_task4/finetune_best.pth\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 29/50: 100%|██████████| 21/21 [10:31<00:00, 30.06s/it, train_loss=0.0487]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 29/50 - train_loss: 0.0487 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 30/50: 100%|██████████| 21/21 [10:39<00:00, 30.45s/it, train_loss=0.0500]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 30/50 - train_loss: 0.0500 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 31/50: 100%|██████████| 21/21 [10:39<00:00, 30.43s/it, train_loss=0.0388]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 31/50 - train_loss: 0.0388 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 32/50: 100%|██████████| 21/21 [10:43<00:00, 30.62s/it, train_loss=0.0415]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 32/50 - train_loss: 0.0415 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 33/50: 100%|██████████| 21/21 [10:45<00:00, 30.74s/it, train_loss=0.0404]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 33/50 - train_loss: 0.0404 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 34/50: 100%|██████████| 21/21 [10:38<00:00, 30.39s/it, train_loss=0.0412]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 34/50 - train_loss: 0.0412 val_acc: 0.9236\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 35/50: 100%|██████████| 21/21 [10:38<00:00, 30.39s/it, train_loss=0.0595]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 35/50 - train_loss: 0.0595 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 36/50: 100%|██████████| 21/21 [10:49<00:00, 30.91s/it, train_loss=0.0339]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 36/50 - train_loss: 0.0339 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 37/50: 100%|██████████| 21/21 [10:48<00:00, 30.90s/it, train_loss=0.0386]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 37/50 - train_loss: 0.0386 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 38/50: 100%|██████████| 21/21 [10:33<00:00, 30.17s/it, train_loss=0.0415]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 38/50 - train_loss: 0.0415 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 39/50: 100%|██████████| 21/21 [10:24<00:00, 29.73s/it, train_loss=0.0358]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 39/50 - train_loss: 0.0358 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 40/50: 100%|██████████| 21/21 [10:46<00:00, 30.78s/it, train_loss=0.0500]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 40/50 - train_loss: 0.0500 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 41/50: 100%|██████████| 21/21 [10:43<00:00, 30.64s/it, train_loss=0.0360]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 41/50 - train_loss: 0.0360 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 42/50: 100%|██████████| 21/21 [10:36<00:00, 30.30s/it, train_loss=0.0315]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 42/50 - train_loss: 0.0315 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 43/50: 100%|██████████| 21/21 [10:34<00:00, 30.20s/it, train_loss=0.0389]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 43/50 - train_loss: 0.0389 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 44/50: 100%|██████████| 21/21 [10:45<00:00, 30.76s/it, train_loss=0.0408]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 44/50 - train_loss: 0.0408 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 45/50: 100%|██████████| 21/21 [10:38<00:00, 30.43s/it, train_loss=0.0409]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 45/50 - train_loss: 0.0409 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 46/50: 100%|██████████| 21/21 [10:36<00:00, 30.32s/it, train_loss=0.0494]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 46/50 - train_loss: 0.0494 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 47/50: 100%|██████████| 21/21 [10:39<00:00, 30.43s/it, train_loss=0.0380]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 47/50 - train_loss: 0.0380 val_acc: 0.9444\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 48/50: 100%|██████████| 21/21 [10:39<00:00, 30.45s/it, train_loss=0.0347]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 48/50 - train_loss: 0.0347 val_acc: 0.9514\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 49/50: 100%|██████████| 21/21 [10:33<00:00, 30.18s/it, train_loss=0.0328]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 49/50 - train_loss: 0.0328 val_acc: 0.9375\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch 50/50: 100%|██████████| 21/21 [10:39<00:00, 30.45s/it, train_loss=0.0322]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Epoch 50/50 - train_loss: 0.0322 val_acc: 0.9375\nFine-tune complete. Best val acc: 0.9513888888888888\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Save File","metadata":{}},{"cell_type":"code","source":"# ===== Save All (run after Cell 12) =====\nimport os, time, json, sys, shutil, torch, random, numpy as np, subprocess\n\nOUT_DIR = \"/kaggle/working/simsiam_task4\"   # same working folder used across notebook\nARCHIVE = \"/kaggle/working/simsiam_cell12_allsave.zip\"\n\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# 1) Save manual checkpoint including RNG and manifests\ntry:\n    ck = {\n        \"timestamp\": time.time(),\n        \"python_version\": sys.version,\n        \"manifest\": globals().get(\"manifest\", None),\n        \"split_manifest\": globals().get(\"split_manifest\", None),\n        \"seed\": globals().get(\"SEED\", None),\n    }\n    if \"model\" in globals():\n        try: ck[\"model_state\"] = model.state_dict()\n        except Exception: pass\n    if \"optimizer\" in globals():\n        try: ck[\"optimizer_state\"] = optimizer.state_dict()\n        except Exception: pass\n    if \"scheduler\" in globals():\n        try: ck[\"scheduler_state\"] = scheduler.state_dict()\n        except Exception: pass\n\n    # last epoch info if present\n    ck[\"last_epoch_pretrain\"] = globals().get(\"start_epoch\", None)\n    ck[\"last_epoch_finetune\"] = globals().get(\"epoch\", None)\n\n    # RNG states\n    ck[\"py_random_state\"] = random.getstate()\n    ck[\"np_random_state\"] = np.random.get_state()\n    ck[\"torch_cpu_rng\"] = torch.get_rng_state()\n    if torch.cuda.is_available():\n        try: ck[\"torch_cuda_rng_all\"] = torch.cuda.get_rng_state_all()\n        except Exception: pass\n\n    torch.save(ck, os.path.join(OUT_DIR, \"manual_checkpoint_after_cell12.pth\"))\n    print(\"Saved manual checkpoint to:\", os.path.join(OUT_DIR, \"manual_checkpoint_after_cell12.pth\"))\nexcept Exception as e:\n    print(\"Warning saving manual checkpoint:\", e)\n\n# 2) Save encoder (prefer current encoder or ft_model.encoder)\ntry:\n    if \"ft_model\" in globals() and hasattr(ft_model, \"encoder\"):\n        enc = ft_model.encoder\n    elif \"model\" in globals() and hasattr(model, \"encoder\"):\n        enc = model.encoder\n    elif \"encoder\" in globals() and encoder is not None:\n        enc = encoder\n    else:\n        enc = None\n\n    if enc is not None:\n        enc_path = os.path.join(OUT_DIR, \"simsiam_encoder_after_cell12.pth\")\n        torch.save({\"encoder_state_dict\": enc.state_dict(), \"feat_dim\": getattr(enc, 'feat_dim', None)}, enc_path)\n        print(\"Saved encoder to\", enc_path)\n    else:\n        print(\"No encoder object in memory to save.\")\nexcept Exception as e:\n    print(\"Warning saving encoder:\", e)\n\n# 3) Save finetune resume & best checkpoints if present on disk or in memory\ntry:\n    # attempt to save in-memory ft_model as resume\n    if \"ft_model\" in globals():\n        resume_path = os.path.join(OUT_DIR, \"finetune_resume.pth\")\n        torch.save({\n            \"epoch\": globals().get(\"epoch\", None),\n            \"model_state\": ft_model.state_dict(),\n            \"optimizer_state\": globals().get(\"ft_optimizer\").state_dict() if \"ft_optimizer\" in globals() else None,\n            \"scheduler_state\": globals().get(\"ft_scheduler\").state_dict() if \"ft_scheduler\" in globals() else None,\n            \"val_acc\": globals().get(\"best_val_acc\", None)\n        }, resume_path)\n        print(\"Saved finetune resume checkpoint:\", resume_path)\n    # copy any existing checkpoints from OUT_DIR to ensure they are included\n    for fname in [\"finetune_best.pth\", \"simsiam_encoder.pth\", \"simsiam_encoder_memory.pth\", \"simsiam_encoder_after_finetune.pth\", \"simsiam_latest.pth\"]:\n        src = os.path.join(OUT_DIR, fname)\n        if os.path.exists(src):\n            print(\"Found existing:\", src)\nexcept Exception as e:\n    print(\"Warning saving finetune checkpoints:\", e)\n\n# 4) Save features arrays if present in memory\ntry:\n    import numpy as _np\n    for name in (\"train_feats\",\"val_feats\",\"test_feats\"):\n        if name in globals():\n            path = os.path.join(OUT_DIR, f\"{name}.npy\")\n            _np.save(path, globals()[name])\n            print(\"Saved feature:\", path)\nexcept Exception as e:\n    print(\"Warning saving features:\", e)\n\n# 5) Copy manifests to OUT_DIR and save any label arrays\ntry:\n    if \"manifest\" in globals():\n        with open(os.path.join(OUT_DIR, \"manifest.json\"), \"w\") as f:\n            json.dump(manifest, f)\n    if \"split_manifest\" in globals():\n        with open(os.path.join(OUT_DIR, \"split_manifest.json\"), \"w\") as f:\n            json.dump(split_manifest, f)\n    print(\"Saved manifest(s).\")\nexcept Exception as e:\n    print(\"Warning saving manifest:\", e)\n\n# 6) Save RNG states separately\ntry:\n    rngp = {\n        \"py_random_state\": random.getstate(),\n        \"np_random_state\": np.random.get_state(),\n        \"torch_cpu_rng\": torch.get_rng_state()\n    }\n    if torch.cuda.is_available():\n        try: rngp[\"torch_cuda_rng_all\"] = torch.cuda.get_rng_state_all()\n        except: pass\n    torch.save(rngp, os.path.join(OUT_DIR, \"rng_states_after_cell12.pth\"))\n    print(\"Saved RNG states.\")\nexcept Exception as e:\n    print(\"Warning saving RNG states:\", e)\n\n# 7) Save requirements\ntry:\n    req_path = os.path.join(OUT_DIR, \"requirements.txt\")\n    with open(req_path,\"w\") as f:\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"freeze\"], stdout=f)\n    print(\"Saved requirements.txt\")\nexcept Exception as e:\n    print(\"Warning saving requirements:\", e)\n\n# 8) Zip the entire OUT_DIR under the requested name\ntry:\n    if os.path.exists(ARCHIVE):\n        os.remove(ARCHIVE)\n    shutil.make_archive(base_name=ARCHIVE.replace(\".zip\",\"\"), format=\"zip\", root_dir=OUT_DIR)\n    print(\"Created archive:\", ARCHIVE)\n    print(\"Archive size (bytes):\", os.path.getsize(ARCHIVE))\nexcept Exception as e:\n    print(\"Error creating archive:\", e)\n\nprint(\"SAVE COMPLETE. Download simsiam_cell12_allsave.zip from the notebook output panel.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T15:09:38.042880Z","iopub.execute_input":"2025-11-27T15:09:38.043341Z","iopub.status.idle":"2025-11-27T15:09:39.651673Z","shell.execute_reply.started":"2025-11-27T15:09:38.043314Z","shell.execute_reply":"2025-11-27T15:09:39.650985Z"}},"outputs":[{"name":"stdout","text":"Saved manual checkpoint to: /kaggle/working/simsiam_task4/manual_checkpoint_after_cell12.pth\nNo encoder object in memory to save.\nSaved manifest(s).\nSaved RNG states.\nSaved requirements.txt\nCreated archive: /kaggle/working/simsiam_cell12_allsave.zip\nArchive size (bytes): 29878\nSAVE COMPLETE. Download simsiam_cell12_allsave.zip from the notebook output panel.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"# ===== LOAD CELL (fixed path) =====\nimport os, shutil, json, torch, random, numpy as np\n\n# --- Set paths (match your uploaded folder name) ---\nARCHIVE_DIR = \"/kaggle/input/simsiam-cell12-allsave\"   # <- your actual Kaggle folder\nOUT_DIR = \"/kaggle/working/simsiam_task4\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# --- Verify source exists ---\nif not os.path.exists(ARCHIVE_DIR):\n    raise FileNotFoundError(f\"Archive folder not found: {ARCHIVE_DIR}\")\n\n# --- Copy files from input folder to working OUT_DIR (no unzip step needed) ---\nfor fn in os.listdir(ARCHIVE_DIR):\n    src = os.path.join(ARCHIVE_DIR, fn)\n    dst = os.path.join(OUT_DIR, fn)\n    if not os.path.exists(dst):\n        try:\n            shutil.copy(src, dst)\n        except Exception as e:\n            print(\"Copy error for\", src, \"->\", e)\n\nprint(\"Copied files to OUT_DIR:\", OUT_DIR)\nprint(\"Sample files:\", os.listdir(OUT_DIR)[:50])\n\n# --- Load manifest and split_manifest if present ---\nmanifest = None\nsplit_manifest = None\nm_path = os.path.join(OUT_DIR, \"manifest.json\")\ns_path = os.path.join(OUT_DIR, \"split_manifest.json\")\nif os.path.exists(m_path):\n    with open(m_path, \"r\") as f: manifest = json.load(f); print(\"Loaded manifest.json\")\nif os.path.exists(s_path):\n    with open(s_path, \"r\") as f: split_manifest = json.load(f); print(\"Loaded split_manifest.json\")\n\n# --- Recreate dataset split variables if available ---\ntrain_paths = train_labels = val_paths = val_labels = test_paths = test_labels = classes = None\nif split_manifest:\n    train_paths  = split_manifest.get(\"train\", None)\n    train_labels = split_manifest.get(\"train_labels\", None)\n    val_paths    = split_manifest.get(\"val\", None)\n    val_labels   = split_manifest.get(\"val_labels\", None)\n    test_paths   = split_manifest.get(\"test\", None)\n    test_labels  = split_manifest.get(\"test_labels\", None)\n    classes      = split_manifest.get(\"classes\", [\"Diseased\",\"Dried\",\"Healthy\"])\n    print(f\"Restored splits: Train={len(train_paths) if train_paths else 0}, Val={len(val_paths) if val_paths else 0}, Test={len(test_paths) if test_paths else 0}\")\nelse:\n    print(\"No split_manifest.json found; you may need to recreate splits or provide split file.\")\n\n# --- Restore RNG states if present ---\nrng_path = os.path.join(OUT_DIR, \"rng_states_after_cell12.pth\")\nif os.path.exists(rng_path):\n    try:\n        rng_ck = torch.load(rng_path, map_location=\"cpu\", weights_only=False)\n        if \"py_random_state\" in rng_ck: random.setstate(rng_ck[\"py_random_state\"])\n        if \"np_random_state\" in rng_ck: np.random.set_state(rng_ck[\"np_random_state\"])\n        if \"torch_cpu_rng\" in rng_ck: torch.set_rng_state(rng_ck[\"torch_cpu_rng\"])\n        if torch.cuda.is_available() and \"torch_cuda_rng_all\" in rng_ck:\n            try: torch.cuda.set_rng_state_all(rng_ck[\"torch_cuda_rng_all\"])\n            except: pass\n        print(\"Restored RNG states from\", rng_path)\n    except Exception as e:\n        print(\"Could not restore RNG states:\", e)\nelse:\n    print(\"No RNG state file found (ok).\")\n\n# --- Try loading encoder checkpoints if present (safe) ---\nencoder_ck = None\nencoder = None\nencoder_candidates = [\n    \"simsiam_encoder_after_cell12.pth\",\n    \"simsiam_encoder_memory.pth\",\n    \"simsiam_encoder.pth\"\n]\nfor fname in encoder_candidates:\n    p = os.path.join(OUT_DIR, fname)\n    if os.path.exists(p):\n        try:\n            encoder_ck = torch.load(p, map_location=\"cpu\", weights_only=False)\n            print(\"Loaded encoder checkpoint:\", p)\n            break\n        except Exception as e:\n            print(\"Error loading encoder file\", p, \"->\", e)\n\n# If SimSiam class is defined in this notebook (Cell 7), attach encoder\nif encoder_ck is not None:\n    if \"SimSiam\" in globals():\n        try:\n            BACKBONE = globals().get(\"BACKBONE\", \"resnet18\")\n            tmp = SimSiam(backbone=BACKBONE)\n            tmp.encoder.load_state_dict(encoder_ck[\"encoder_state_dict\"])\n            encoder = tmp.encoder.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n            print(\"Encoder loaded into SimSiam model (in-memory).\")\n        except Exception as e:\n            print(\"Could not attach encoder to SimSiam instance:\", e)\n    else:\n        print(\"SimSiam class not defined in this notebook; encoder_ck available for later use.\")\n\n# --- Load optional manual checkpoint with metadata if present ---\nmanual_ckpt = os.path.join(OUT_DIR, \"manual_checkpoint_after_cell12.pth\")\ncheckpoint_dict = None\nif os.path.exists(manual_ckpt):\n    try:\n        checkpoint_dict = torch.load(manual_ckpt, map_location=\"cpu\", weights_only=False)\n        print(\"Loaded manual checkpoint:\", manual_ckpt)\n    except Exception as e:\n        print(\"Could not load manual checkpoint:\", e)\n\n# --- Expose variables to global scope so downstream cells can use them directly ---\n_globals = {\n    \"OUT_DIR\": OUT_DIR,\n    \"manifest\": manifest,\n    \"split_manifest\": split_manifest,\n    \"train_paths\": train_paths,\n    \"train_labels\": train_labels,\n    \"val_paths\": val_paths,\n    \"val_labels\": val_labels,\n    \"test_paths\": test_paths,\n    \"test_labels\": test_labels,\n    \"classes\": classes,\n    \"encoder\": encoder,\n    \"encoder_ck\": encoder_ck,\n    \"checkpoint_dict\": checkpoint_dict\n}\nglobals().update({k:v for k,v in _globals.items() if v is not None})\n\nprint(\"\\nLOAD COMPLETE. Continue from Cell 10 (feature extraction) or Cell 13 (embeddings).\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:30:42.346622Z","iopub.execute_input":"2025-12-01T03:30:42.346979Z","iopub.status.idle":"2025-12-01T03:30:42.642062Z","shell.execute_reply.started":"2025-12-01T03:30:42.346959Z","shell.execute_reply":"2025-12-01T03:30:42.641264Z"}},"outputs":[{"name":"stdout","text":"Copied files to OUT_DIR: /kaggle/working/simsiam_task4\nSample files: ['requirements.txt', 'LogisticRegression.joblib', 'val_labels.npy', 'val_feats.npy', 'probe_results.json', 'train_labels.npy', 'test_labels.npy', 'DecisionTree.joblib', 'simsiam_encoder.pth', 'manual_checkpoint_after_pretrain.pth', 'simsiam_encoder_memory.pth', 'MLP.joblib', 'SVM_RBF.joblib', 'test_feats.npy', 'simsiam_latest.pth', 'RandomForest.joblib', 'split_manifest.json', 'manual_checkpoint_after_cell12.pth', 'rng_states_after_cell12.pth', 'manifest.json', 'train_feats.npy']\nLoaded manifest.json\nLoaded split_manifest.json\nRestored splits: Train=1296, Val=144, Test=360\nRestored RNG states from /kaggle/working/simsiam_task4/rng_states_after_cell12.pth\nLoaded encoder checkpoint: /kaggle/working/simsiam_task4/simsiam_encoder_memory.pth\nEncoder loaded into SimSiam model (in-memory).\nLoaded manual checkpoint: /kaggle/working/simsiam_task4/manual_checkpoint_after_cell12.pth\n\nLOAD COMPLETE. Continue from Cell 10 (feature extraction) or Cell 13 (embeddings).\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"CELL 13 — Embedding visualization: UMAP, t-SNE, PCA & silhouette","metadata":{}},{"cell_type":"code","source":"# ===== CELL 13 (Robust Embedding Viz: PCA, UMAP (safe), t-SNE (safe), silhouette) =====\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\ntry:\n    from sklearn.manifold import TSNE\nexcept Exception:\n    TSNE = None\n\n# Safe UMAP import may already be present; if not, set to None and skip gracefully.\ntry:\n    import umap\nexcept Exception:\n    umap = None\n\n# --- Load features and labels ---\nOUT_DIR = globals().get(\"OUT_DIR\", \"/kaggle/working/simsiam_task4\")\nif not os.path.exists(OUT_DIR):\n    os.makedirs(OUT_DIR, exist_ok=True)\n\ndef safe_load(npname):\n    p = os.path.join(OUT_DIR, npname)\n    if not os.path.exists(p):\n        raise FileNotFoundError(f\"Missing required file: {p}\")\n    return np.load(p, allow_pickle=False)\n\ntrain_feats = safe_load(\"train_feats.npy\")\nval_feats   = safe_load(\"val_feats.npy\")\ntest_feats  = safe_load(\"test_feats.npy\")\ntrain_lbls  = safe_load(\"train_labels.npy\")\nval_lbls    = safe_load(\"val_labels.npy\")\ntest_lbls   = safe_load(\"test_labels.npy\")\n\nfeats_all = np.vstack([train_feats, val_feats, test_feats]).astype(np.float32)\nlbls_all  = np.concatenate([train_lbls, val_lbls, test_lbls]).astype(int)\n\nclasses = globals().get(\"classes\", [\"Diseased\", \"Dried\", \"Healthy\"])\nSEED = globals().get(\"SEED\", 42)\n\n# small helper to plot and save\ndef scatter_and_save(X2, labels, title, fname):\n    plt.figure(figsize=(8,6))\n    for c_idx, c_name in enumerate(classes):\n        idx = labels == c_idx\n        if np.any(idx):\n            plt.scatter(X2[idx,0], X2[idx,1], label=c_name, s=10, alpha=0.6)\n    plt.legend()\n    plt.title(title)\n    outpath = os.path.join(OUT_DIR, fname)\n    plt.savefig(outpath, dpi=150, bbox_inches=\"tight\")\n    plt.close()\n    print(\"Saved:\", outpath)\n\n# --- PCA (always) ---\npca = PCA(n_components=2, random_state=SEED)\nproj_pca = pca.fit_transform(feats_all)\nscatter_and_save(proj_pca, lbls_all, \"PCA projection of features\", \"pca_proj.png\")\n\n# --- UMAP (try / fallback) ---\nif umap is None:\n    print(\"UMAP not installed or import failed; skipping UMAP projection.\")\nelse:\n    try:\n        # convert to float32 (safer) and run UMAP\n        reducer = umap.UMAP(n_components=2, random_state=SEED)\n        proj_umap = reducer.fit_transform(feats_all)\n        scatter_and_save(proj_umap, lbls_all, \"UMAP projection of features\", \"umap_proj.png\")\n    except Exception as e:\n        # compatibility error fallback\n        print(\"UMAP failed:\", repr(e))\n        # fallback: save a PCA-based proxy for UMAP so downstream cells have a file\n        scatter_and_save(proj_pca, lbls_all, \"UMAP fallback (PCA proxy)\", \"umap_proj_fallback_pca.png\")\n        print(\"Saved PCA proxy as UMAP fallback.\")\n\n# --- t-SNE (try with subsample fallback to avoid very long runs) ---\nif TSNE is None:\n    print(\"TSNE not available; skipping t-SNE projection.\")\nelse:\n    try:\n        n_samples = feats_all.shape[0]\n        tsne_max = 2000  # limit to keep runtime reasonable on Kaggle\n        if n_samples > tsne_max:\n            # stratified subsample roughly balanced across classes\n            idx_keep = []\n            rng = np.random.RandomState(SEED)\n            per_class = max(50, int(tsne_max / max(1, len(classes))))\n            lbls_arr = lbls_all\n            for c in range(len(classes)):\n                positions = np.where(lbls_arr == c)[0]\n                if len(positions) == 0:\n                    continue\n                k = min(len(positions), per_class)\n                sel = rng.choice(positions, size=k, replace=False)\n                idx_keep.extend(sel.tolist())\n            idx_keep = np.array(sorted(idx_keep))\n            feats_tsne = feats_all[idx_keep]\n            labels_tsne = lbls_all[idx_keep]\n            print(f\"t-SNE: dataset too large ({n_samples}), subsampling to {len(idx_keep)} samples for speed.\")\n        else:\n            feats_tsne = feats_all\n            labels_tsne = lbls_all\n\n        tsne = TSNE(n_components=2, perplexity=30, random_state=SEED, init='pca')\n        proj_tsne = tsne.fit_transform(feats_tsne)\n        # if subsampled, include suffix in filename\n        fname = \"tsne_proj.png\" if feats_tsne.shape[0] == n_samples else \"tsne_proj_subsample.png\"\n        scatter_and_save(proj_tsne, labels_tsne, \"t-SNE projection of features\", fname)\n    except Exception as e:\n        print(\"t-SNE failed or was interrupted:\", repr(e))\n        print(\"Skipping t-SNE.\")\n\n# --- silhouette score (only if valid) ---\ntry:\n    # silhouette requires at least 2 classes and at least 2 samples per label\n    unique, counts = np.unique(lbls_all, return_counts=True)\n    if len(unique) < 2 or np.min(counts) < 2:\n        print(\"Silhouette not computed: need >=2 classes and >=2 samples per class.\")\n        sil = None\n    else:\n        sil = silhouette_score(feats_all, lbls_all)\n        print(\"Silhouette score (features):\", sil)\n        with open(os.path.join(OUT_DIR, \"embedding_stats.txt\"), \"w\") as f:\n            f.write(f\"Silhouette: {sil}\\n\")\nexcept Exception as e:\n    print(\"Silhouette computation failed:\", repr(e))\n    sil = None\n\nprint(\"Embedding viz cell finished. Check files in:\", OUT_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:30:45.794219Z","iopub.execute_input":"2025-12-01T03:30:45.794826Z","iopub.status.idle":"2025-12-01T03:30:54.394676Z","shell.execute_reply.started":"2025-12-01T03:30:45.794791Z","shell.execute_reply":"2025-12-01T03:30:54.393975Z"}},"outputs":[{"name":"stdout","text":"Saved: /kaggle/working/simsiam_task4/pca_proj.png\nUMAP failed: TypeError(\"check_array() got an unexpected keyword argument 'ensure_all_finite'\")\nSaved: /kaggle/working/simsiam_task4/umap_proj_fallback_pca.png\nSaved PCA proxy as UMAP fallback.\nSaved: /kaggle/working/simsiam_task4/tsne_proj.png\nSilhouette score (features): -0.019335013\nEmbedding viz cell finished. Check files in: /kaggle/working/simsiam_task4\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"CELL 14 — Label-efficiency experiments (1%,5%,10%,25%,50% labeled) using linear probe","metadata":{}},{"cell_type":"code","source":"# =========================\n# Label-efficiency curves: train logistic regression with limited labeled fractions of train set\n# Saves accuracy for each fraction.\n# =========================\n\nfractions = [0.01, 0.05, 0.10, 0.25, 0.50, 1.0]\nresults = {}\ntotal_train = len(train_feats)\nfor frac in fractions:\n    n = max(1, int(total_train * frac))\n    # subsample stratified by labels\n    # simple stratified subsampling: sample per class proportionally\n    subs_idx = []\n    train_lbls_arr = np.array(train_lbls)\n    for c in range(len(classes)):\n        idxs = np.where(train_lbls_arr == c)[0]\n        k = max(1, int(len(idxs) * frac))\n        rng = np.random.RandomState(SEED)\n        sel = rng.choice(idxs, size=k, replace=False)\n        subs_idx.extend(sel.tolist())\n    subs_idx = sorted(subs_idx)\n    X_sub = train_feats[subs_idx]\n    y_sub = train_lbls_arr[subs_idx]\n\n    clf = LogisticRegression(max_iter=2000)\n    clf.fit(X_sub, y_sub)\n    test_pred = clf.predict(test_feats)\n    acc = accuracy_score(test_lbls, test_pred)\n    results[f\"{int(frac*100)}%\"] = float(acc)\n    print(f\"Fraction {int(frac*100)}% -> Test Acc: {acc:.4f}\")\n\nwith open(os.path.join(OUT_DIR, \"label_efficiency.json\"), \"w\") as f:\n    json.dump(results, f, indent=2)\nprint(\"Saved label-efficiency results to\", os.path.join(OUT_DIR, \"label_efficiency.json\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:30:57.658886Z","iopub.execute_input":"2025-12-01T03:30:57.659173Z","iopub.status.idle":"2025-12-01T03:31:08.679058Z","shell.execute_reply.started":"2025-12-01T03:30:57.659153Z","shell.execute_reply":"2025-12-01T03:31:08.678345Z"}},"outputs":[{"name":"stdout","text":"Fraction 1% -> Test Acc: 0.6250\nFraction 5% -> Test Acc: 0.7472\nFraction 10% -> Test Acc: 0.7778\nFraction 25% -> Test Acc: 0.7889\nFraction 50% -> Test Acc: 0.8167\nFraction 100% -> Test Acc: 0.8167\nSaved label-efficiency results to /kaggle/working/simsiam_task4/label_efficiency.json\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"CELL 16 — (optional for cisual check) Augmentation probe (visual check to ensure augmentations are not destroying diagnostic cues)","metadata":{}},{"cell_type":"code","source":"# =========================\n# Augmentation probe: shows a few augmented views for several random images from each class/subfolder\n# Run this cell to produce visuals; saves PNGs to OUT_DIR for your report.\n# =========================\n\nprobe_samples = 3  # how many sample images per class to visualize\nout_probe_dir = os.path.join(OUT_DIR, \"augmentation_probe\")\nos.makedirs(out_probe_dir, exist_ok=True)\n\nfor cls in classes:\n    # find an example image from either Controlled Environment or On Field for that class\n    found = None\n    for src in sources:\n        p = Path(DATA_DIR) / src / cls\n        imgs = list(p.glob(\"*\"))\n        if len(imgs) > 0:\n            found = imgs[:probe_samples]\n            break\n    if found is None:\n        continue\n    for i, imgp in enumerate(found):\n        outs = aug_probe_image(str(imgp), n=6)\n        # plot and save\n        fig, axs = plt.subplots(1, len(outs), figsize=(len(outs)*2, 2.4))\n        for j, arr in enumerate(outs):\n            axs[j].imshow(arr)\n            axs[j].axis(\"off\")\n        plt.suptitle(f\"Augmentation probe: class={cls} sample={i}\")\n        savepath = os.path.join(out_probe_dir, f\"probe_{cls}_{i}.png\")\n        plt.savefig(savepath, dpi=150, bbox_inches=\"tight\")\n        plt.close()\n        print(\"Saved augmentation probe:\", savepath)\n\nprint(\"Augmentation probe images saved to\", out_probe_dir)\n","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"Saved augmentation probe: /kaggle/working/simsiam_task4/augmentation_probe/probe_Diseased_0.png\nSaved augmentation probe: /kaggle/working/simsiam_task4/augmentation_probe/probe_Diseased_1.png\nSaved augmentation probe: /kaggle/working/simsiam_task4/augmentation_probe/probe_Diseased_2.png\nSaved augmentation probe: /kaggle/working/simsiam_task4/augmentation_probe/probe_Dried_0.png\nSaved augmentation probe: /kaggle/working/simsiam_task4/augmentation_probe/probe_Dried_1.png\nSaved augmentation probe: /kaggle/working/simsiam_task4/augmentation_probe/probe_Dried_2.png\nSaved augmentation probe: /kaggle/working/simsiam_task4/augmentation_probe/probe_Healthy_0.png\nSaved augmentation probe: /kaggle/working/simsiam_task4/augmentation_probe/probe_Healthy_1.png\nSaved augmentation probe: /kaggle/working/simsiam_task4/augmentation_probe/probe_Healthy_2.png\nAugmentation probe images saved to /kaggle/working/simsiam_task4/augmentation_probe\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Task 4.4: Full Metrics Suite (Per-Class Metrics, Confusion Matrices, ROC Curves, Learning Curves, Best-Model Selection, ZIP Archiver)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n#            TASK 4 COMPLETION MEGA-CELL (WITH ZIP) all roc and stuff\n# ============================================================\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport csv\nfrom sklearn.metrics import (\n    precision_recall_fscore_support,\n    accuracy_score,\n    roc_curve,\n    auc,\n    confusion_matrix\n)\nfrom sklearn.model_selection import train_test_split\nimport joblib\nimport shutil\n\n# ------------------------------------------------------------\n# 1. LOAD FEATURES & LABELS\n# ------------------------------------------------------------\nBASE = \"/kaggle/input/all-files/All Files\"\n\ntrain_feats = np.load(f\"{BASE}/train_feats.npy\")\ntrain_labels = np.load(f\"{BASE}/train_labels.npy\")\n\nval_feats = np.load(f\"{BASE}/val_feats.npy\")\nval_labels = np.load(f\"{BASE}/val_labels.npy\")\n\ntest_feats = np.load(f\"{BASE}/test_feats.npy\")\ntest_labels = np.load(f\"{BASE}/test_labels.npy\")\n\n# Load class names\nwith open(\"/kaggle/input/simsiam-task4-archive/manifest.json\", \"r\") as f:\n    manifest = json.load(f)\nCLASSES = manifest[\"classes\"]\nNUM_CLASSES = len(CLASSES)\n\nprint(\"Classes:\", CLASSES)\n\n# ------------------------------------------------------------\n# 2. LOAD CLASSIFIERS\n# ------------------------------------------------------------\nmodels = {\n    \"LogisticRegression\": joblib.load(f\"{BASE}/LogisticRegression.joblib\"),\n    \"SVM_RBF\": joblib.load(f\"{BASE}/SVM_RBF.joblib\"),\n    \"RandomForest\": joblib.load(f\"{BASE}/RandomForest.joblib\"),\n    \"DecisionTree\": joblib.load(f\"{BASE}/DecisionTree.joblib\"),\n    \"MLP\": joblib.load(f\"{BASE}/MLP.joblib\"),\n}\n\n# ------------------------------------------------------------\n# 3. OUTPUT DIRECTORY\n# ------------------------------------------------------------\nOUT = \"/kaggle/working/task4_outputs\"\nos.makedirs(OUT, exist_ok=True)\n\n# ------------------------------------------------------------\n# 4. METRICS FUNCTION\n# ------------------------------------------------------------\ndef compute_metrics(model, name):\n    preds = model.predict(test_feats)\n    acc = accuracy_score(test_labels, preds)\n\n    precision, recall, f1, support = precision_recall_fscore_support(\n        test_labels, preds, labels=list(range(NUM_CLASSES)), zero_division=0\n    )\n\n    cm = confusion_matrix(test_labels, preds)\n\n    result = {\n        \"model\": name,\n        \"overall_accuracy\": float(acc),\n        \"per_class\": {}\n    }\n\n    for i, cls in enumerate(CLASSES):\n        result[\"per_class\"][cls] = {\n            \"precision\": float(precision[i]),\n            \"recall\": float(recall[i]),\n            \"f1\": float(f1[i]),\n            \"support\": int(support[i])\n        }\n\n    return result, cm\n\nall_metrics = {}\n\n# ------------------------------------------------------------\n# 5. GENERATE METRICS + CONFUSION MATRICES\n# ------------------------------------------------------------\nfor name, clf in models.items():\n    print(f\"Computing metrics for {name}...\")\n    metrics, cm = compute_metrics(clf, name)\n\n    # Save JSON\n    with open(f\"{OUT}/metrics_{name}.json\", \"w\") as f:\n        json.dump(metrics, f, indent=2)\n\n    # Confusion matrix figure\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n                xticklabels=CLASSES, yticklabels=CLASSES)\n    plt.title(f\"Confusion Matrix - {name}\")\n    plt.savefig(f\"{OUT}/confusion_{name}.png\")\n    plt.close()\n\n    all_metrics[name] = metrics\n\n# ------------------------------------------------------------\n# 6. SAVE ALL METRICS AS CSV\n# ------------------------------------------------------------\ncsv_path = f\"{OUT}/per_class_metrics.csv\"\nwith open(csv_path, \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    header = [\"Model\", \"Class\", \"Precision\", \"Recall\", \"F1\", \"Support\", \"Overall Accuracy\"]\n    writer.writerow(header)\n\n    for model_name, data in all_metrics.items():\n        acc = data[\"overall_accuracy\"]\n        for cls, d in data[\"per_class\"].items():\n            writer.writerow([\n                model_name,\n                cls,\n                d[\"precision\"],\n                d[\"recall\"],\n                d[\"f1\"],\n                d[\"support\"],\n                acc\n            ])\n\nprint(\"Saved CSV:\", csv_path)\n\n# ------------------------------------------------------------\n# 7. SAFE predict_proba wrapper\n# ------------------------------------------------------------\ndef safe_predict_proba(model, feats):\n    try:\n        return model.predict_proba(feats)\n    except:\n        try:\n            df = model.decision_function(feats)\n            exp = np.exp(df - np.max(df, axis=1, keepdims=True))\n            return exp / np.sum(exp, axis=1, keepdims=True)\n        except:\n            preds = model.predict(feats)\n            one_hot = np.zeros((len(preds), NUM_CLASSES))\n            for i, p in enumerate(preds):\n                one_hot[i][p] = 1\n            return one_hot\n\n# ------------------------------------------------------------\n# 8. ROC CURVES — PER CLASSIFIER\n# ------------------------------------------------------------\nfor name, clf in models.items():\n    probs = safe_predict_proba(clf, test_feats)\n\n    plt.figure(figsize=(7,6))\n    for i, cls in enumerate(CLASSES):\n        fpr, tpr, _ = roc_curve(test_labels == i, probs[:, i])\n        auc_score = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label=f\"{cls} (AUC={auc_score:.3f})\")\n\n    plt.plot([0,1],[0,1],\"k--\")\n    plt.title(f\"ROC Curve - {name}\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.legend()\n    plt.savefig(f\"{OUT}/roc_{name}.png\")\n    plt.close()\n\nprint(\"Saved per-model ROC curves.\")\n\n# ------------------------------------------------------------\n# 9. ROC CURVES — PER CLASS COMPARISON\n# ------------------------------------------------------------\nfor c_idx, cls in enumerate(CLASSES):\n    plt.figure(figsize=(7,6))\n    for name, clf in models.items():\n        probs = safe_predict_proba(clf, test_feats)\n        fpr, tpr, _ = roc_curve(test_labels == c_idx, probs[:, c_idx])\n        auc_score = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label=f\"{name} (AUC={auc_score:.3f})\")\n\n    plt.plot([0,1],[0,1], 'k--')\n    plt.title(f\"ROC Comparison – Class: {cls}\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.legend()\n    plt.savefig(f\"{OUT}/roc_class_{cls}.png\")\n    plt.close()\n\nprint(\"Saved per-class ROC comparison plots.\")\n\n# ------------------------------------------------------------\n# 10. LEARNING CURVES FOR ALL MODELS\n# ------------------------------------------------------------\ndef learning_curve_plot(model, name):\n    sizes = np.linspace(0.1, 1.0, 10)\n    sizes = (sizes * len(train_feats)).astype(int)\n\n    train_accs = []\n    val_accs = []\n\n    for s in sizes:\n        X_s = train_feats[:s]\n        y_s = train_labels[:s]\n\n        model.fit(X_s, y_s)\n        train_pred = model.predict(X_s)\n        val_pred = model.predict(val_feats)\n\n        train_accs.append(accuracy_score(y_s, train_pred))\n        val_accs.append(accuracy_score(val_labels, val_pred))\n\n    plt.figure(figsize=(7,6))\n    plt.plot(sizes, train_accs, label=\"Train Acc\", marker=\"o\")\n    plt.plot(sizes, val_accs, label=\"Val Acc\", marker=\"o\")\n    plt.title(f\"Learning Curve - {name}\")\n    plt.xlabel(\"Training Samples\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(f\"{OUT}/learning_curve_{name}.png\")\n    plt.close()\n\nimport copy\nfor name, clf in models.items():\n    print(f\"Learning curve: {name}\")\n    learning_curve_plot(copy.deepcopy(clf), name)\n\n# ------------------------------------------------------------\n# 11. BEST MODEL SELECTION\n# ------------------------------------------------------------\nbest_model = None\nbest_acc = -1\n\nfor name, clf in models.items():\n    preds = clf.predict(val_feats)\n    acc = accuracy_score(val_labels, preds)\n    if acc > best_acc:\n        best_acc = acc\n        best_model = name\n\nwith open(f\"{OUT}/best_model.txt\", \"w\") as f:\n    f.write(f\"Best model (by validation accuracy): {best_model} ({best_acc:.4f})\\n\")\n\nprint(\"Best model:\", best_model)\n\n# ------------------------------------------------------------\n# 12. ZIP ALL OUTPUTS\n# ------------------------------------------------------------\nZIP_PATH = \"/kaggle/working/task4_outputs.zip\"\n\n# Remove existing zip if rerun\nif os.path.exists(ZIP_PATH):\n    os.remove(ZIP_PATH)\n\nshutil.make_archive(\"/kaggle/working/task4_outputs\", \"zip\", OUT)\nprint(\"ZIP file created:\", ZIP_PATH)\n\nprint(\"\\nALL TASK 4 OUTPUTS COMPLETE & ARCHIVED.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:24:40.325695Z","iopub.execute_input":"2025-12-05T06:24:40.326517Z","iopub.status.idle":"2025-12-05T06:26:07.331537Z","shell.execute_reply.started":"2025-12-05T06:24:40.326488Z","shell.execute_reply":"2025-12-05T06:26:07.330890Z"}},"outputs":[{"name":"stdout","text":"Classes: ['Diseased', 'Dried', 'Healthy']\nComputing metrics for LogisticRegression...\nComputing metrics for SVM_RBF...\nComputing metrics for RandomForest...\nComputing metrics for DecisionTree...\nComputing metrics for MLP...\nSaved CSV: /kaggle/working/task4_outputs/per_class_metrics.csv\nSaved per-model ROC curves.\nSaved per-class ROC comparison plots.\nLearning curve: LogisticRegression\nLearning curve: SVM_RBF\nLearning curve: RandomForest\nLearning curve: DecisionTree\nLearning curve: MLP\nBest model: MLP\nZIP file created: /kaggle/working/task4_outputs.zip\n\nALL TASK 4 OUTPUTS COMPLETE & ARCHIVED.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"CELL 15 — Ablation: varying pretraining epochs (100, 200, 400) — skeleton runner","metadata":{}},{"cell_type":"code","source":"# =========================\n# Cell 15 (SAVE-EVERY-20-EPOCHS) — Ablation runner with periodic save (every N epochs)\n# - Saves full checkpoint (weights+opt+sched+encoder+metadata) every `save_interval` epochs\n# - Zips run dir on each save (for easy download)\n# - Auto-resumes from latest saved epoch (which will be a multiple of save_interval)\n# - Shows tqdm progress and prints epoch summaries\n# =========================\n\nimport os, time, json, shutil\nimport torch\nfrom torch import optim\nfrom tqdm import tqdm\n\n# ---------- Config ----------\nablation_epochs = [100, 200, 400]    # ablation configs to run\nsave_interval = 20                    # SAVE every N epochs (set 20 as you requested)\nzip_every_k_backups = 1               # create zip each time we save (1 => on every save); 0 to disable\nzip_output_name_template = \"simsiam_ablation_epochs_{E}.zip\"  # saved to /kaggle/working\n# ----------------------------\n\n# hyperparams (fallback to notebook globals)\nlearning_rate = globals().get(\"learning_rate\", 0.05)\nmomentum = globals().get(\"momentum\", 0.9)\nweight_decay = globals().get(\"weight_decay\", 1e-4)\n\n# sanity checks\nif \"train_loader\" not in globals():\n    raise RuntimeError(\"train_loader not found — run the data preparation / pretraining cells first.\")\nif \"SimSiam\" not in globals():\n    raise RuntimeError(\"SimSiam class not defined — run the model definition cell first (Cell 7).\")\n\nOUT_DIR = globals().get(\"OUT_DIR\", \"/kaggle/working/simsiam_task4\")\nos.makedirs(OUT_DIR, exist_ok=True)\n\ndevice = globals().get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\nBACKBONE = globals().get(\"BACKBONE\", \"resnet18\")\n\n# negative cosine similarity helper (same as pretrain)\ndef negative_cosine_similarity(p, z):\n    z = z.detach()\n    p = torch.nn.functional.normalize(p, dim=1)\n    z = torch.nn.functional.normalize(z, dim=1)\n    return - (p * z).sum(dim=1).mean()\n\n# save checkpoint helper (full save)\ndef save_full_checkpoint(model, optimizer, scheduler, run_dir, epoch_num, avg_loss):\n    \"\"\"Save full checkpoint for epoch_num (1-based).\"\"\"\n    epoch_dir = os.path.join(run_dir, f\"epoch_{epoch_num:03d}\")\n    os.makedirs(epoch_dir, exist_ok=True)\n    ck = {\n        \"epoch\": int(epoch_num),\n        \"timestamp\": time.time(),\n        \"model_state\": model.state_dict(),\n        \"optimizer_state\": optimizer.state_dict() if optimizer is not None else None,\n        \"scheduler_state\": scheduler.state_dict() if scheduler is not None else None,\n        \"avg_loss\": float(avg_loss),\n        \"manifest\": globals().get(\"split_manifest\", None)\n    }\n    ck_path = os.path.join(epoch_dir, \"checkpoint.pth\")\n    torch.save(ck, ck_path)\n    # encoder snapshot (convenience)\n    try:\n        enc_path = os.path.join(epoch_dir, \"encoder.pth\")\n        torch.save({\"encoder_state_dict\": model.encoder.state_dict(), \"feat_dim\": model.feat_dim}, enc_path)\n    except Exception:\n        pass\n    # metadata.json\n    meta = {\"epoch\": int(epoch_num), \"avg_loss\": float(avg_loss), \"saved_at\": time.time()}\n    with open(os.path.join(epoch_dir, \"metadata.json\"), \"w\") as f:\n        json.dump(meta, f)\n    return ck_path\n\n# Main ablation loop (periodic save)\nfor E in ablation_epochs:\n    run_dir = os.path.join(OUT_DIR, f\"ablation_epochs_{E}\")\n    os.makedirs(run_dir, exist_ok=True)\n    zip_out_path = os.path.join(\"/kaggle/working\", zip_output_name_template.format(E=E))\n\n    print(f\"\\n=== Ablation config: {E} epochs | saving every {save_interval} epochs | run_dir: {run_dir} ===\")\n\n    # Build model/optimizer/scheduler fresh (or will load later if resuming)\n    model_ab = SimSiam(backbone=BACKBONE).to(device)\n    opt_ab = optim.SGD(model_ab.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n    sched_ab = torch.optim.lr_scheduler.CosineAnnealingLR(opt_ab, T_max=E)\n\n    # Detect last saved epoch (must be multiple of save_interval typically)\n    existing_epochs = []\n    if os.path.exists(run_dir):\n        for name in os.listdir(run_dir):\n            if name.startswith(\"epoch_\"):\n                try:\n                    existing_epochs.append(int(name.split(\"_\")[1]))\n                except Exception:\n                    pass\n    last_saved = max(existing_epochs) if existing_epochs else 0\n    # Resume from next epoch (1-based)\n    start_epoch = last_saved + 1\n\n    # If resuming, attempt to load the latest full checkpoint (best-effort)\n    if last_saved > 0:\n        ckpt_path = os.path.join(run_dir, f\"epoch_{last_saved:03d}\", \"checkpoint.pth\")\n        if os.path.exists(ckpt_path):\n            print(f\"Resuming from saved checkpoint at epoch {last_saved}: {ckpt_path}\")\n            ck = torch.load(ckpt_path, map_location=device, weights_only=False)\n            try:\n                model_ab.load_state_dict(ck[\"model_state\"])\n            except Exception as e:\n                print(\"Warning: model_state load partial/failed ->\", e)\n            try:\n                if ck.get(\"optimizer_state\") is not None:\n                    opt_ab.load_state_dict(ck[\"optimizer_state\"])\n            except Exception as e:\n                print(\"Warning: optimizer_state load failed ->\", e)\n            try:\n                if ck.get(\"scheduler_state\") is not None:\n                    sched_ab.load_state_dict(ck[\"scheduler_state\"])\n            except Exception:\n                pass\n            print(f\"Resumed. Next epoch will be {start_epoch} (1-based) out of {E}.\")\n        else:\n            print(\"Found epoch folders but checkpoint.pth missing — starting from epoch 1.\")\n            start_epoch = 1\n    else:\n        start_epoch = 1\n\n    # If the last_saved isn't exactly the last completed epoch before interruption,\n    # you will lose progress between last_saved and the current interruption.\n    if last_saved > 0:\n        print(f\"Note: last saved epoch = {last_saved}. Progress after that may be lost if run stopped earlier than next save point.\")\n\n    # Training loop: epochs are 1..E inclusive\n    try:\n        for epoch in range(start_epoch, E + 1):   # epoch is 1-based here\n            model_ab.train()\n            running_loss = 0.0\n            n_steps = 0\n\n            loop = tqdm(train_loader, desc=f\"Ablation E={E} Epoch {epoch}/{E}\", leave=False)\n            for x1, x2, _, _ in loop:\n                x1 = x1.to(device); x2 = x2.to(device)\n\n                p1, p2, z1, z2 = model_ab(x1, x2)\n                loss = 0.5 * negative_cosine_similarity(p1, z2) + 0.5 * negative_cosine_similarity(p2, z1)\n\n                opt_ab.zero_grad()\n                loss.backward()\n                opt_ab.step()\n\n                running_loss += loss.item()\n                n_steps += 1\n                loop.set_postfix(loss=f\"{loss.item():.4f}\")\n\n            avg_loss = (running_loss / n_steps) if n_steps > 0 else 0.0\n            sched_ab.step()\n            print(f\"Epoch {epoch}/{E} completed - Avg Loss: {avg_loss:.4f}\")\n\n            # Save only at save_interval multiples OR on final epoch\n            to_save = (epoch % save_interval == 0) or (epoch == E)\n            if to_save:\n                try:\n                    ck_path = save_full_checkpoint(model_ab, opt_ab, sched_ab, run_dir, epoch, avg_loss)\n                    print(\"Saved full checkpoint for epoch:\", epoch, \"->\", ck_path)\n                except Exception as e:\n                    print(\"Warning: could not save checkpoint:\", e)\n\n                # periodic zip backup if enabled\n                if zip_every_k_backups and zip_every_k_backups > 0:\n                    try:\n                        # overwrite previous zip for same E\n                        if os.path.exists(zip_out_path):\n                            os.remove(zip_out_path)\n                        shutil.make_archive(base_name=zip_out_path.replace(\".zip\",\"\"), format=\"zip\", root_dir=run_dir)\n                        print(\"Saved ZIP backup to:\", zip_out_path)\n                    except Exception as e:\n                        print(\"Warning: ZIP backup failed ->\", e)\n\n    except KeyboardInterrupt:\n        # On interrupt, save the most recent multiple-of-save_interval checkpoint if possible\n        print(\"KeyboardInterrupt caught — attempting to save resume checkpoint (if we are on a save point).\")\n        try:\n            # if current epoch is a save point, save it; otherwise save last_saved again (best-effort)\n            cur_epoch = epoch\n            if (cur_epoch % save_interval == 0) or (cur_epoch == E):\n                save_full_checkpoint(model_ab, opt_ab, sched_ab, run_dir, cur_epoch, avg_loss if 'avg_loss' in locals() else 0.0)\n                print(\"Saved checkpoint for interrupted epoch:\", cur_epoch)\n            else:\n                print(f\"Current epoch {cur_epoch} not a save point. Last permanent save remains epoch {last_saved}.\")\n        except Exception as e:\n            print(\"Could not save on interrupt:\", e)\n        raise\n\n    # final zip after finishing all epochs for this E\n    try:\n        if zip_every_k_backups and zip_every_k_backups > 0:\n            if os.path.exists(zip_out_path):\n                os.remove(zip_out_path)\n            shutil.make_archive(base_name=zip_out_path.replace(\".zip\",\"\"), format=\"zip\", root_dir=run_dir)\n            print(\"Completed ablation run. Final ZIP:\", zip_out_path)\n    except Exception as e:\n        print(\"Could not create final ZIP:\", e)\n\nprint(\"\\nAll ablation configs processed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T05:39:57.963711Z","iopub.execute_input":"2025-11-30T05:39:57.966519Z","execution_failed":"2025-11-30T15:04:48.659Z"}},"outputs":[{"name":"stdout","text":"\n=== Ablation config: 100 epochs | saving every 20 epochs | run_dir: /kaggle/working/simsiam_task4/ablation_epochs_100 ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100 completed - Avg Loss: -0.3544\n","output_type":"stream"},{"name":"stderr","text":"                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/100 completed - Avg Loss: -0.6602\n","output_type":"stream"},{"name":"stderr","text":"                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/100 completed - Avg Loss: -0.8142\n","output_type":"stream"},{"name":"stderr","text":"                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/100 completed - Avg Loss: -0.8335\n","output_type":"stream"},{"name":"stderr","text":"                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/100 completed - Avg Loss: -0.8616\n","output_type":"stream"},{"name":"stderr","text":"                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/100 completed - Avg Loss: -0.8948\n","output_type":"stream"},{"name":"stderr","text":"                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/100 completed - Avg Loss: -0.8459\n","output_type":"stream"},{"name":"stderr","text":"                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/100 completed - Avg Loss: -0.8835\n","output_type":"stream"},{"name":"stderr","text":"                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/100 completed - Avg Loss: -0.9091\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/100 completed - Avg Loss: -0.9155\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/100 completed - Avg Loss: -0.9060\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/100 completed - Avg Loss: -0.9051\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/100 completed - Avg Loss: -0.9177\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/100 completed - Avg Loss: -0.9089\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/100 completed - Avg Loss: -0.9111\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/100 completed - Avg Loss: -0.9254\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/100 completed - Avg Loss: -0.9219\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/100 completed - Avg Loss: -0.9178\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/100 completed - Avg Loss: -0.8918\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/100 completed - Avg Loss: -0.9234\nSaved full checkpoint for epoch: 20 -> /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_020/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/100 completed - Avg Loss: -0.9221\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/100 completed - Avg Loss: -0.9404\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/100 completed - Avg Loss: -0.9371\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/100 completed - Avg Loss: -0.9062\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/100 completed - Avg Loss: -0.8888\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/100 completed - Avg Loss: -0.9240\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/100 completed - Avg Loss: -0.9341\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/100 completed - Avg Loss: -0.9380\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/100 completed - Avg Loss: -0.9371\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/100 completed - Avg Loss: -0.9390\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31/100 completed - Avg Loss: -0.9326\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32/100 completed - Avg Loss: -0.9433\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33/100 completed - Avg Loss: -0.9424\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34/100 completed - Avg Loss: -0.9477\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35/100 completed - Avg Loss: -0.9463\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 36/100 completed - Avg Loss: -0.9468\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 37/100 completed - Avg Loss: -0.9433\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 38/100 completed - Avg Loss: -0.9434\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 39/100 completed - Avg Loss: -0.9445\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 40/100 completed - Avg Loss: -0.9481\nSaved full checkpoint for epoch: 40 -> /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_040/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 41/100 completed - Avg Loss: -0.9451\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 42/100 completed - Avg Loss: -0.9364\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 43/100 completed - Avg Loss: -0.9513\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 44/100 completed - Avg Loss: -0.9480\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 45/100 completed - Avg Loss: -0.9490\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 46/100 completed - Avg Loss: -0.9489\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 47/100 completed - Avg Loss: -0.9502\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 48/100 completed - Avg Loss: -0.9503\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 49/100 completed - Avg Loss: -0.9509\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 50/100 completed - Avg Loss: -0.9496\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 51/100 completed - Avg Loss: -0.9520\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 52/100 completed - Avg Loss: -0.9510\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 53/100 completed - Avg Loss: -0.9535\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 54/100 completed - Avg Loss: -0.9472\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 55/100 completed - Avg Loss: -0.9480\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 56/100 completed - Avg Loss: -0.9471\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 57/100 completed - Avg Loss: -0.9479\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 58/100 completed - Avg Loss: -0.9500\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 59/100 completed - Avg Loss: -0.9455\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 60/100 completed - Avg Loss: -0.9424\nSaved full checkpoint for epoch: 60 -> /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_060/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 61/100 completed - Avg Loss: -0.9420\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 62/100 completed - Avg Loss: -0.9426\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 63/100 completed - Avg Loss: -0.9363\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 64/100 completed - Avg Loss: -0.9406\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 65/100 completed - Avg Loss: -0.9366\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 66/100 completed - Avg Loss: -0.9419\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 67/100 completed - Avg Loss: -0.9453\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 68/100 completed - Avg Loss: -0.9445\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 69/100 completed - Avg Loss: -0.9445\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 71/100 completed - Avg Loss: -0.9411\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 72/100 completed - Avg Loss: -0.9436\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 73/100 completed - Avg Loss: -0.9392\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 74/100 completed - Avg Loss: -0.9386\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 75/100 completed - Avg Loss: -0.9390\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 76/100 completed - Avg Loss: -0.9381\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 77/100 completed - Avg Loss: -0.9356\n","output_type":"stream"},{"name":"stderr","text":"                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 78/100 completed - Avg Loss: -0.9323\n","output_type":"stream"},{"name":"stderr","text":"Ablation E=100 Epoch 79/100:  30%|███       | 6/20 [01:43<03:30, 15.02s/it, loss=-0.9433]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# ===== Cell 15 (RESUME FROM 80 -> 100, save every 5 epochs) =====\nimport os, shutil, json, time, torch\nfrom torch import optim\nfrom tqdm import tqdm\n\n# -------- CONFIG --------\nE_target = 100\n# Where to keep the run folders (where your epoch_xxx folders will live)\nRUN_ROOT = \"/kaggle/working/simsiam_task4\"\nRUN_DIR  = os.path.join(RUN_ROOT, f\"ablation_epochs_{E_target}\")   # target run dir\n# Uploaded archive location you mentioned\nINPUT_ARCHIVE = \"/kaggle/input/simsiam-ablation-epochs-100\"\n# Save policy now\nsave_interval = 5   # save every 5 epochs (85,90,95,100)\nZIP_OUT = os.path.join(\"/kaggle/working\", f\"simsiam_ablation_epochs_{E_target}.zip\")\n# Device / model fallback values (use your notebook globals if set)\ndevice = globals().get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\nBACKBONE = globals().get(\"BACKBONE\", \"resnet18\")\nlearning_rate = globals().get(\"learning_rate\", 0.05)\nmomentum = globals().get(\"momentum\", 0.9)\nweight_decay = globals().get(\"weight_decay\", 1e-4)\n# ------------------------\n\n# Sanity: model and data must be defined earlier in the notebook\nif \"SimSiam\" not in globals():\n    raise RuntimeError(\"SimSiam not defined — run model-definition cell first.\")\nif \"train_loader\" not in globals():\n    raise RuntimeError(\"train_loader not found — run data prep / pretraining cells first.\")\n\nos.makedirs(RUN_DIR, exist_ok=True)\n\n# Helper loss (same as used)\ndef negative_cosine_similarity(p, z):\n    z = z.detach()\n    p = torch.nn.functional.normalize(p, dim=1)\n    z = torch.nn.functional.normalize(z, dim=1)\n    return - (p * z).sum(dim=1).mean()\n\n# Helper save function\ndef save_full_checkpoint(model, optimizer, scheduler, run_dir, epoch_num, avg_loss):\n    epoch_dir = os.path.join(run_dir, f\"epoch_{epoch_num:03d}\")\n    os.makedirs(epoch_dir, exist_ok=True)\n    ck = {\n        \"epoch\": int(epoch_num),\n        \"timestamp\": time.time(),\n        \"model_state\": model.state_dict(),\n        \"optimizer_state\": optimizer.state_dict() if optimizer is not None else None,\n        \"scheduler_state\": scheduler.state_dict() if scheduler is not None else None,\n        \"avg_loss\": float(avg_loss),\n        \"manifest\": globals().get(\"split_manifest\", None)\n    }\n    ck_path = os.path.join(epoch_dir, \"checkpoint.pth\")\n    torch.save(ck, ck_path)\n    # encoder snapshot\n    try:\n        torch.save({\"encoder_state_dict\": model.encoder.state_dict(), \"feat_dim\": model.feat_dim},\n                   os.path.join(epoch_dir, \"encoder.pth\"))\n    except Exception:\n        pass\n    # metadata\n    with open(os.path.join(epoch_dir, \"metadata.json\"), \"w\") as f:\n        json.dump({\"epoch\": epoch_num, \"avg_loss\": float(avg_loss), \"saved_at\": time.time()}, f)\n    return ck_path\n\n# 1) Ensure we have the existing checkpoint folders in RUN_DIR\n# Prefer already-present working dir, else copy from INPUT_ARCHIVE\ndef ensure_existing_checkpoints():\n    # if run dir already has epoch folders, do nothing\n    has_epochs = any(n.startswith(\"epoch_\") for n in os.listdir(RUN_DIR)) if os.path.exists(RUN_DIR) else False\n    if has_epochs:\n        return True\n    # else try copy from input archive\n    if os.path.exists(INPUT_ARCHIVE):\n        copied = 0\n        for root, dirs, files in os.walk(INPUT_ARCHIVE):\n            for d in dirs:\n                if d.startswith(\"epoch_\"):\n                    src = os.path.join(root, d)\n                    dst = os.path.join(RUN_DIR, d)\n                    if not os.path.exists(dst):\n                        try:\n                            shutil.copytree(src, dst)\n                            copied += 1\n                        except Exception as e:\n                            print(\"Copy error:\", e)\n        if copied > 0:\n            print(f\"Copied {copied} epoch folders from input archive -> {RUN_DIR}\")\n            return True\n        else:\n            print(\"No epoch_* folders found in input archive.\")\n            return False\n    else:\n        print(\"Input archive folder not present:\", INPUT_ARCHIVE)\n        return False\n\nok = ensure_existing_checkpoints()\nif not ok:\n    raise FileNotFoundError(\"Could not locate saved epoch folders in working or input archive. Place epoch_080 checkpoint into RUN_DIR or upload it.\")\n\n# 2) Detect highest saved epoch\nsaved_epochs = []\nfor name in os.listdir(RUN_DIR):\n    if name.startswith(\"epoch_\"):\n        try:\n            saved_epochs.append(int(name.split(\"_\")[1]))\n        except:\n            pass\nif not saved_epochs:\n    raise RuntimeError(\"No epoch_XXX folders present in RUN_DIR after copy step.\")\nsaved_epochs = sorted(saved_epochs)\nprint(\"Detected saved epochs:\", saved_epochs)\nlast_saved = max(saved_epochs)\nprint(\"Last saved epoch:\", last_saved)\n\n# We expect last_saved >= 80; if not, you can set last_saved manually\nif last_saved < 80:\n    print(\"Warning: last_saved < 80; check your uploaded files. Continuing will start from last_saved+1.\")\n# We'll resume from last_saved+1 (so if last_saved==80 -> resume at 81)\nstart_epoch = last_saved + 1\nif start_epoch > E_target:\n    print(\"Target already reached. Exiting.\")\nelse:\n    print(f\"Resume training from epoch {start_epoch} -> {E_target} (inclusive)\")\n\n# 3) Build model, optimizer, scheduler and try to load checkpoint for last_saved\nmodel = SimSiam(backbone=BACKBONE).to(device)\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=E_target)\n\nck_path = os.path.join(RUN_DIR, f\"epoch_{last_saved:03d}\", \"checkpoint.pth\")\nif os.path.exists(ck_path):\n    print(\"Loading checkpoint:\", ck_path)\n    ck = torch.load(ck_path, map_location=device, weights_only=False)\n    # load model\n    if ck.get(\"model_state\") is not None:\n        try:\n            model.load_state_dict(ck[\"model_state\"])\n            print(\"Model state loaded.\")\n        except Exception as e:\n            print(\"Model load warning:\", e)\n    # load optimizer\n    if ck.get(\"optimizer_state\") is not None:\n        try:\n            optimizer.load_state_dict(ck[\"optimizer_state\"])\n            print(\"Optimizer state loaded.\")\n        except Exception as e:\n            print(\"Optimizer load warning:\", e)\n    # load scheduler\n    if ck.get(\"scheduler_state\") is not None:\n        try:\n            scheduler.load_state_dict(ck[\"scheduler_state\"])\n            print(\"Scheduler state loaded.\")\n        except Exception:\n            pass\n    # try restore rng states (if saved in checkpoint)\n    if \"py_random_state\" in ck:\n        import random, numpy as np\n        try:\n            random.setstate(ck[\"py_random_state\"])\n            np.random.set_state(ck[\"np_random_state\"])\n            torch.set_rng_state(ck[\"torch_cpu_rng\"])\n            if torch.cuda.is_available() and \"torch_cuda_rng_all\" in ck:\n                try: torch.cuda.set_rng_state_all(ck[\"torch_cuda_rng_all\"])\n                except: pass\n            print(\"Restored RNG states from checkpoint (if present).\")\n        except Exception:\n            pass\nelse:\n    print(\"No checkpoint.pth found for last_saved epoch, will continue from fresh weights.\")\n\n# 4) Resume loop: start_epoch .. E_target, print per-epoch, save every save_interval\ntry:\n    for epoch in range(start_epoch, E_target + 1):\n        model.train()\n        running_loss = 0.0\n        steps = 0\n        loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{E_target}\", leave=False)\n        for x1, x2, _, _ in loop:\n            x1 = x1.to(device); x2 = x2.to(device)\n            p1, p2, z1, z2 = model(x1, x2)\n            loss = 0.5 * negative_cosine_similarity(p1, z2) + 0.5 * negative_cosine_similarity(p2, z1)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            running_loss += float(loss.item())\n            steps += 1\n            loop.set_postfix(loss=f\"{loss.item():.4f}\")\n        scheduler.step()\n        avg_loss = (running_loss / steps) if steps>0 else 0.0\n        print(f\"Epoch {epoch}/{E_target} completed - Avg Loss: {avg_loss:.4f}\")\n\n        # save at multiples of save_interval OR final epoch\n        if (epoch % save_interval == 0) or (epoch == E_target):\n            try:\n                ck_out = save_full_checkpoint(model, optimizer, scheduler, RUN_DIR, epoch, avg_loss)\n                print(\"Saved checkpoint:\", ck_out)\n            except Exception as e:\n                print(\"Warning saving checkpoint:\", e)\n            # update zip\n            try:\n                if os.path.exists(ZIP_OUT):\n                    os.remove(ZIP_OUT)\n                shutil.make_archive(base_name=ZIP_OUT.replace(\".zip\",\"\"), format=\"zip\", root_dir=RUN_DIR)\n                print(\"Updated ZIP:\", ZIP_OUT)\n            except Exception as e:\n                print(\"Warning creating zip:\", e)\n\nexcept KeyboardInterrupt:\n    print(\"Interrupted by user. Last permanent saved epoch is last existing epoch folder.\")\n    raise\n\nprint(\"Resume finished. Final folders in:\", RUN_DIR)\nprint(\"Download the zip from Kaggle output:\", ZIP_OUT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:31:15.904883Z","iopub.execute_input":"2025-12-01T03:31:15.905157Z","iopub.status.idle":"2025-12-01T05:40:03.366489Z","shell.execute_reply.started":"2025-12-01T03:31:15.905137Z","shell.execute_reply":"2025-12-01T05:40:03.365661Z"}},"outputs":[{"name":"stdout","text":"Copied 4 epoch folders from input archive -> /kaggle/working/simsiam_task4/ablation_epochs_100\nDetected saved epochs: [20, 40, 60, 80]\nLast saved epoch: 80\nResume training from epoch 81 -> 100 (inclusive)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Loading checkpoint: /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_080/checkpoint.pth\nModel state loaded.\nOptimizer state loaded.\nScheduler state loaded.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 81/100 completed - Avg Loss: -0.9401\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 82/100 completed - Avg Loss: -0.9332\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 83/100 completed - Avg Loss: -0.9370\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 84/100 completed - Avg Loss: -0.9354\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 85/100 completed - Avg Loss: -0.9359\nSaved checkpoint: /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_085/checkpoint.pth\nUpdated ZIP: /kaggle/working/simsiam_ablation_epochs_100.zip\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 86/100 completed - Avg Loss: -0.9361\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 87/100 completed - Avg Loss: -0.9341\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 88/100 completed - Avg Loss: -0.9346\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 89/100 completed - Avg Loss: -0.9357\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 90/100 completed - Avg Loss: -0.9347\nSaved checkpoint: /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_090/checkpoint.pth\nUpdated ZIP: /kaggle/working/simsiam_ablation_epochs_100.zip\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 91/100 completed - Avg Loss: -0.9339\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 92/100 completed - Avg Loss: -0.9330\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 93/100 completed - Avg Loss: -0.9331\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 94/100 completed - Avg Loss: -0.9349\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 95/100 completed - Avg Loss: -0.9344\nSaved checkpoint: /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_095/checkpoint.pth\nUpdated ZIP: /kaggle/working/simsiam_ablation_epochs_100.zip\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 96/100 completed - Avg Loss: -0.9338\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 97/100 completed - Avg Loss: -0.9341\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 98/100 completed - Avg Loss: -0.9315\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 99/100 completed - Avg Loss: -0.9322\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 100/100 completed - Avg Loss: -0.9313\nSaved checkpoint: /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_100/checkpoint.pth\nUpdated ZIP: /kaggle/working/simsiam_ablation_epochs_100.zip\nResume finished. Final folders in: /kaggle/working/simsiam_task4/ablation_epochs_100\nDownload the zip from Kaggle output: /kaggle/working/simsiam_ablation_epochs_100.zip\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"print(\"\"\"\n=== Ablation config: 100 epochs | saving every 20 epochs | run_dir: /kaggle/working/simsiam_task4/ablation_epochs_100 ===\n\nEpoch 1/100 completed - Avg Loss: -0.3544\n                                                                                         \nEpoch 2/100 completed - Avg Loss: -0.6602\n                                                                                         \nEpoch 3/100 completed - Avg Loss: -0.8142\n                                                                                         \nEpoch 4/100 completed - Avg Loss: -0.8335\n                                                                                         \nEpoch 5/100 completed - Avg Loss: -0.8616\n                                                                                         \nEpoch 6/100 completed - Avg Loss: -0.8948\n                                                                                         \nEpoch 7/100 completed - Avg Loss: -0.8459\n                                                                                         \nEpoch 8/100 completed - Avg Loss: -0.8835\n                                                                                         \nEpoch 9/100 completed - Avg Loss: -0.9091\n                                                                                          \nEpoch 10/100 completed - Avg Loss: -0.9155\n                                                                                          \nEpoch 11/100 completed - Avg Loss: -0.9060\n                                                                                          \nEpoch 12/100 completed - Avg Loss: -0.9051\n                                                                                          \nEpoch 13/100 completed - Avg Loss: -0.9177\n                                                                                          \nEpoch 14/100 completed - Avg Loss: -0.9089\n                                                                                          \nEpoch 15/100 completed - Avg Loss: -0.9111\n                                                                                          \nEpoch 16/100 completed - Avg Loss: -0.9254\n                                                                                          \nEpoch 17/100 completed - Avg Loss: -0.9219\n                                                                                          \nEpoch 18/100 completed - Avg Loss: -0.9178\n                                                                                          \nEpoch 19/100 completed - Avg Loss: -0.8918\n                                                                                          \nEpoch 20/100 completed - Avg Loss: -0.9234\nSaved full checkpoint for epoch: 20 -> /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_020/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                                          \nEpoch 21/100 completed - Avg Loss: -0.9221\n                                                                                          \nEpoch 22/100 completed - Avg Loss: -0.9404\n                                                                                          \nEpoch 23/100 completed - Avg Loss: -0.9371\n                                                                                          \nEpoch 24/100 completed - Avg Loss: -0.9062\n                                                                                          \nEpoch 25/100 completed - Avg Loss: -0.8888\n                                                                                          \nEpoch 26/100 completed - Avg Loss: -0.9240\n                                                                                          \nEpoch 27/100 completed - Avg Loss: -0.9341\n                                                                                          \nEpoch 28/100 completed - Avg Loss: -0.9380\n                                                                                          \nEpoch 29/100 completed - Avg Loss: -0.9371\n                                                                                          \nEpoch 30/100 completed - Avg Loss: -0.9390\n                                                                                          \nEpoch 31/100 completed - Avg Loss: -0.9326\n                                                                                          \nEpoch 32/100 completed - Avg Loss: -0.9433\n                                                                                          \nEpoch 33/100 completed - Avg Loss: -0.9424\n                                                                                          \nEpoch 34/100 completed - Avg Loss: -0.9477\n                                                                                          \nEpoch 35/100 completed - Avg Loss: -0.9463\n                                                                                          \nEpoch 36/100 completed - Avg Loss: -0.9468\n                                                                                          \nEpoch 37/100 completed - Avg Loss: -0.9433\n                                                                                          \nEpoch 38/100 completed - Avg Loss: -0.9434\n                                                                                          \nEpoch 39/100 completed - Avg Loss: -0.9445\n                                                                                          \nEpoch 40/100 completed - Avg Loss: -0.9481\nSaved full checkpoint for epoch: 40 -> /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_040/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                                          \nEpoch 41/100 completed - Avg Loss: -0.9451\n                                                                                          \nEpoch 42/100 completed - Avg Loss: -0.9364\n                                                                                          \nEpoch 43/100 completed - Avg Loss: -0.9513\n                                                                                          \nEpoch 44/100 completed - Avg Loss: -0.9480\n                                                                                          \nEpoch 45/100 completed - Avg Loss: -0.9490\n                                                                                          \nEpoch 46/100 completed - Avg Loss: -0.9489\n                                                                                          \nEpoch 47/100 completed - Avg Loss: -0.9502\n                                                                                          \nEpoch 48/100 completed - Avg Loss: -0.9503\n                                                                                          \nEpoch 49/100 completed - Avg Loss: -0.9509\n                                                                                          \nEpoch 50/100 completed - Avg Loss: -0.9496\n                                                                                          \nEpoch 51/100 completed - Avg Loss: -0.9520\n                                                                                          \nEpoch 52/100 completed - Avg Loss: -0.9510\n                                                                                          \nEpoch 53/100 completed - Avg Loss: -0.9535\n                                                                                          \nEpoch 54/100 completed - Avg Loss: -0.9472\n                                                                                          \nEpoch 55/100 completed - Avg Loss: -0.9480\n                                                                                          \nEpoch 56/100 completed - Avg Loss: -0.9471\n                                                                                          \nEpoch 57/100 completed - Avg Loss: -0.9479\n                                                                                          \nEpoch 58/100 completed - Avg Loss: -0.9500\n                                                                                          \nEpoch 59/100 completed - Avg Loss: -0.9455\n                                                                                          \nEpoch 60/100 completed - Avg Loss: -0.9424\nSaved full checkpoint for epoch: 60 -> /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_060/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                                          \nEpoch 61/100 completed - Avg Loss: -0.9420\n                                                                                          \nEpoch 62/100 completed - Avg Loss: -0.9426\n                                                                                          \nEpoch 63/100 completed - Avg Loss: -0.9363\n                                                                                          \nEpoch 64/100 completed - Avg Loss: -0.9406\n                                                                                          \nEpoch 65/100 completed - Avg Loss: -0.9366\n                                                                                          \nEpoch 66/100 completed - Avg Loss: -0.9419\n                                                                                          \nEpoch 67/100 completed - Avg Loss: -0.9453\n                                                                                          \nEpoch 68/100 completed - Avg Loss: -0.9445\n                                                                                          \nEpoch 69/100 completed - Avg Loss: -0.9445\n                                                                                          \nEpoch 71/100 completed - Avg Loss: -0.9411\n                                                                                          \nEpoch 72/100 completed - Avg Loss: -0.9436\n                                                                                          \nEpoch 73/100 completed - Avg Loss: -0.9392\n                                                                                          \nEpoch 74/100 completed - Avg Loss: -0.9386\n                                                                                          \nEpoch 75/100 completed - Avg Loss: -0.9390\n                                                                                          \nEpoch 76/100 completed - Avg Loss: -0.9381\n                                                                                          \nEpoch 77/100 completed - Avg Loss: -0.9356\n                                                                                          \nEpoch 78/100 completed - Avg Loss: -0.9323\n                                                                                          \nEpoch 79/100 completed - Avg Loss: -0.9391       \n                                                                                          \nEpoch 80/100 completed - Avg Loss: -0.9388\n\nEpoch 81/100 completed - Avg Loss: -0.9401\n                                                                           \nEpoch 82/100 completed - Avg Loss: -0.9332\n                                                                           \nEpoch 83/100 completed - Avg Loss: -0.9370\n                                                                           \nEpoch 84/100 completed - Avg Loss: -0.9354\n                                                                           \nEpoch 85/100 completed - Avg Loss: -0.9359\nSaved full checkpoint for epoch: 85 ->  /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_085/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                           \nEpoch 86/100 completed - Avg Loss: -0.9361\n                                                                           \nEpoch 87/100 completed - Avg Loss: -0.9341\n                                                                           \nEpoch 88/100 completed - Avg Loss: -0.9346\n                                                                           \nEpoch 89/100 completed - Avg Loss: -0.9357\n                                                                           \nEpoch 90/100 completed - Avg Loss: -0.9347\nSaved full checkpoint for epoch: 90 ->  /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_090/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                           \nEpoch 91/100 completed - Avg Loss: -0.9339\n                                                                           \nEpoch 92/100 completed - Avg Loss: -0.9330\n                                                                           \nEpoch 93/100 completed - Avg Loss: -0.9331\n                                                                           \nEpoch 94/100 completed - Avg Loss: -0.9349\n                                                                           \nEpoch 95/100 completed - Avg Loss: -0.9344\nSaved full checkpoint for epoch: 95 ->  /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_095/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                           \nEpoch 96/100 completed - Avg Loss: -0.9338\n                                                                           \nEpoch 97/100 completed - Avg Loss: -0.9341\n                                                                           \nEpoch 98/100 completed - Avg Loss: -0.9315\n                                                                           \nEpoch 99/100 completed - Avg Loss: -0.9322\n                                                                            \nEpoch 100/100 completed - Avg Loss: -0.9313\nSaved full checkpoint for epoch: 100 ->  /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_100/checkpoint.pth       \nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n\"\"\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T14:58:14.815626Z","iopub.execute_input":"2025-12-07T14:58:14.816237Z","iopub.status.idle":"2025-12-07T14:58:14.830574Z","shell.execute_reply.started":"2025-12-07T14:58:14.816210Z","shell.execute_reply":"2025-12-07T14:58:14.829788Z"}},"outputs":[{"name":"stdout","text":"\n=== Ablation config: 100 epochs | saving every 20 epochs | run_dir: /kaggle/working/simsiam_task4/ablation_epochs_100 ===\n\nEpoch 1/100 completed - Avg Loss: -0.3544\n                                                                                         \nEpoch 2/100 completed - Avg Loss: -0.6602\n                                                                                         \nEpoch 3/100 completed - Avg Loss: -0.8142\n                                                                                         \nEpoch 4/100 completed - Avg Loss: -0.8335\n                                                                                         \nEpoch 5/100 completed - Avg Loss: -0.8616\n                                                                                         \nEpoch 6/100 completed - Avg Loss: -0.8948\n                                                                                         \nEpoch 7/100 completed - Avg Loss: -0.8459\n                                                                                         \nEpoch 8/100 completed - Avg Loss: -0.8835\n                                                                                         \nEpoch 9/100 completed - Avg Loss: -0.9091\n                                                                                          \nEpoch 10/100 completed - Avg Loss: -0.9155\n                                                                                          \nEpoch 11/100 completed - Avg Loss: -0.9060\n                                                                                          \nEpoch 12/100 completed - Avg Loss: -0.9051\n                                                                                          \nEpoch 13/100 completed - Avg Loss: -0.9177\n                                                                                          \nEpoch 14/100 completed - Avg Loss: -0.9089\n                                                                                          \nEpoch 15/100 completed - Avg Loss: -0.9111\n                                                                                          \nEpoch 16/100 completed - Avg Loss: -0.9254\n                                                                                          \nEpoch 17/100 completed - Avg Loss: -0.9219\n                                                                                          \nEpoch 18/100 completed - Avg Loss: -0.9178\n                                                                                          \nEpoch 19/100 completed - Avg Loss: -0.8918\n                                                                                          \nEpoch 20/100 completed - Avg Loss: -0.9234\nSaved full checkpoint for epoch: 20 -> /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_020/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                                          \nEpoch 21/100 completed - Avg Loss: -0.9221\n                                                                                          \nEpoch 22/100 completed - Avg Loss: -0.9404\n                                                                                          \nEpoch 23/100 completed - Avg Loss: -0.9371\n                                                                                          \nEpoch 24/100 completed - Avg Loss: -0.9062\n                                                                                          \nEpoch 25/100 completed - Avg Loss: -0.8888\n                                                                                          \nEpoch 26/100 completed - Avg Loss: -0.9240\n                                                                                          \nEpoch 27/100 completed - Avg Loss: -0.9341\n                                                                                          \nEpoch 28/100 completed - Avg Loss: -0.9380\n                                                                                          \nEpoch 29/100 completed - Avg Loss: -0.9371\n                                                                                          \nEpoch 30/100 completed - Avg Loss: -0.9390\n                                                                                          \nEpoch 31/100 completed - Avg Loss: -0.9326\n                                                                                          \nEpoch 32/100 completed - Avg Loss: -0.9433\n                                                                                          \nEpoch 33/100 completed - Avg Loss: -0.9424\n                                                                                          \nEpoch 34/100 completed - Avg Loss: -0.9477\n                                                                                          \nEpoch 35/100 completed - Avg Loss: -0.9463\n                                                                                          \nEpoch 36/100 completed - Avg Loss: -0.9468\n                                                                                          \nEpoch 37/100 completed - Avg Loss: -0.9433\n                                                                                          \nEpoch 38/100 completed - Avg Loss: -0.9434\n                                                                                          \nEpoch 39/100 completed - Avg Loss: -0.9445\n                                                                                          \nEpoch 40/100 completed - Avg Loss: -0.9481\nSaved full checkpoint for epoch: 40 -> /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_040/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                                          \nEpoch 41/100 completed - Avg Loss: -0.9451\n                                                                                          \nEpoch 42/100 completed - Avg Loss: -0.9364\n                                                                                          \nEpoch 43/100 completed - Avg Loss: -0.9513\n                                                                                          \nEpoch 44/100 completed - Avg Loss: -0.9480\n                                                                                          \nEpoch 45/100 completed - Avg Loss: -0.9490\n                                                                                          \nEpoch 46/100 completed - Avg Loss: -0.9489\n                                                                                          \nEpoch 47/100 completed - Avg Loss: -0.9502\n                                                                                          \nEpoch 48/100 completed - Avg Loss: -0.9503\n                                                                                          \nEpoch 49/100 completed - Avg Loss: -0.9509\n                                                                                          \nEpoch 50/100 completed - Avg Loss: -0.9496\n                                                                                          \nEpoch 51/100 completed - Avg Loss: -0.9520\n                                                                                          \nEpoch 52/100 completed - Avg Loss: -0.9510\n                                                                                          \nEpoch 53/100 completed - Avg Loss: -0.9535\n                                                                                          \nEpoch 54/100 completed - Avg Loss: -0.9472\n                                                                                          \nEpoch 55/100 completed - Avg Loss: -0.9480\n                                                                                          \nEpoch 56/100 completed - Avg Loss: -0.9471\n                                                                                          \nEpoch 57/100 completed - Avg Loss: -0.9479\n                                                                                          \nEpoch 58/100 completed - Avg Loss: -0.9500\n                                                                                          \nEpoch 59/100 completed - Avg Loss: -0.9455\n                                                                                          \nEpoch 60/100 completed - Avg Loss: -0.9424\nSaved full checkpoint for epoch: 60 -> /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_060/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                                          \nEpoch 61/100 completed - Avg Loss: -0.9420\n                                                                                          \nEpoch 62/100 completed - Avg Loss: -0.9426\n                                                                                          \nEpoch 63/100 completed - Avg Loss: -0.9363\n                                                                                          \nEpoch 64/100 completed - Avg Loss: -0.9406\n                                                                                          \nEpoch 65/100 completed - Avg Loss: -0.9366\n                                                                                          \nEpoch 66/100 completed - Avg Loss: -0.9419\n                                                                                          \nEpoch 67/100 completed - Avg Loss: -0.9453\n                                                                                          \nEpoch 68/100 completed - Avg Loss: -0.9445\n                                                                                          \nEpoch 69/100 completed - Avg Loss: -0.9445\n                                                                                          \nEpoch 71/100 completed - Avg Loss: -0.9411\n                                                                                          \nEpoch 72/100 completed - Avg Loss: -0.9436\n                                                                                          \nEpoch 73/100 completed - Avg Loss: -0.9392\n                                                                                          \nEpoch 74/100 completed - Avg Loss: -0.9386\n                                                                                          \nEpoch 75/100 completed - Avg Loss: -0.9390\n                                                                                          \nEpoch 76/100 completed - Avg Loss: -0.9381\n                                                                                          \nEpoch 77/100 completed - Avg Loss: -0.9356\n                                                                                          \nEpoch 78/100 completed - Avg Loss: -0.9323\n                                                                                          \nEpoch 79/100 completed - Avg Loss: -0.9391       \n                                                                                          \nEpoch 80/100 completed - Avg Loss: -0.9388\n\nEpoch 81/100 completed - Avg Loss: -0.9401\n                                                                           \nEpoch 82/100 completed - Avg Loss: -0.9332\n                                                                           \nEpoch 83/100 completed - Avg Loss: -0.9370\n                                                                           \nEpoch 84/100 completed - Avg Loss: -0.9354\n                                                                           \nEpoch 85/100 completed - Avg Loss: -0.9359\nSaved full checkpoint for epoch: 85 ->  /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_085/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                           \nEpoch 86/100 completed - Avg Loss: -0.9361\n                                                                           \nEpoch 87/100 completed - Avg Loss: -0.9341\n                                                                           \nEpoch 88/100 completed - Avg Loss: -0.9346\n                                                                           \nEpoch 89/100 completed - Avg Loss: -0.9357\n                                                                           \nEpoch 90/100 completed - Avg Loss: -0.9347\nSaved full checkpoint for epoch: 90 ->  /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_090/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                           \nEpoch 91/100 completed - Avg Loss: -0.9339\n                                                                           \nEpoch 92/100 completed - Avg Loss: -0.9330\n                                                                           \nEpoch 93/100 completed - Avg Loss: -0.9331\n                                                                           \nEpoch 94/100 completed - Avg Loss: -0.9349\n                                                                           \nEpoch 95/100 completed - Avg Loss: -0.9344\nSaved full checkpoint for epoch: 95 ->  /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_095/checkpoint.pth\nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n                                                                           \nEpoch 96/100 completed - Avg Loss: -0.9338\n                                                                           \nEpoch 97/100 completed - Avg Loss: -0.9341\n                                                                           \nEpoch 98/100 completed - Avg Loss: -0.9315\n                                                                           \nEpoch 99/100 completed - Avg Loss: -0.9322\n                                                                            \nEpoch 100/100 completed - Avg Loss: -0.9313\nSaved full checkpoint for epoch: 100 ->  /kaggle/working/simsiam_task4/ablation_epochs_100/epoch_100/checkpoint.pth       \nSaved ZIP backup to: /kaggle/working/simsiam_ablation_epochs_100.zip\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ===== Manifest path-fixer cell =====\n# Run this cell BEFORE the Ablation / Ratio cells to fix broken file paths in split_manifest.json.\nimport os, json, glob\nfrom pathlib import Path\n\n# CONFIG - edit only if your files live elsewhere\nORIGINAL_SPLIT_MANIFEST = \"/kaggle/input/simsiam-task4-archive/split_manifest.json\"\nDATASET_ROOT = \"/kaggle/input/betel-leaf\"   # where the dataset images live\nOUTPUT_FIXED_MANIFEST = \"/kaggle/working/corrected_split_manifest.json\"\nMISSING_LIST = \"/kaggle/working/missing_files.txt\"\n\nprint(\"Loading manifest:\", ORIGINAL_SPLIT_MANIFEST)\nwith open(ORIGINAL_SPLIT_MANIFEST, \"r\") as f:\n    manifest = json.load(f)\n\n# Expect lists named \"train\",\"val\",\"test\" and label lists \"train_labels\", etc.\nsplits = [\"train\", \"val\", \"test\"]\nlabel_keys = {\"train\":\"train_labels\", \"val\":\"val_labels\", \"test\":\"test_labels\"}\n\nfixed = {k: [] for k in manifest if isinstance(manifest.get(k), list)}\nmissing = []\n\n# Build a fast index of available files under DATASET_ROOT by basename -> fullpath (first match wins)\nprint(\"Indexing dataset files under\", DATASET_ROOT, \" (this may take a few seconds)...\")\nall_files = list(Path(DATASET_ROOT).rglob(\"*.*\"))\nbasename_index = {}\nfor p in all_files:\n    b = p.name\n    if b not in basename_index:\n        basename_index[b] = str(p)\n\nprint(\"Indexed\", len(all_files), \"files. Unique basenames:\", len(basename_index))\n\nfor s in splits:\n    paths = manifest.get(s, [])\n    labels = manifest.get(label_keys[s], [])\n    if len(labels) != len(paths):\n        print(f\"Warning: split {s} has mismatched counts: {len(paths)} paths vs {len(labels)} labels. Will align by min length.\")\n    new_paths = []\n    new_labels = []\n    for i, p in enumerate(paths):\n        if p is None: \n            missing.append((s, p))\n            continue\n        # If absolute path exists as-is, keep\n        if os.path.exists(p):\n            new_paths.append(p)\n            if i < len(labels):\n                new_labels.append(labels[i])\n            continue\n        # Try common adjustments: sometimes manifest paths are missing a prefix. Try joining with DATASET_ROOT\n        candidate1 = os.path.join(DATASET_ROOT, p) if not p.startswith(DATASET_ROOT) else p\n        if os.path.exists(candidate1):\n            new_paths.append(candidate1)\n            if i < len(labels):\n                new_labels.append(labels[i])\n            continue\n        # Try basename lookup in dataset\n        b = os.path.basename(p)\n        if b in basename_index:\n            found = basename_index[b]\n            new_paths.append(found)\n            if i < len(labels):\n                new_labels.append(labels[i])\n            continue\n        # Try searching for similar basenames with partial match (rare) - look for any file containing the basename fragment\n        candidates = [str(pp) for pp in all_files if b.split(\".\")[0] in pp.name]\n        if len(candidates) == 1:\n            new_paths.append(candidates[0])\n            if i < len(labels):\n                new_labels.append(labels[i])\n            continue\n        # Couldn't find it\n        missing.append((s, p))\n    fixed[s] = new_paths\n    fixed[label_keys[s]] = new_labels\n\n# Keep other keys intact (classes, any metadata)\nfor k,v in manifest.items():\n    if k not in fixed:\n        fixed[k] = v\n\n# Save corrected manifest\nwith open(OUTPUT_FIXED_MANIFEST, \"w\") as f:\n    json.dump(fixed, f, indent=2)\n\nprint(\"Saved corrected manifest to:\", OUTPUT_FIXED_MANIFEST)\nprint(\"Total missing references that could not be resolved:\", len(missing))\nif len(missing) > 0:\n    print(\"Writing missing list to\", MISSING_LIST)\n    with open(MISSING_LIST, \"w\") as fm:\n        for s,p in missing:\n            fm.write(f\"{s}\\t{p}\\n\")\n    print(\"Sample of missing entries (first 20):\")\n    for e in missing[:20]:\n        print(\"-\", e)\n\n# Helpful tips for next steps\nprint(\"\\nNext steps:\")\nprint(\"1) Inspect\", MISSING_LIST, \"to check whether files are truly missing or misnamed.\")\nprint(\"2) If many files are missing, you may need to re-upload dataset files or ask teammates.\")\nprint(\"3) Re-run the Ablation cell after replacing SPLIT_MANIFEST path with this corrected manifest path.\")\nprint(\"\\nIf you want, I can automatically update the Ablation/Ratio cells to use this corrected manifest path (/kaggle/working/corrected_split_manifest.json).\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T12:31:35.814010Z","iopub.execute_input":"2025-12-06T12:31:35.814762Z","iopub.status.idle":"2025-12-06T12:31:40.718846Z","shell.execute_reply.started":"2025-12-06T12:31:35.814733Z","shell.execute_reply":"2025-12-06T12:31:40.718066Z"}},"outputs":[{"name":"stdout","text":"Loading manifest: /kaggle/input/simsiam-task4-archive/split_manifest.json\nIndexing dataset files under /kaggle/input/betel-leaf  (this may take a few seconds)...\nIndexed 1800 files. Unique basenames: 1800\nSaved corrected manifest to: /kaggle/working/corrected_split_manifest.json\nTotal missing references that could not be resolved: 0\n\nNext steps:\n1) Inspect /kaggle/working/missing_files.txt to check whether files are truly missing or misnamed.\n2) If many files are missing, you may need to re-upload dataset files or ask teammates.\n3) Re-run the Ablation cell after replacing SPLIT_MANIFEST path with this corrected manifest path.\n\nIf you want, I can automatically update the Ablation/Ratio cells to use this corrected manifest path (/kaggle/working/corrected_split_manifest.json).\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ===== CELL A: Ablation Evaluation (epoch_020 -> epoch_100) =====\n# Self-contained cell — paste into a new notebook (after runtime GPU selection).\nimport os, json, time, shutil, glob\nfrom pathlib import Path\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom torchvision import transforms, models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\nfrom sklearn.metrics import precision_recall_fscore_support, silhouette_score\nfrom sklearn.preprocessing import label_binarize\nimport joblib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# -------- Config (edit if needed) --------\nBACKBONE = \"resnet18\"\nRESOLUTION = 224\nBATCH_SIZE = 64\nNUM_WORKERS = 2\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nOUT_ROOT = \"/kaggle/working/task7_ablation\"   # outputs saved here\nos.makedirs(OUT_ROOT, exist_ok=True)\n\n# Uploaded locations (from your Kaggle dataset structure)\nSPLIT_MANIFEST = \"/kaggle/working/corrected_split_manifest.json\"   # your split manifest. :contentReference[oaicite:6]{index=6}\nABLATION_BASE = \"/kaggle/input/all-files/All Files/simsiam_ablation_epochs_100\"  # folder with epoch_* subfolders. :contentReference[oaicite:7]{index=7}\n\n# Classifier list (same as your probe list)\nCLASSIFIERS = {\n    \"LogisticRegression\": LogisticRegression(max_iter=2000),\n    \"SVM_RBF\": SVC(kernel=\"rbf\", probability=True),\n    \"RandomForest\": RandomForestClassifier(n_estimators=100),\n    \"DecisionTree\": DecisionTreeClassifier(),\n    \"MLP\": MLPClassifier(hidden_layer_sizes=(512,), max_iter=500)\n}\n\n# Use these flags to control heavy operations\nDO_FINETUNE = False   # set True only if you want to fine-tune encoder for each checkpoint (very heavy)\nRUN_LABEL_EFFICIENCY = True  # compute label-efficiency curves per checkpoint (costly but useful)\n\n# -------- Helpers --------\ndef build_encoder(backbone=\"resnet18\"):\n    if backbone == \"resnet18\":\n        base = models.resnet18(weights=None)\n        feat_dim = 512\n    elif backbone == \"resnet50\":\n        base = models.resnet50(weights=None)\n        feat_dim = 2048\n    else:\n        raise ValueError(\"Unsupported backbone\")\n    modules = list(base.children())[:-1]\n    encoder = nn.Sequential(*modules)\n    encoder.feat_dim = feat_dim\n    return encoder\n\ndef try_load_encoder(encoder, path):\n    ck = torch.load(path, map_location=\"cpu\")\n    # many checkpoint formats: try to find encoder state dict\n    if isinstance(ck, dict):\n        # common keys\n        for key in [\"encoder_state_dict\", \"encoder\", \"model_state\", \"model\", \"state_dict\"]:\n            if key in ck:\n                st = ck[key]\n                break\n        else:\n            st = ck\n    else:\n        st = ck\n    # try direct load; if fails, try mapping prefixes\n    try:\n        encoder.load_state_dict(st)\n        return True\n    except Exception:\n        mapped = {}\n        for k,v in st.items():\n            newk = k\n            if k.startswith(\"encoder.\"):\n                newk = k.replace(\"encoder.\", \"\")\n            if k.startswith(\"module.encoder.\"):\n                newk = k.replace(\"module.encoder.\", \"\")\n            mapped[newk] = v\n        try:\n            encoder.load_state_dict(mapped)\n            return True\n        except Exception as e:\n            print(\"Failed to load encoder weights from\", path, \"error:\", e)\n            return False\n\n# Dataset wrapper using split_manifest paths\nclass ManifestDataset(Dataset):\n    def __init__(self, paths, labels, transform=None):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        lbl = self.labels[idx]\n        img = Image.open(p).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, lbl, p\n\neval_transform = transforms.Compose([\n    transforms.Resize(int(RESOLUTION * 1.1)),\n    transforms.CenterCrop(RESOLUTION),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\n\ndef extract_features(encoder, paths, batch_size=64, workers=2, save_path=None):\n    ds = ManifestDataset(paths, [0]*len(paths), transform=eval_transform)\n    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=workers)\n    feats = []\n    encoder.eval()\n    enc = encoder.to(DEVICE)\n    with torch.no_grad():\n        for imgs, _, _ in loader:\n            imgs = imgs.to(DEVICE)\n            h = enc(imgs).view(imgs.size(0), -1).cpu().numpy()\n            feats.append(h)\n    feats = np.vstack(feats)\n    if save_path:\n        np.save(save_path, feats)\n    return feats\n\ndef train_and_eval_probes(train_feats, train_labels, val_feats, val_labels, test_feats, test_labels, out_prefix):\n    results = {}\n    for name, clf in CLASSIFIERS.items():\n        print(\"Training probe:\", name)\n        # clone classifier instance to avoid scikit state reuse\n        import copy\n        clf_local = copy.deepcopy(clf)\n        clf_local.fit(train_feats, train_labels)\n        # save model\n        joblib.dump(clf_local, out_prefix + f\"_{name}.joblib\")\n        # metrics\n        y_pred = clf_local.predict(test_feats)\n        acc = accuracy_score(test_labels, y_pred)\n        prec, rec, f1, supp = precision_recall_fscore_support(test_labels, y_pred, average=None, zero_division=0)\n        # per-class auc if predict_proba available\n        aucs = {}\n        try:\n            if hasattr(clf_local, \"predict_proba\"):\n                probs = clf_local.predict_proba(test_feats)\n                y_bin = label_binarize(test_labels, classes=list(range(np.max(test_labels)+1)))\n                # compute per-class AUC safely\n                for i in range(y_bin.shape[1]):\n                    try:\n                        aucs[i] = float(roc_auc_score(y_bin[:,i], probs[:,i]))\n                    except Exception:\n                        aucs[i] = None\n                macro = roc_auc_score(y_bin, probs, average=\"macro\")\n                micro = roc_auc_score(y_bin, probs, average=\"micro\")\n            else:\n                aucs = None\n                macro = None; micro = None\n        except Exception as e:\n            aucs = None; macro = None; micro = None\n        results[name] = {\n            \"accuracy\": float(acc),\n            \"per_class_prec\": prec.tolist(),\n            \"per_class_rec\": rec.tolist(),\n            \"per_class_f1\": f1.tolist(),\n            \"per_class_support\": supp.tolist(),\n            \"per_class_auc\": aucs,\n            \"macro_auc\": float(macro) if macro is not None else None,\n            \"micro_auc\": float(micro) if micro is not None else None\n        }\n    return results\n\n# -------- Load split manifest (train/val/test lists) --------\nwith open(SPLIT_MANIFEST, \"r\") as f:\n    split = json.load(f)\ntrain_paths = split[\"train\"]\ntrain_labels = split[\"train_labels\"]\nval_paths = split[\"val\"]\nval_labels = split[\"val_labels\"]\ntest_paths = split[\"test\"]\ntest_labels = split[\"test_labels\"]\nclasses = split.get(\"classes\", None)\nif classes is None:\n    classes = [str(i) for i in range(max(train_labels)+1)]\n\n# -------- Find ablation checkpoint subfolders --------\nepoch_dirs = sorted(glob.glob(os.path.join(ABLATION_BASE, \"epoch_*\")))\nprint(\"Found ablation epoch dirs:\", epoch_dirs)\n\nablation_summary = []\nfor ed in epoch_dirs:\n    try:\n        epoch_name = os.path.basename(ed)\n        enc_path = os.path.join(ed, \"encoder.pth\")\n        if not os.path.exists(enc_path):\n            print(\"No encoder.pth in\", ed, \"skipping\")\n            continue\n        print(\"Processing\", epoch_name)\n        out_dir = os.path.join(OUT_ROOT, epoch_name)\n        os.makedirs(out_dir, exist_ok=True)\n        # Build encoder and load weights\n        encoder = build_encoder(BACKBONE)\n        ok = try_load_encoder(encoder, enc_path)\n        if not ok:\n            print(\"Failed to load encoder for\", epoch_name)\n            continue\n\n        # Extract features if not cached\n        train_feat_path = os.path.join(out_dir, \"train_feats.npy\")\n        val_feat_path = os.path.join(out_dir, \"val_feats.npy\")\n        test_feat_path = os.path.join(out_dir, \"test_feats.npy\")\n\n        if not (os.path.exists(train_feat_path) and os.path.exists(val_feat_path) and os.path.exists(test_feat_path)):\n            print(\"Extracting features for\", epoch_name)\n            tr_feats = extract_features(encoder, train_paths, batch_size=BATCH_SIZE, workers=NUM_WORKERS, save_path=train_feat_path)\n            v_feats = extract_features(encoder, val_paths, batch_size=BATCH_SIZE, workers=NUM_WORKERS, save_path=val_feat_path)\n            te_feats = extract_features(encoder, test_paths, batch_size=BATCH_SIZE, workers=NUM_WORKERS, save_path=test_feat_path)\n        else:\n            print(\"Loading cached features for\", epoch_name)\n            tr_feats = np.load(train_feat_path)\n            v_feats = np.load(val_feat_path)\n            te_feats = np.load(test_feat_path)\n\n        # compute silhouette on concatenated features (quick)\n        try:\n            feats_all = np.vstack([tr_feats, v_feats, te_feats])\n            lbls_all = np.array(train_labels + val_labels + test_labels)\n            sil = silhouette_score(feats_all, lbls_all) if len(np.unique(lbls_all))>1 else None\n        except Exception as e:\n            print(\"Silhouette failed:\", e)\n            sil = None\n\n        # Train probes and get results\n        probe_results = train_and_eval_probes(tr_feats, train_labels, v_feats, val_labels, te_feats, test_labels, out_prefix=os.path.join(out_dir, \"probe\"))\n\n        # Label-efficiency (optional) - train logistic on fractions\n        label_eff = {}\n        if RUN_LABEL_EFFICIENCY:\n            fractions = [0.01, 0.05, 0.10, 0.25, 0.50, 1.0]\n            total = tr_feats.shape[0]\n            for frac in fractions:\n                n = max(1, int(total * frac))\n                # simple stratified subsample\n                idxs = np.arange(total)\n                rng = np.random.RandomState(42)\n                # naive selection, better to per-class sample but for brevity:\n                sel = rng.choice(idxs, size=n, replace=False)\n                clf = LogisticRegression(max_iter=2000)\n                clf.fit(tr_feats[sel], np.array(train_labels)[sel])\n                pred = clf.predict(te_feats)\n                acc = accuracy_score(test_labels, pred)\n                label_eff[f\"{int(frac*100)}%\"] = float(acc)\n\n            # save\n            with open(os.path.join(out_dir, \"label_efficiency.json\"), \"w\") as f:\n                json.dump(label_eff, f, indent=2)\n\n        # Save summary for this epoch\n        summary = {\n            \"epoch_dir\": epoch_name,\n            \"enc_path\": enc_path,\n            \"silhouette\": float(sil) if sil is not None else None,\n            \"probe_results\": probe_results,\n            \"label_efficiency\": label_eff\n        }\n        ablation_summary.append(summary)\n        with open(os.path.join(out_dir, \"ablation_summary.json\"), \"w\") as f:\n            json.dump(summary, f, indent=2)\n\n        # Save confusion matrix plots for each probe\n        for name in probe_results.keys():\n            # load saved model if exists\n            try:\n                clf = joblib.load(os.path.join(out_dir, f\"probe_{name}.joblib\"))\n            except Exception:\n                clf = None\n            if clf is None: continue\n            y_pred = clf.predict(te_feats)\n            cm = confusion_matrix(test_labels, y_pred)\n            plt.figure(figsize=(6,5))\n            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n            plt.title(f\"Confusion Matrix - {epoch_name} - {name}\")\n            plt.savefig(os.path.join(out_dir, f\"confusion_{name}.png\"))\n            plt.close()\n\n    except Exception as e:\n        print(\"Error processing\", ed, e)\n\n# Save aggregated ablation summary\nwith open(os.path.join(OUT_ROOT, \"ablation_results.json\"), \"w\") as f:\n    json.dump(ablation_summary, f, indent=2)\n\n# Create CSV summary table\nimport csv\ncsv_path = os.path.join(OUT_ROOT, \"ablation_table.csv\")\nwith open(csv_path, \"w\", newline=\"\") as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow([\"epoch_dir\",\"silhouette\",\"probe_name\",\"accuracy\",\"macro_auc\",\"micro_auc\"])\n    for s in ablation_summary:\n        ed = s[\"epoch_dir\"]\n        sil = s[\"silhouette\"]\n        for probe_name, pr in s[\"probe_results\"].items():\n            writer.writerow([ed, sil, probe_name, pr.get(\"accuracy\", None), pr.get(\"macro_auc\", None), pr.get(\"micro_auc\", None)])\n\n# Zip outputs\nzipname = os.path.join(\"/kaggle/working\", \"task7_ablation_outputs\")\nif os.path.exists(zipname + \".zip\"):\n    os.remove(zipname + \".zip\")\nshutil.make_archive(base_name=zipname, format=\"zip\", root_dir=OUT_ROOT)\nprint(\"Ablation outputs zipped to\", zipname + \".zip\")\nprint(\"Done. Outputs in\", OUT_ROOT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T12:31:55.185752Z","iopub.execute_input":"2025-12-06T12:31:55.186079Z","iopub.status.idle":"2025-12-06T13:37:06.855478Z","shell.execute_reply.started":"2025-12-06T12:31:55.186057Z","shell.execute_reply":"2025-12-06T13:37:06.854667Z"}},"outputs":[{"name":"stdout","text":"Found ablation epoch dirs: ['/kaggle/input/all-files/All Files/simsiam_ablation_epochs_100/epoch_020', '/kaggle/input/all-files/All Files/simsiam_ablation_epochs_100/epoch_040', '/kaggle/input/all-files/All Files/simsiam_ablation_epochs_100/epoch_060', '/kaggle/input/all-files/All Files/simsiam_ablation_epochs_100/epoch_080', '/kaggle/input/all-files/All Files/simsiam_ablation_epochs_100/epoch_085', '/kaggle/input/all-files/All Files/simsiam_ablation_epochs_100/epoch_090', '/kaggle/input/all-files/All Files/simsiam_ablation_epochs_100/epoch_095', '/kaggle/input/all-files/All Files/simsiam_ablation_epochs_100/epoch_100']\nProcessing epoch_020\nExtracting features for epoch_020\nTraining probe: LogisticRegression\nTraining probe: SVM_RBF\nTraining probe: RandomForest\nTraining probe: DecisionTree\nTraining probe: MLP\nProcessing epoch_040\nExtracting features for epoch_040\nTraining probe: LogisticRegression\nTraining probe: SVM_RBF\nTraining probe: RandomForest\nTraining probe: DecisionTree\nTraining probe: MLP\nProcessing epoch_060\nExtracting features for epoch_060\nTraining probe: LogisticRegression\nTraining probe: SVM_RBF\nTraining probe: RandomForest\nTraining probe: DecisionTree\nTraining probe: MLP\nProcessing epoch_080\nExtracting features for epoch_080\nTraining probe: LogisticRegression\nTraining probe: SVM_RBF\nTraining probe: RandomForest\nTraining probe: DecisionTree\nTraining probe: MLP\nProcessing epoch_085\nExtracting features for epoch_085\nTraining probe: LogisticRegression\nTraining probe: SVM_RBF\nTraining probe: RandomForest\nTraining probe: DecisionTree\nTraining probe: MLP\nProcessing epoch_090\nExtracting features for epoch_090\nTraining probe: LogisticRegression\nTraining probe: SVM_RBF\nTraining probe: RandomForest\nTraining probe: DecisionTree\nTraining probe: MLP\nProcessing epoch_095\nExtracting features for epoch_095\nTraining probe: LogisticRegression\nTraining probe: SVM_RBF\nTraining probe: RandomForest\nTraining probe: DecisionTree\nTraining probe: MLP\nProcessing epoch_100\nExtracting features for epoch_100\nTraining probe: LogisticRegression\nTraining probe: SVM_RBF\nTraining probe: RandomForest\nTraining probe: DecisionTree\nTraining probe: MLP\nAblation outputs zipped to /kaggle/working/task7_ablation_outputs.zip\nDone. Outputs in /kaggle/working/task7_ablation\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ===== FIXED CELL B (final): Ratio Sweep Evaluation (robust integer split) =====\n# Paste into a notebook. This replaces previous CELL B and fixes the \"sum > N\" error.\nimport os, json, time, shutil\nfrom pathlib import Path\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, precision_recall_fscore_support\nfrom sklearn.preprocessing import label_binarize\nimport joblib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy.random as npr\n\n# -------- Config --------\nBACKBONE = \"resnet18\"\nRESOLUTION = 224\nBATCH_SIZE = 64\nNUM_WORKERS = 2\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nOUT_ROOT = \"/kaggle/working/task7_ratios\"\nos.makedirs(OUT_ROOT, exist_ok=True)\n\n# Files (uploaded)\nSPLIT_MANIFEST = \"/kaggle/input/simsiam-task4-archive/split_manifest.json\"\nBASE_FEATURES_DIR = \"/kaggle/input/all-files/All Files\"\nBASE_TRAIN_FEATS = os.path.join(BASE_FEATURES_DIR, \"train_feats.npy\")\nBASE_TRAIN_LABELS = os.path.join(BASE_FEATURES_DIR, \"train_labels.npy\")\nBASE_VAL_FEATS = os.path.join(BASE_FEATURES_DIR, \"val_feats.npy\")\nBASE_VAL_LABELS = os.path.join(BASE_FEATURES_DIR, \"val_labels.npy\")\nBASE_TEST_FEATS = os.path.join(BASE_FEATURES_DIR, \"test_feats.npy\")\nBASE_TEST_LABELS = os.path.join(BASE_FEATURES_DIR, \"test_labels.npy\")\n\nCLASSIFIERS = {\n    \"LogisticRegression\": LogisticRegression(max_iter=2000),\n    \"SVM_RBF\": SVC(kernel=\"rbf\", probability=True),\n    \"RandomForest\": RandomForestClassifier(n_estimators=100),\n    \"DecisionTree\": DecisionTreeClassifier(),\n    \"MLP\": MLPClassifier(hidden_layer_sizes=(512,), max_iter=500)\n}\n\n# -------- Helpers (feature extraction kept for fallback) --------\nclass ImageDataset(Dataset):\n    def __init__(self, paths, labels, transform=None):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        lbl = self.labels[idx]\n        img = Image.open(p).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, lbl, p\n\neval_transform = transforms.Compose([\n    transforms.Resize(int(RESOLUTION * 1.1)),\n    transforms.CenterCrop(RESOLUTION),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\n\ndef build_encoder(backbone=\"resnet18\"):\n    if backbone == \"resnet18\":\n        base = models.resnet18(weights=None)\n        feat_dim = 512\n    elif backbone == \"resnet50\":\n        base = models.resnet50(weights=None)\n        feat_dim = 2048\n    else:\n        raise ValueError(\"Unsupported backbone\")\n    modules = list(base.children())[:-1]\n    encoder = nn.Sequential(*modules)\n    encoder.feat_dim = feat_dim\n    return encoder\n\ndef load_encoder_weights(encoder, ckpt_path):\n    ck = torch.load(ckpt_path, map_location=\"cpu\")\n    if isinstance(ck, dict):\n        for key in [\"encoder_state_dict\",\"encoder\",\"model_state\",\"state_dict\",\"model\"]:\n            if key in ck:\n                state = ck[key]; break\n        else:\n            state = ck\n    else:\n        state = ck\n    try:\n        encoder.load_state_dict(state)\n        return True\n    except Exception:\n        mapped = {}\n        for k,v in state.items():\n            newk = k\n            if k.startswith(\"encoder.\"): newk = k.replace(\"encoder.\",\"\")\n            if k.startswith(\"module.encoder.\"): newk = k.replace(\"module.encoder.\",\"\")\n            mapped[newk] = v\n        try:\n            encoder.load_state_dict(mapped)\n            return True\n        except Exception as e:\n            print(\"Failed to load encoder:\", e)\n            return False\n\ndef extract_features_from_paths(encoder, paths, batch_size=64, workers=2, save_path=None):\n    ds = ImageDataset(paths, [0]*len(paths), transform=eval_transform)\n    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=workers)\n    feats = []\n    encoder.eval()\n    enc = encoder.to(DEVICE)\n    with torch.no_grad():\n        for imgs, _, _ in loader:\n            imgs = imgs.to(DEVICE)\n            h = enc(imgs).view(imgs.size(0), -1).cpu().numpy()\n            feats.append(h)\n    feats = np.vstack(feats)\n    if save_path: np.save(save_path, feats)\n    return feats\n\n# Robust stratified subsampler for label-efficiency\ndef stratified_subsample_indices(y, k, random_state=42):\n    y = np.array(y)\n    n = len(y)\n    unique, counts = np.unique(y, return_counts=True)\n    n_classes = len(unique)\n    if n_classes < 2:\n        return None\n    if k < 2:\n        return None\n    rng = npr.RandomState(random_state)\n    try:\n        # attempt stratified train_test_split with train_size=k\n        train_idx, _ = train_test_split(np.arange(n), train_size=k, stratify=y, random_state=random_state)\n        if len(np.unique(y[train_idx])) >= 2:\n            return train_idx\n    except Exception:\n        pass\n    # fallback proportional per-class sampling\n    prop = counts / counts.sum()\n    desired = np.floor(prop * k).astype(int)\n    for i, uc in enumerate(unique):\n        if desired[i] == 0 and k >= n_classes and counts[i] > 0:\n            desired[i] = 1\n    rem = int(k - desired.sum())\n    if rem > 0:\n        leftover = (prop * k) - desired\n        order = np.argsort(-leftover)\n        for idx in order:\n            if rem <= 0:\n                break\n            desired[idx] += 1\n            rem -= 1\n    selected = []\n    for cls_idx, cls in enumerate(unique):\n        cls_inds = np.where(y == cls)[0]\n        cnt = desired[cls_idx]\n        if cnt <= 0:\n            continue\n        if cnt > len(cls_inds):\n            cnt = len(cls_inds)\n        chosen = rng.choice(cls_inds, size=cnt, replace=False)\n        selected.extend(chosen.tolist())\n    selected = np.array(selected, dtype=int)\n    if len(selected) < 2 or len(np.unique(y[selected])) < 2:\n        return None\n    if len(selected) > k:\n        selected = selected[:k]\n    return selected\n\n# -------- Read master manifest to get full file list and labels --------\nwith open(SPLIT_MANIFEST, \"r\") as f:\n    sm = json.load(f)\n\n# Build feats_all & labels_all using available cached files; fallback to extracting from images if needed\nfeats_all = None\nlabels_all = None\n\nhave_train = os.path.exists(BASE_TRAIN_FEATS) and os.path.exists(BASE_TRAIN_LABELS)\nhave_val = os.path.exists(BASE_VAL_FEATS) and os.path.exists(BASE_VAL_LABELS)\nhave_test = os.path.exists(BASE_TEST_FEATS) and os.path.exists(BASE_TEST_LABELS)\n\nif have_train and have_val and have_test:\n    tr = np.load(BASE_TRAIN_FEATS); tr_lbl = np.load(BASE_TRAIN_LABELS)\n    v = np.load(BASE_VAL_FEATS); v_lbl = np.load(BASE_VAL_LABELS)\n    te = np.load(BASE_TEST_FEATS); te_lbl = np.load(BASE_TEST_LABELS)\n    feats_all = np.vstack([tr, v, te])\n    labels_all = np.hstack([tr_lbl, v_lbl, te_lbl]).astype(int)\nelif have_train and have_test:\n    tr = np.load(BASE_TRAIN_FEATS); tr_lbl = np.load(BASE_TRAIN_LABELS)\n    te = np.load(BASE_TEST_FEATS); te_lbl = np.load(BASE_TEST_LABELS)\n    feats_all = np.vstack([tr, te])\n    labels_all = np.hstack([tr_lbl, te_lbl]).astype(int)\nelse:\n    # fallback: build list of image paths from manifest and extract features using encoder\n    print(\"No adequate cached features found — will extract features from images. This will take longer.\")\n    all_paths = sm[\"train\"] + sm[\"val\"] + sm[\"test\"]\n    all_labels = sm[\"train_labels\"] + sm[\"val_labels\"] + sm[\"test_labels\"]\n    BASE_ENCODER_CKPT = \"/kaggle/input/simsiam-task4-archive/simsiam_encoder.pth\"\n    encoder = build_encoder(BACKBONE)\n    if not load_encoder_weights(encoder, BASE_ENCODER_CKPT):\n        raise RuntimeError(\"Cannot load encoder weights from \" + BASE_ENCODER_CKPT)\n    feats_all = extract_features_from_paths(encoder, all_paths, batch_size=BATCH_SIZE, workers=NUM_WORKERS, save_path=os.path.join(OUT_ROOT,\"feats_all.npy\"))\n    labels_all = np.array(all_labels).astype(int)\n    np.save(os.path.join(OUT_ROOT,\"labels_all.npy\"), labels_all)\n\n# Final check\nif feats_all is None or labels_all is None:\n    raise RuntimeError(\"Failed to prepare features and labels. Check feature files or manifest.\")\n\nN = feats_all.shape[0]\nprint(\"Total samples used for ratio sweep:\", N)\n\n# Save composed arrays for reproducibility\nnp.save(os.path.join(OUT_ROOT,\"feats_all.npy\"), feats_all)\nnp.save(os.path.join(OUT_ROOT,\"labels_all.npy\"), labels_all)\n\n# -------- Ratio sweep: loop through ratios (use integer n_train to avoid rounding errors) --------\nratios = [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]  # train fraction (train:test)\nratio_results = []\n\nfor train_frac in ratios:\n    # compute integer train size robustly\n    n_train = int(round(train_frac * N))\n    # clamp to [1, N-1]\n    if n_train >= N:\n        n_train = N - 1\n    if n_train < 1:\n        n_train = 1\n    n_test = N - n_train\n    print(f\"Running ratio: train {int(train_frac*100)}% -> n_train={n_train}, n_test={n_test}\")\n    # Use stratified train_test_split with integer train_size\n    idxs = np.arange(N)\n    try:\n        train_idx, test_idx = train_test_split(idxs, train_size=n_train, stratify=labels_all, random_state=42)\n    except Exception as e:\n        # fallback: use random split (should be rare)\n        print(\"Stratified split failed, falling back to random split:\", e)\n        train_idx, test_idx = train_test_split(idxs, train_size=n_train, random_state=42)\n    X_train = feats_all[train_idx]; y_train = labels_all[train_idx]\n    X_test = feats_all[test_idx]; y_test = labels_all[test_idx]\n    # carve out val 10% of train (integer)\n    val_portion = max(1, int(round(0.10 * len(X_train))))\n    # pick val indices via stratify if possible\n    try:\n        tr_sub_idx, val_sub_idx = train_test_split(np.arange(len(X_train)), test_size=val_portion, stratify=y_train, random_state=42)\n    except Exception:\n        tr_sub_idx, val_sub_idx = train_test_split(np.arange(len(X_train)), test_size=val_portion, random_state=42)\n    X_tr = X_train[tr_sub_idx]; y_tr = y_train[tr_sub_idx]\n    X_val = X_train[val_sub_idx]; y_val = y_train[val_sub_idx]\n\n    # Train classifiers on X_tr\n    probes_res = {}\n    for name, clf in CLASSIFIERS.items():\n        import copy\n        clf_local = copy.deepcopy(clf)\n        if len(np.unique(y_tr)) < 2:\n            probes_res[name] = {\"accuracy\": None, \"macro_auc\": None, \"micro_auc\": None, \"per_class_f1\": None, \"skipped_reason\": \"only_one_class_in_train\"}\n            continue\n        clf_local.fit(X_tr, y_tr)\n        joblib.dump(clf_local, os.path.join(OUT_ROOT, f\"{int(train_frac*100)}pct_{name}.joblib\"))\n        y_pred = clf_local.predict(X_test)\n        acc = accuracy_score(y_test, y_pred)\n        prec, rec, f1, sup = precision_recall_fscore_support(y_test, y_pred, average=None, zero_division=0)\n        # AUC if probabilities exist\n        try:\n            if hasattr(clf_local, \"predict_proba\"):\n                probs = clf_local.predict_proba(X_test)\n                y_bin = label_binarize(y_test, classes=list(range(np.max(labels_all)+1)))\n                macro = roc_auc_score(y_bin, probs, average=\"macro\")\n                micro = roc_auc_score(y_bin, probs, average=\"micro\")\n            else:\n                macro = None; micro = None\n        except Exception:\n            macro = None; micro = None\n        probes_res[name] = {\"accuracy\": float(acc), \"macro_auc\": macro, \"micro_auc\": micro, \"per_class_f1\": f1.tolist()}\n\n    # label-efficiency robust (LogReg only)\n    label_eff = {}\n    total = X_tr.shape[0]\n    for frac in [0.01,0.05,0.10,0.25,0.50,1.0]:\n        k = max(1, int(total * frac))\n        sel = stratified_subsample_indices(y_tr, k, random_state=42)\n        if sel is None:\n            label_eff[f\"{int(frac*100)}%\"] = {\"accuracy\": None, \"skipped\": True, \"reason\": \"insufficient_class_diversity_for_k\"}\n            continue\n        clf = LogisticRegression(max_iter=2000)\n        clf.fit(X_tr[sel], y_tr[sel])\n        score = accuracy_score(y_test, clf.predict(X_test))\n        label_eff[f\"{int(frac*100)}%\"] = {\"accuracy\": float(score), \"skipped\": False, \"k_used\": int(len(sel))}\n\n    ratio_results.append({\n        \"train_frac\": train_frac,\n        \"n_train\": int(n_train),\n        \"n_val\": int(len(X_val)),\n        \"n_test\": int(n_test),\n        \"probes\": probes_res,\n        \"label_efficiency\": label_eff\n    })\n\n    # Save intermediate results\n    with open(os.path.join(OUT_ROOT, f\"ratio_{int(train_frac*100)}.json\"), \"w\") as f:\n        json.dump(ratio_results[-1], f, indent=2)\n\n# Save full results and CSV table\nwith open(os.path.join(OUT_ROOT, \"ratio_results.json\"), \"w\") as f:\n    json.dump(ratio_results, f, indent=2)\n\nimport csv\ncsv_path = os.path.join(OUT_ROOT, \"ratio_table.csv\")\nwith open(csv_path, \"w\", newline=\"\") as csvfile:\n    writer = csv.writer(csvfile)\n    # header\n    header = [\"train_pct\", \"n_train\", \"n_val\", \"n_test\"]\n    probe_names = list(CLASSIFIERS.keys())\n    header += [pn + \"_acc\" for pn in probe_names]\n    writer.writerow(header)\n    for rr in ratio_results:\n        row = [int(rr[\"train_frac\"]*100), rr[\"n_train\"], rr[\"n_val\"], rr[\"n_test\"]]\n        for pn in probe_names:\n            acc_val = rr[\"probes\"][pn][\"accuracy\"] if rr[\"probes\"][pn].get(\"accuracy\") is not None else \"\"\n            row.append(acc_val)\n        writer.writerow(row)\n\n# Zip outputs\nzipname = os.path.join(\"/kaggle/working\", \"task7_ratio_outputs\")\nif os.path.exists(zipname + \".zip\"):\n    os.remove(zipname + \".zip\")\nshutil.make_archive(base_name=zipname, format=\"zip\", root_dir=OUT_ROOT)\nprint(\"Ratio sweep outputs zipped to\", zipname + \".zip\")\nprint(\"Done. Outputs in\", OUT_ROOT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:00:38.293061Z","iopub.execute_input":"2025-12-06T15:00:38.293745Z","iopub.status.idle":"2025-12-06T15:03:46.259406Z","shell.execute_reply.started":"2025-12-06T15:00:38.293719Z","shell.execute_reply":"2025-12-06T15:03:46.258575Z"}},"outputs":[{"name":"stdout","text":"Total samples used for ratio sweep: 1800\nRunning ratio: train 90% -> n_train=1620, n_test=180\nRunning ratio: train 80% -> n_train=1440, n_test=360\nRunning ratio: train 70% -> n_train=1260, n_test=540\nRunning ratio: train 60% -> n_train=1080, n_test=720\nRunning ratio: train 50% -> n_train=900, n_test=900\nRunning ratio: train 40% -> n_train=720, n_test=1080\nRunning ratio: train 30% -> n_train=540, n_test=1260\nRunning ratio: train 20% -> n_train=360, n_test=1440\nRunning ratio: train 10% -> n_train=180, n_test=1620\nRatio sweep outputs zipped to /kaggle/working/task7_ratio_outputs.zip\nDone. Outputs in /kaggle/working/task7_ratios\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ===== FIXED CELL C: Statistical Tests (produces stats_report.json & significance_table.txt) =====\n# Self-contained. Run after ablation + ratio cells produced outputs.\nimport os, json, itertools, math, warnings\nfrom pathlib import Path\nimport numpy as np\nfrom scipy import stats\n\n# Try optional libs\ntry:\n    import scikit_posthocs as sp\n    HAVE_SPPH = True\nexcept Exception:\n    HAVE_SPPH = False\n\ntry:\n    from statsmodels.stats.contingency_tables import mcnemar\n    HAVE_STATSMODELS = True\nexcept Exception:\n    HAVE_STATSMODELS = False\n\n# Paths (edit if needed)\nABLATION_DIR = \"/kaggle/working/task7_ablation\"   # outputs from CELL A\nRATIO_DIR = \"/kaggle/working/task7_ratios\"       # outputs from CELL B\nOUT_DIR = \"/kaggle/working/task7_stats\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# Initialize report with consistent structure\nstats_report = {\n    \"friedman_ratio\": None,\n    \"posthoc_ratio\": None,\n    \"pairwise_tests_ratio\": [],   # standardized entries: {\"pair\":(...), \"test\": \"wilcoxon\"|\"ttest\", \"stat\":..., \"pvalue\":...}\n    \"ablation_mcnemar\": [],\n    \"ablation_pairwise_wilcoxon\": []\n}\n\n# Helper to safely append a pairwise test record\ndef append_pairwise(pair, test_name, stat_val, pval):\n    stats_report[\"pairwise_tests_ratio\"].append({\n        \"pair\": pair,\n        \"test\": test_name,\n        \"stat\": None if stat_val is None else float(stat_val),\n        \"pvalue\": None if pval is None else float(pval)\n    })\n\n# --------- Load ratio results and prepare matrix for Friedman test ---------\nratio_json = os.path.join(RATIO_DIR, \"ratio_results.json\")\nif not os.path.exists(ratio_json):\n    print(\"WARNING: ratio_results.json not found at\", ratio_json)\n    ratio_results = None\nelse:\n    with open(ratio_json,\"r\") as f:\n        ratio_results = json.load(f)\n\nif ratio_results:\n    # build matrix: rows = ratios, cols = probe names (consistent order)\n    probe_names = list(ratio_results[0][\"probes\"].keys())\n    ratios = [r.get(\"train_frac\", r.get(\"train_pct\", None)) for r in ratio_results]\n    # build accuracy matrix, ensuring numeric or nan\n    acc_matrix = np.array([[ (r[\"probes\"][p].get(\"accuracy\") if isinstance(r[\"probes\"][p].get(\"accuracy\"), (int,float)) else np.nan)\n                              for p in probe_names] for r in ratio_results], dtype=float)\n    # drop columns (probes) that are all NaN\n    valid_cols = ~np.all(np.isnan(acc_matrix), axis=0)\n    probe_names_valid = [pn for pn,ok in zip(probe_names, valid_cols) if ok]\n    acc_matrix_valid = acc_matrix[:, valid_cols]\n\n    # Friedman test across probes using ratios as blocks (requires no NaNs)\n    try:\n        if np.isnan(acc_matrix_valid).any():\n            # if there are NaNs, remove rows that contain any NaN (blocks with missing probe)\n            good_rows = ~np.isnan(acc_matrix_valid).any(axis=1)\n            arr = acc_matrix_valid[good_rows]\n            if arr.shape[0] >= 2 and arr.shape[1] >= 2:\n                fried_stat, fried_p = stats.friedmanchisquare(*[arr[:,j] for j in range(arr.shape[1])])\n            else:\n                fried_stat, fried_p = None, None\n        else:\n            fried_stat, fried_p = stats.friedmanchisquare(*[acc_matrix_valid[:,j] for j in range(acc_matrix_valid.shape[1])])\n        stats_report[\"friedman_ratio\"] = {\"statistic\": None if fried_stat is None else float(fried_stat),\n                                         \"pvalue\": None if fried_p is None else float(fried_p),\n                                         \"n_blocks\": int(acc_matrix_valid.shape[0]),\n                                         \"n_probes\": int(acc_matrix_valid.shape[1]),\n                                         \"probe_names\": probe_names_valid}\n        print(\"Friedman test on ratio sweep probes:\", stats_report[\"friedman_ratio\"])\n    except Exception as e:\n        print(\"Friedman test failed:\", e)\n        stats_report[\"friedman_ratio\"] = {\"error\": str(e)}\n\n    # Post-hoc: try Nemenyi if scikit-posthocs available\n    if HAVE_SPPH and acc_matrix_valid.shape[0] >= 2 and acc_matrix_valid.shape[1] >= 2:\n        try:\n            pvals = sp.posthoc_nemenyi_friedman(acc_matrix_valid)\n            stats_report[\"posthoc_ratio\"] = {\"method\": \"nemenyi\", \"pvals_matrix\": pvals.values.tolist(), \"probe_names\": probe_names_valid}\n            print(\"Nemenyi post-hoc completed.\")\n        except Exception as e:\n            print(\"Nemenyi failed:\", e)\n            stats_report[\"posthoc_ratio\"] = {\"error\": str(e)}\n    else:\n        # fallback: pairwise Wilcoxon signed-rank tests with Holm correction\n        from itertools import combinations\n        p_list = []\n        pairs = []\n        for i,j in combinations(range(acc_matrix_valid.shape[1]),2):\n            a = acc_matrix_valid[:, i]\n            b = acc_matrix_valid[:, j]\n            # drop rows where either is nan\n            mask = ~np.isnan(a) & ~np.isnan(b)\n            a2 = a[mask]; b2 = b[mask]\n            if len(a2) < 2:\n                # not enough paired observations — skip\n                append_pairwise((probe_names_valid[i], probe_names_valid[j]), \"insufficient_data\", None, None)\n                p_list.append(np.nan); pairs.append((probe_names_valid[i], probe_names_valid[j], None))\n                continue\n            try:\n                with warnings.catch_warnings():\n                    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n                    stat, p = stats.wilcoxon(a2, b2)\n                append_pairwise((probe_names_valid[i], probe_names_valid[j]), \"wilcoxon\", stat, p)\n                p_list.append(p); pairs.append((probe_names_valid[i], probe_names_valid[j], float(p)))\n            except Exception:\n                # fallback to paired t-test\n                try:\n                    stat_t, p_t = stats.ttest_rel(a2, b2)\n                    append_pairwise((probe_names_valid[i], probe_names_valid[j]), \"ttest_rel\", stat_t, p_t)\n                    p_list.append(p_t); pairs.append((probe_names_valid[i], probe_names_valid[j], float(p_t)))\n                except Exception:\n                    append_pairwise((probe_names_valid[i], probe_names_valid[j]), \"error\", None, None)\n                    p_list.append(np.nan); pairs.append((probe_names_valid[i], probe_names_valid[j], None))\n\n        # Holm-Bonferroni correction on valid p-values\n        valid_p_idx = [idx for idx,p in enumerate(p_list) if not (p is None or np.isnan(p))]\n        m = len(valid_p_idx)\n        holm_results = []\n        if m > 0:\n            sorted_idx = sorted(valid_p_idx, key=lambda k: p_list[k])\n            for rank, idx in enumerate(sorted_idx, start=1):\n                p = p_list[idx]\n                adj_thresh = 0.05/(m - rank + 1)\n                pair = pairs[idx]\n                holm_results.append({\"pair\": (pair[0], pair[1]), \"raw_p\": float(p), \"adj_threshold\": adj_thresh, \"significant\": float(p) <= adj_thresh})\n        stats_report[\"posthoc_ratio\"] = {\"method\": \"wilcoxon_holm\", \"results\": holm_results}\n\n    # Also run pairwise paired t-tests (for reference) and store consistently\n    for i,j in combinations(range(acc_matrix_valid.shape[1]),2):\n        a = acc_matrix_valid[:, i]; b = acc_matrix_valid[:, j]\n        mask = ~np.isnan(a) & ~np.isnan(b)\n        a2 = a[mask]; b2 = b[mask]\n        if len(a2) < 2:\n            append_pairwise((probe_names_valid[i], probe_names_valid[j]), \"ttest_rel_insufficient\", None, None)\n            continue\n        tstat, p = stats.ttest_rel(a2, b2)\n        append_pairwise((probe_names_valid[i], probe_names_valid[j]), \"ttest_rel\", tstat, p)\n\n# --------- Ablation: pairwise McNemar (if predictions available) & Wilcoxon on probe accuracies across epochs ---------\nablation_json = os.path.join(ABLATION_DIR, \"ablation_results.json\")\nif not os.path.exists(ablation_json):\n    print(\"WARNING: ablation_results.json not found at\", ablation_json)\n    ablation_results = None\nelse:\n    with open(ablation_json,\"r\") as f:\n        ablation_results = json.load(f)\n\nif ablation_results:\n    # Extract per-epoch accuracies for each probe\n    epoch_names = [s[\"epoch_dir\"] for s in ablation_results]\n    probe_accs = {}\n    for s in ablation_results:\n        for probe_name, pr in s[\"probe_results\"].items():\n            probe_accs.setdefault(probe_name, []).append(pr.get(\"accuracy\", None))\n    # pairwise Wilcoxon across epochs per probe\n    from itertools import combinations\n    for probe_name, accs in probe_accs.items():\n        pairwise = []\n        # compare every epoch pair\n        for i,j in combinations(range(len(accs)),2):\n            a = accs[i]; b = accs[j]\n            if a is None or b is None:\n                pairwise.append({\"epoch_pair\": (epoch_names[i], epoch_names[j]), \"stat\": None, \"pvalue\": None})\n                continue\n            try:\n                with warnings.catch_warnings():\n                    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n                    stat, p = stats.wilcoxon([a,b]) if (a==b) else stats.wilcoxon([a,b])\n                pairwise.append({\"epoch_pair\": (epoch_names[i], epoch_names[j]), \"stat\": None if stat is None else float(stat), \"pvalue\": None if p is None else float(p)})\n            except Exception:\n                try:\n                    stat_t, p_t = stats.ttest_rel([a],[b])\n                    pairwise.append({\"epoch_pair\": (epoch_names[i], epoch_names[j]), \"stat\": None if stat_t is None else float(stat_t), \"pvalue\": None if p_t is None else float(p_t)})\n                except Exception:\n                    pairwise.append({\"epoch_pair\": (epoch_names[i], epoch_names[j]), \"stat\": None, \"pvalue\": None})\n        stats_report[\"ablation_pairwise_wilcoxon\"].append({\"probe\": probe_name, \"pairwise\": pairwise})\n\n    # McNemar pairwise if per-epoch probe joblibs and test features/labels exist\n    global_test_labels = \"/kaggle/input/all-files/All Files/test_labels.npy\"\n    for s in ablation_results:\n        epoch_dir = s[\"epoch_dir\"]\n        epoch_path = os.path.join(ABLATION_DIR, epoch_dir)\n        test_feats_path = os.path.join(epoch_path, \"test_feats.npy\")\n        if os.path.exists(test_feats_path) and os.path.exists(global_test_labels):\n            y_true = np.load(global_test_labels)\n            models_found = []\n            for model_name in probe_accs.keys():\n                model_file = os.path.join(epoch_path, f\"probe_{model_name}.joblib\")\n                if os.path.exists(model_file):\n                    models_found.append((model_name, model_file))\n            for (m1, f1), (m2, f2) in combinations(models_found, 2):\n                try:\n                    import joblib\n                    clf1 = joblib.load(f1)\n                    clf2 = joblib.load(f2)\n                    X_test = np.load(test_feats_path)\n                    y1 = clf1.predict(X_test)\n                    y2 = clf2.predict(X_test)\n                    b01 = int(((y1==y_true) & (y2!=y_true)).sum())\n                    b10 = int(((y1!=y_true) & (y2==y_true)).sum())\n                    if HAVE_STATSMODELS:\n                        table = [[int(((y1==y_true)&(y2==y_true)).sum()), b01],\n                                 [b10, int(((y1!=y_true)&(y2!=y_true)).sum())]]\n                        res = mcnemar(table, exact=False)\n                        pval = float(res.pvalue)\n                        stats_report[\"ablation_mcnemar\"].append({\"epoch\": epoch_dir, \"model_pair\": (m1,m2), \"b01\": b01, \"b10\": b10, \"pvalue\": pval})\n                    else:\n                        n = b01 + b10\n                        if n == 0:\n                            pval = 1.0\n                        else:\n                            pval = 2.0 * min(stats.binom.cdf(min(b01,b10), n, 0.5), 1 - stats.binom.cdf(max(b01,b10)-1, n, 0.5))\n                        stats_report[\"ablation_mcnemar\"].append({\"epoch\": epoch_dir, \"model_pair\": (m1,m2), \"b01\": b01, \"b10\": b10, \"pvalue\": float(pval)})\n                except Exception as e:\n                    print(\"McNemar pairwise failed for\", epoch_dir, m1, m2, e)\n                    continue\n\n# Save stats report\nwith open(os.path.join(OUT_DIR, \"stats_report.json\"), \"w\") as f:\n    json.dump(stats_report, f, indent=2)\n\n# Also create a human-readable significance table text\nlines = []\nlines.append(\"STATISTICAL TESTS SUMMARY\\n\")\nif stats_report.get(\"friedman_ratio\"):\n    fr = stats_report[\"friedman_ratio\"]\n    lines.append(f\"Friedman (ratio sweep) statistic={fr.get('statistic')} p={fr.get('pvalue')} probes={fr.get('probe_names')}\\n\")\nif stats_report.get(\"posthoc_ratio\"):\n    ph = stats_report[\"posthoc_ratio\"]\n    lines.append(f\"Post-hoc method: {ph.get('method')}\\n\")\n    if ph.get(\"method\") == \"wilcoxon_holm\":\n        for item in ph.get(\"results\", []):\n            lines.append(f\"Pair {item['pair'][0]} vs {item['pair'][1]} raw_p={item['raw_p']:.4f} adj_thresh={item['adj_threshold']:.4f} significant={item['significant']}\\n\")\n    elif ph.get(\"method\") == \"nemenyi\":\n        lines.append(\"Nemenyi p-value matrix (rows/cols = probes):\\n\")\n        for row in ph.get(\"pvals_matrix\", []):\n            lines.append(\", \".join([f\"{x:.4f}\" for x in row]) + \"\\n\")\n\n# pairwise tests (robust printing)\nif stats_report.get(\"pairwise_tests_ratio\"):\n    lines.append(\"\\nPairwise tests (ratio sweep):\\n\")\n    for item in stats_report[\"pairwise_tests_ratio\"]:\n        pair = item.get(\"pair\")\n        test = item.get(\"test\")\n        stat = item.get(\"stat\")\n        p = item.get(\"pvalue\")\n        lines.append(f\"{pair[0]} vs {pair[1]}  test={test}  stat={stat}  p={p}\\n\")\n\nif stats_report.get(\"ablation_mcnemar\"):\n    lines.append(\"\\nAblation McNemar pairwise results:\\n\")\n    for item in stats_report[\"ablation_mcnemar\"]:\n        lines.append(f\"Epoch {item['epoch']} pair {item['model_pair'][0]} vs {item['model_pair'][1]} b01={item['b01']} b10={item['b10']} p={item['pvalue']:.6f}\\n\")\n\nif stats_report.get(\"ablation_pairwise_wilcoxon\"):\n    lines.append(\"\\nAblation pairwise Wilcoxon (per-probe):\\n\")\n    for item in stats_report[\"ablation_pairwise_wilcoxon\"]:\n        lines.append(f\"Probe: {item['probe']}\\n\")\n        for p in item[\"pairwise\"]:\n            lines.append(f\"  {p['epoch_pair'][0]} vs {p['epoch_pair'][1]} p={p.get('pvalue')}\\n\")\n\nwith open(os.path.join(OUT_DIR, \"significance_table.txt\"), \"w\") as f:\n    f.writelines(lines)\n\nprint(\"Stats saved to\", os.path.join(OUT_DIR, \"stats_report.json\"))\nprint(\"Human-readable table saved to\", os.path.join(OUT_DIR, \"significance_table.txt\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:28:26.798401Z","iopub.execute_input":"2025-12-06T15:28:26.798964Z","iopub.status.idle":"2025-12-06T15:28:32.395759Z","shell.execute_reply.started":"2025-12-06T15:28:26.798930Z","shell.execute_reply":"2025-12-06T15:28:32.394934Z"}},"outputs":[{"name":"stdout","text":"Friedman test on ratio sweep probes: {'statistic': 31.55555555555557, 'pvalue': 2.3579392529254347e-06, 'n_blocks': 9, 'n_probes': 5, 'probe_names': ['LogisticRegression', 'SVM_RBF', 'RandomForest', 'DecisionTree', 'MLP']}\nStats saved to /kaggle/working/task7_stats/stats_report.json\nHuman-readable table saved to /kaggle/working/task7_stats/significance_table.txt\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ===== CELL D: Zip all Task 7 outputs into task7_results.zip =====\nimport os, shutil\n\nOUT_ZIP = \"/kaggle/working/task7_results\"\n# directories to include\ndirs = [\n    \"/kaggle/working/task7_ablation\",\n    \"/kaggle/working/task7_ratios\",\n    \"/kaggle/working/task7_stats\"\n]\n# create combined folder if you want; but we'll directly archive each dir into one zip root\n# remove existing zip\nif os.path.exists(OUT_ZIP + \".zip\"):\n    os.remove(OUT_ZIP + \".zip\")\n\n# create a temporary folder to aggregate (safe)\ntmp_agg = \"/kaggle/working/task7_aggregate_tmp\"\nif os.path.exists(tmp_agg):\n    shutil.rmtree(tmp_agg)\nos.makedirs(tmp_agg, exist_ok=True)\n\nfor d in dirs:\n    if os.path.exists(d):\n        # copy into tmp_agg preserving folder name\n        folder_name = os.path.basename(d)\n        dst = os.path.join(tmp_agg, folder_name)\n        shutil.copytree(d, dst)\n    else:\n        print(\"Warning: directory not found, skipping:\", d)\n\n# create zip\nshutil.make_archive(base_name=OUT_ZIP, format=\"zip\", root_dir=tmp_agg)\nprint(\"Created zip:\", OUT_ZIP + \".zip\")\n# cleanup tmp\n# shutil.rmtree(tmp_agg)  # uncomment to remove tmp after creation\nprint(\"All Task 7 outputs archived.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:30:00.825105Z","iopub.execute_input":"2025-12-06T15:30:00.825451Z","iopub.status.idle":"2025-12-06T15:30:11.995162Z","shell.execute_reply.started":"2025-12-06T15:30:00.825426Z","shell.execute_reply":"2025-12-06T15:30:11.994500Z"}},"outputs":[{"name":"stdout","text":"Created zip: /kaggle/working/task7_results.zip\nAll Task 7 outputs archived.\n","output_type":"stream"}],"execution_count":12}]}